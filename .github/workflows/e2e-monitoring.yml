name: E2E Production Monitoring

on:
  # Daily at 6 AM UTC (only runs if there were changes)
  schedule:
    - cron: '0 6 * * *'
  # Manual trigger
  workflow_dispatch:
    inputs:
      url:
        description: 'Worker URL to benchmark'
        required: false
        default: 'https://parquedb.workers.do'
      skip_change_check:
        description: 'Run even if no recent changes'
        type: boolean
        required: false
        default: false

env:
  WORKER_URL: ${{ github.event.inputs.url || 'https://parquedb.workers.do' }}

jobs:
  # Check if there were recent changes (skip benchmark if no changes in last 24h)
  check-changes:
    name: Check for Recent Changes
    runs-on: ubuntu-latest
    outputs:
      has_changes: ${{ steps.check.outputs.has_changes }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Check for commits in last 24 hours
        id: check
        run: |
          # Skip check if manually triggered with skip_change_check
          if [ "${{ github.event.inputs.skip_change_check }}" == "true" ]; then
            echo "has_changes=true" >> $GITHUB_OUTPUT
            echo "Skipping change check (manual override)"
            exit 0
          fi

          # Check for commits in the last 24 hours
          COMMITS=$(git log --oneline --since="24 hours ago" | wc -l)
          echo "Commits in last 24 hours: $COMMITS"

          if [ "$COMMITS" -gt 0 ]; then
            echo "has_changes=true" >> $GITHUB_OUTPUT
          else
            echo "has_changes=false" >> $GITHUB_OUTPUT
            echo "No changes in last 24 hours, skipping benchmark"
          fi

  benchmark:
    name: E2E Benchmark
    runs-on: ubuntu-latest
    timeout-minutes: 30
    needs: check-changes
    if: needs.check-changes.outputs.has_changes == 'true'

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20.x'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Install Wrangler
        run: npm install -g wrangler

      - name: Download baseline from R2
        id: baseline
        continue-on-error: true
        run: |
          wrangler r2 object get parquedb-benchmarks/benchmarks/baselines/production/latest.json \
            --file=baseline.json 2>/dev/null || echo "No baseline found"
          if [ -f baseline.json ]; then
            echo "baseline_exists=true" >> $GITHUB_OUTPUT
          else
            echo "baseline_exists=false" >> $GITHUB_OUTPUT
          fi
        env:
          CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
          CLOUDFLARE_ACCOUNT_ID: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}

      - name: Run E2E benchmark
        id: benchmark
        run: |
          BASELINE_FLAG=""
          if [ "${{ steps.baseline.outputs.baseline_exists }}" == "true" ]; then
            BASELINE_FLAG="--baseline-url=./baseline.json"
          fi

          npx tsx tests/e2e/benchmarks/runner.ts \
            --url="${{ env.WORKER_URL }}" \
            --iterations=5 \
            --output=json \
            --save-baseline=./results.json \
            --environment=production \
            --fail-on-regression \
            $BASELINE_FLAG \
            > benchmark-output.json || true

          # Check exit code
          if [ $? -eq 0 ]; then
            echo "benchmark_status=passed" >> $GITHUB_OUTPUT
          else
            echo "benchmark_status=failed" >> $GITHUB_OUTPUT
          fi
        env:
          CI: true
          GITHUB_SHA: ${{ github.sha }}
          GITHUB_REF_NAME: ${{ github.ref_name }}

      - name: Upload results to R2
        if: always()
        continue-on-error: true
        run: |
          if [ -f results.json ]; then
            DATE_PATH=$(date -u +"%Y/%m/%d")
            RUN_ID="monitoring-$(date -u +"%s")-${{ github.run_id }}"
            RESULT_PATH="benchmarks/results/production/${DATE_PATH}/${RUN_ID}.json"

            wrangler r2 object put parquedb-benchmarks/${RESULT_PATH} \
              --file=results.json \
              --content-type="application/json"
          fi
        env:
          CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
          CLOUDFLARE_ACCOUNT_ID: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}

      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: monitoring-results-${{ github.run_id }}
          path: |
            results.json
            benchmark-output.json
          retention-days: 7

      - name: Display summary
        if: always()
        run: |
          echo "## E2E Monitoring Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Time:** $(date -u +"%Y-%m-%d %H:%M:%S UTC")" >> $GITHUB_STEP_SUMMARY
          echo "**Worker URL:** ${{ env.WORKER_URL }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          if [ -f results.json ]; then
            node -e "
              const fs = require('fs');
              const results = JSON.parse(fs.readFileSync('results.json', 'utf8'));
              const r = results.results || results;

              if (r.summary) {
                console.log('### Summary');
                console.log('| Metric | Value |');
                console.log('|--------|-------|');
                console.log('| Total Tests | ' + r.summary.totalTests + ' |');
                console.log('| Passed | ' + r.summary.passedTests + ' |');
                console.log('| Failed | ' + r.summary.failedTests + ' |');
                console.log('| Avg Latency | ' + r.summary.avgLatencyMs?.toFixed(1) + 'ms |');
                console.log('');
              }

              if (r.regression) {
                const status = r.regression.hasRegression ? ':warning: Regression' : ':white_check_mark: OK';
                console.log('### Regression: ' + status);
                console.log('Severity: ' + r.regression.severity);
              }
            " >> $GITHUB_STEP_SUMMARY
          fi

      - name: Alert on regression (Slack)
        if: steps.benchmark.outputs.benchmark_status == 'failed'
        continue-on-error: true
        run: |
          if [ -n "${{ secrets.E2E_SLACK_WEBHOOK_URL }}" ]; then
            curl -X POST -H 'Content-type: application/json' \
              --data '{
                "text": ":chart_with_downwards_trend: E2E Monitoring: Regression Detected",
                "blocks": [
                  {
                    "type": "section",
                    "text": {
                      "type": "mrkdwn",
                      "text": ":chart_with_downwards_trend: *E2E Monitoring: Regression Detected*\n\n*Worker URL:* ${{ env.WORKER_URL }}\n*Time:* '"$(date -u +"%Y-%m-%d %H:%M:%S UTC")"'\n\n<${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}|View Run>"
                    }
                  }
                ]
              }' \
              ${{ secrets.E2E_SLACK_WEBHOOK_URL }}
          fi

