{"id":"parquedb-02r","title":"[GREEN] Bloom filter implementation","description":"Implement bloom filters to pass tests","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:47.278863-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:24:19.421114-06:00","closed_at":"2026-02-01T14:24:19.421114-06:00","close_reason":"Closed"}
{"id":"parquedb-05ul","title":"Extract duplicate utility functions to shared module","description":"Code duplication found across multiple files:\n- deepEqual() in filter.ts, predicate.ts, update.ts\n- compareValues() in filter.ts, predicate.ts, update.ts, Collection.ts\n- getNestedValue() in filter.ts, predicate.ts, Collection.ts\n- deepClone() in Collection.ts\n\nCreate /src/utils/comparison.ts to centralize these. Update all imports.","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-01T12:42:09.794245-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T12:54:07.325887-06:00","closed_at":"2026-02-01T12:54:07.325887-06:00","close_reason":"Completed by parallel agents"}
{"id":"parquedb-06e7","title":"Refactor: Worker - Use ParqueDBDOStub type consistently for DO RPC calls","description":"The codebase defines a typed ParqueDBDOStub interface in src/types/worker.ts, but several DO RPC calls use `as unknown as ParqueDBDOStub` casting pattern instead of proper typing.\n\nFiles:\n- src/worker/index.ts (multiple occurrences in create, update, delete, etc.)\n\nAll DO stub accesses use this pattern:\n```typescript\nconst stub = this.env.PARQUEDB.get(doId) as unknown as ParqueDBDOStub\n```\n\nConsider:\n1. Create a typed wrapper function like `getDOStub(ns: string): ParqueDBDOStub`\n2. Or improve the Cloudflare Workers type definitions\n\nImpact: Cleaner code, single point of change for DO access","status":"open","priority":3,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:33:18.24622-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T06:33:18.24622-06:00"}
{"id":"parquedb-073b","title":"Add CLI plugin/command registry system","description":"CLI commands are hardcoded in switch statement. Add a command registry pattern for easier extension: CommandRegistry.register('backup', backupCommand). Allow custom commands via plugins.","status":"closed","priority":2,"issue_type":"feature","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-01T17:01:05.127307-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-02T04:43:33.879368-06:00","closed_at":"2026-02-02T04:43:33.879368-06:00","close_reason":"Completed by agents"}
{"id":"parquedb-07e","title":"[GREEN] Delete operation implementation","description":"Implement delete operations to pass tests","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:36.046455-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:06:19.220126-06:00","closed_at":"2026-02-01T14:06:19.220126-06:00","close_reason":"Closed"}
{"id":"parquedb-09qp","title":"Use binary search for SST unique constraint check","description":"SSTIndex.ts:285-300 uses linear O(n) scan for unique constraint check instead of using the index's sorted nature. Should use lowerBound/upperBound binary search for O(log n).","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-02T05:32:34.091559-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-02T06:31:20.035884-06:00","closed_at":"2026-02-02T06:31:20.035884-06:00","close_reason":"Closed"}
{"id":"parquedb-0axe","title":"Add error path and recovery tests","description":"Error paths under-tested:\n- Corrupted Parquet files\n- Invalid index data\n- Malformed events\n- Out of memory handling\n- Large file handling\n- Concurrent request limits\n- Timeout handling\n- Partial failures\n\nAdd tests for error recovery scenarios.","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-01T12:42:24.690643-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T13:07:24.720102-06:00","closed_at":"2026-02-01T13:07:24.720102-06:00","close_reason":"Completed by parallel agents"}
{"id":"parquedb-0grh","title":"Refactor: Worker - CdnR2StorageAdapter duplicates StorageBackend interface","description":"CdnR2StorageAdapter in QueryExecutor.ts implements a partial StorageBackend interface inline, with stub methods that throw 'Not implemented':\n\n```typescript\nasync write(): Promise\u003cnever\u003e { throw new Error('Not implemented') }\nasync writeAtomic(): Promise\u003cnever\u003e { throw new Error('Not implemented') }\n// ... 6 more stub methods\n```\n\nSimilarly, IndexCache has MemoryStorageAdapter with full implementation.\n\nFiles:\n- src/worker/QueryExecutor.ts (CdnR2StorageAdapter, lines 246-429)\n- src/worker/IndexCache.ts (MemoryStorageAdapter, lines 396-458)\n\nBoth implement the same interface differently. This could be consolidated:\n1. Create a ReadOnlyStorageAdapter base class\n2. Or use Partial\u003cStorageBackend\u003e type properly\n3. Or extract shared logic to a common module\n\nImpact: Reduced code duplication, clearer contracts","status":"open","priority":3,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:34:43.054215-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T06:34:43.054215-06:00"}
{"id":"parquedb-0gy","title":"[RED] Unique index tests","description":"Write failing tests for unique constraint validation","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:52:02.00521-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:32:37.78447-06:00","closed_at":"2026-02-01T14:32:37.78447-06:00","close_reason":"RED phase complete: Created unique index test suite with 23 tests"}
{"id":"parquedb-0jhn","title":"Refactor: core.ts update() - Extract update operators into separate functions","description":"In src/ParqueDB/core.ts, the update() method (lines 685-1155) is excessively long at ~470 lines. It handles all update operators inline ($set, $unset, $inc, $mul, $min, $max, $push, $pull, $addToSet, $currentDate, $link, $unlink).\n\nEach operator's logic should be extracted into separate pure functions in a dedicated module (e.g., src/mutation/operators.ts):\n- applySetOperator(entity, setOps)\n- applyIncOperator(entity, incOps)\n- applyPushOperator(entity, pushOps)\n- applyLinkOperator(entity, linkOps, schema, entities)\n- etc.\n\nBenefits:\n1. Reduces cognitive load when reading the code\n2. Makes individual operators testable in isolation\n3. Enables code reuse if operators are needed elsewhere\n4. Follows single responsibility principle\n\nThe method should orchestrate operator application rather than implement each one.","status":"closed","priority":3,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:32:41.919518-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T06:55:48.020436-06:00","closed_at":"2026-02-03T06:55:48.020436-06:00","close_reason":"Implemented by agents","labels":["complexity","refactor"]}
{"id":"parquedb-0lu","title":"[GREEN] Sorting implementation","description":"Implement sorting to pass tests","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:29.251572-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:11:19.031765-06:00","closed_at":"2026-02-01T14:11:19.031765-06:00","close_reason":"Closed"}
{"id":"parquedb-0nr","title":"[RED] Relationship storage tests","description":"Write failing tests for writing relationships to forward and reverse indexes","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:22.955863-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:08:29.179944-06:00","closed_at":"2026-02-01T14:08:29.179944-06:00","close_reason":"Closed"}
{"id":"parquedb-0ol","title":"[RED] vitest-pool-workers with real bindings","description":"Configure vitest-pool-workers with remote:true. Real R2, DO, service bindings. No mocks.","status":"closed","priority":0,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T14:30:01.09188-06:00","created_by":"Nathan Clevenger","updated_at":"2026-01-30T14:35:40.046008-06:00","closed_at":"2026-01-30T14:35:40.046008-06:00","close_reason":"Closed"}
{"id":"parquedb-1237","title":"Refactor: core.ts hydrateEntity() and getRelated() - Consolidate reverse relationship traversal","description":"In src/ParqueDB/core.ts, reverse relationship traversal logic is duplicated in:\n\n1. hydrateEntity() lines 1562-1581:\n```typescript\nthis.entities.forEach((relatedEntity, relatedId) =\u003e {\n  if (!relatedId.startsWith(`${relatedNs}/`)) return\n  if (relatedEntity.deletedAt) return\n  const refField = (relatedEntity as Record\u003cstring, unknown\u003e)[relatedField]\n  if (refField \u0026\u0026 typeof refField === 'object') {\n    for (const [, refId] of Object.entries(refField)) {\n      if (refId === fullId) { /* collect */ }\n    }\n  }\n})\n```\n\n2. getRelated() lines 541-556: Nearly identical logic\n\nThis should be extracted to a shared utility:\n```typescript\ninterface ReverseRelationQuery {\n  targetId: string\n  relatedNs: string\n  relatedField: string\n  includeDeleted?: boolean\n}\nfunction findReverseRelations(\n  entities: Map\u003cstring, Entity\u003e,\n  query: ReverseRelationQuery\n): Entity[]\n```\n\nBenefits:\n1. Single implementation to maintain\n2. Consistent behavior across hydration and getRelated\n3. Could be optimized with an index in the future","status":"open","priority":3,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:33:52.503016-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T06:33:52.503016-06:00","labels":["duplication","refactor"]}
{"id":"parquedb-16qd","title":"Add tests for untested storage backends","description":"Missing test coverage for: DOSqliteBackend.ts, ObservedBackend.ts. These are critical storage components that need unit tests.","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-02T05:32:41.14438-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-02T06:34:50.118264-06:00","closed_at":"2026-02-02T06:34:50.118264-06:00","close_reason":"Closed"}
{"id":"parquedb-18b","title":"[GREEN] Collection class implementation","description":"Implement Collection class to pass tests","status":"closed","priority":0,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:45.589587-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:02:25.577545-06:00","closed_at":"2026-02-01T14:02:25.577545-06:00","close_reason":"Closed"}
{"id":"parquedb-1c3","title":"Implement R2 segment writer for events","description":"Write event batches as Parquet segments to R2:\n\n- Write events as Parquet file to events/seg-{seq}.parquet\n- Use for bulk operations or when SQLite batching isn't optimal\n- Segment naming with monotonic sequence\n\nFile: src/events/segment.ts","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-01T06:37:53.915852-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T07:08:19.518679-06:00","closed_at":"2026-02-01T07:08:19.518679-06:00","close_reason":"Implemented SegmentWriter for writing event batches to R2 as segments. Features: JSON-lines serialization (Parquet TODO), sequence numbering, batch merging, R2 adapter. Added 18 passing tests.","dependencies":[{"issue_id":"parquedb-1c3","depends_on_id":"parquedb-zqk","type":"blocks","created_at":"2026-02-01T06:38:08.241877-06:00","created_by":"Nathan Clevenger"}]}
{"id":"parquedb-1c4","title":"[GREEN] Vector index implementation","description":"Implement vector indexes to pass tests","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:59.753193-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:30:37.82127-06:00","closed_at":"2026-02-01T14:30:37.82127-06:00","close_reason":"Implemented HNSW vector index in src/indexes/vector/ with full support for cosine, euclidean, and dot product distance metrics. All 29 tests pass."}
{"id":"parquedb-1gj","title":"Implement sorting","description":"Sort query results by multiple fields","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:26.901849-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:11:18.954003-06:00","closed_at":"2026-02-01T14:11:18.954003-06:00","close_reason":"Closed"}
{"id":"parquedb-1m38","title":"Add cleanup for stale R2 multipart uploads","description":"R2Backend.activeUploads Map stores multipart uploads but only clears on success/abort. Failed clients leave uploads in memory indefinitely. Add timeout/TTL mechanism to clean up stale uploads.","status":"closed","priority":1,"issue_type":"bug","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-02T05:32:32.20722-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-02T06:33:51.416442-06:00","closed_at":"2026-02-02T06:33:51.416442-06:00","close_reason":"Closed"}
{"id":"parquedb-1t78","title":"Add npm badges to README","description":"README has no badges. Add: npm version, build status, test coverage, license, TypeScript badge. Use shields.io format.","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-01T17:01:11.319238-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T17:18:33.800543-06:00","closed_at":"2026-02-01T17:18:33.800543-06:00","close_reason":"Closed"}
{"id":"parquedb-1ys","title":"[RED] Event logging tests","description":"Write failing tests for event creation and storage","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:35.63593-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:21:45.00322-06:00","closed_at":"2026-02-01T14:21:45.00322-06:00","close_reason":"Closed"}
{"id":"parquedb-2679","title":"Refactor: Worker - API consistency between DO and local ParqueDB","description":"There are API differences between ParqueDBDO (Worker writes) and ParqueDBImpl (local):\n\nDO (ParqueDBDO):\n- Uses DOCreateOptions, DOUpdateOptions, DODeleteOptions\n- create() requires $type and name fields\n- link() takes full entityId strings (ns/id format)\n\nLocal (ParqueDBImpl/ParqueDB):\n- Uses CreateOptions, UpdateOptions, DeleteOptions\n- create() derives type from namespace\n- Different relationship API\n\nFiles:\n- src/worker/ParqueDBDO.ts\n- src/ParqueDB/core.ts\n- src/types/worker.ts\n\nThis makes code sharing difficult and creates confusion about which API to use.\n\nRefactor:\n1. Align option types (or document why they differ)\n2. Standardize required fields for create\n3. Consider shared base implementation\n\nImpact: Easier code reuse, clearer mental model for developers","status":"open","priority":3,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:34:25.51832-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T06:34:25.51832-06:00"}
{"id":"parquedb-290","title":"Implement secondary indexes","description":"B-tree style indexes for range queries on fields","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:49.296781-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:24:34.937087-06:00","closed_at":"2026-02-01T14:24:34.937087-06:00","close_reason":"Secondary indexes implemented with Hash and SST index types. All 251 index tests passing including unit tests for hash index, SST index, sharded indexes, and integration tests."}
{"id":"parquedb-2be","title":"Documentation Epic: Complete ParqueDB Documentation","description":"Comprehensive documentation for ParqueDB including API docs, guides, and examples","status":"closed","priority":1,"issue_type":"epic","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T12:40:05.653094-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:38:45.473766-06:00","closed_at":"2026-02-01T14:38:45.473766-06:00","close_reason":"Closed"}
{"id":"parquedb-2dao","title":"Standardize null vs undefined handling","description":"Inconsistent null/undefined handling: comparison.ts treats them as equivalent, filter.ts distinguishes between them (null matches null/undefined, undefined matches everything). Document and standardize the behavior.","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-01T17:01:13.169944-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T17:21:56.33577-06:00","closed_at":"2026-02-01T17:21:56.33577-06:00","close_reason":"Closed"}
{"id":"parquedb-2h4","title":"[RED] Projection tests","description":"Write failing tests for field inclusion and exclusion","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:24.593745-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:15:31.014614-06:00","closed_at":"2026-02-01T14:15:31.014614-06:00","close_reason":"Closed"}
{"id":"parquedb-2jk","title":"Implement upsert","description":"Create or update based on filter","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:36.635305-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:06:28.672893-06:00","closed_at":"2026-02-01T14:06:28.672893-06:00","close_reason":"Closed"}
{"id":"parquedb-2kk","title":"[REFACTOR] ParqueDB class cleanup","description":"Refactor ParqueDB class","status":"closed","priority":0,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:31.644586-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:02:41.978869-06:00","closed_at":"2026-02-01T14:02:41.978869-06:00","close_reason":"Closed"}
{"id":"parquedb-2lf","title":"Implement StorageBackend interface","description":"Define and implement the StorageBackend interface for abstracting file operations","status":"closed","priority":0,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:50:54.271963-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:03:10.06904-06:00","closed_at":"2026-02-01T14:03:10.06904-06:00","close_reason":"Closed","dependencies":[{"issue_id":"parquedb-2lf","depends_on_id":"parquedb-nvh","type":"blocks","created_at":"2026-01-30T11:51:09.046564-06:00","created_by":"Nathan Clevenger"},{"issue_id":"parquedb-2lf","depends_on_id":"parquedb-2nq","type":"blocks","created_at":"2026-01-30T11:51:09.136886-06:00","created_by":"Nathan Clevenger"},{"issue_id":"parquedb-2lf","depends_on_id":"parquedb-ce0","type":"blocks","created_at":"2026-01-30T11:51:09.226986-06:00","created_by":"Nathan Clevenger"}]}
{"id":"parquedb-2m9z","title":"Refactor: Storage - Extract duplicate normalizePath function","description":"The normalizePath function is duplicated in:\\n\\n1. MemoryBackend.ts (lines 122-128) - normalizePath method, removes leading slash\\n2. DOSqliteBackend.ts (lines 132-143) - normalizePath function, removes leading and trailing slashes\\n\\nAlso, R2Backend has withPrefix/withoutPrefix pattern, and FsBackend has resolvePath which does normalization plus security checks.\\n\\nRefactor to:\\n- Create a shared normalizePath function in src/storage/utils.ts\\n- Consider adding a PathNormalizer class with configurable behavior\\n- Standardize path handling across all backends\\n\\nFiles affected:\\n- /Users/nathanclevenger/projects/parquedb/src/storage/MemoryBackend.ts\\n- /Users/nathanclevenger/projects/parquedb/src/storage/DOSqliteBackend.ts\\n- /Users/nathanclevenger/projects/parquedb/src/storage/R2Backend.ts\\n- /Users/nathanclevenger/projects/parquedb/src/storage/FsBackend.ts\\n- /Users/nathanclevenger/projects/parquedb/src/storage/FsxBackend.ts","status":"open","priority":3,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:32:47.572467-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T06:32:47.572467-06:00"}
{"id":"parquedb-2nq","title":"[GREEN] StorageBackend interface implementation","description":"Implement StorageBackend interface to pass tests","status":"closed","priority":0,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:03.480769-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:03:05.085765-06:00","closed_at":"2026-02-01T14:03:05.085765-06:00","close_reason":"Closed"}
{"id":"parquedb-2o5","title":"Implement vector indexes","description":"HNSW index for $vector similarity queries","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:57.669927-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:30:38.642369-06:00","closed_at":"2026-02-01T14:30:38.642369-06:00","close_reason":"Implemented HNSW vector index with near similarity queries. Features: O(log n) ANN search, multiple distance metrics (cosine, euclidean, dot), persistence, score filtering, efSearch tuning."}
{"id":"parquedb-2sm","title":"[GREEN] Secondary index implementation","description":"Implement secondary indexes to pass tests","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:52.53722-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:24:38.686033-06:00","closed_at":"2026-02-01T14:24:38.686033-06:00","close_reason":"Secondary index implementation complete. Hash index provides O(1) equality lookups, SST index provides sorted range queries. Includes sharded variants for large indexes. All 251 tests passing."}
{"id":"parquedb-2v6","title":"Convert wrangler.toml to wrangler.jsonc 2026 compat","description":"Replace wrangler.toml with modern wrangler.jsonc. Use compatibility_date 2026-01-30.","status":"closed","priority":0,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T14:30:02.153993-06:00","created_by":"Nathan Clevenger","updated_at":"2026-01-30T14:30:41.603228-06:00","closed_at":"2026-01-30T14:30:41.603228-06:00","close_reason":"Closed"}
{"id":"parquedb-2vo","title":"[GREEN] Field operators implementation","description":"Implement $set, $unset, $rename to pass tests","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:21.944301-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:08:21.651836-06:00","closed_at":"2026-02-01T14:08:21.651836-06:00","close_reason":"Closed"}
{"id":"parquedb-2whw","title":"[FEATURE] Implement vector similarity search","description":"Vector search is not implemented. Need to:\n\n1. Design vector storage format (in Parquet or separate index)\n2. Implement embedding storage and retrieval\n3. Add similarity search operators ($nearVector, $cosineSimilarity)\n4. Consider HNSW or IVF index structures\n5. Integrate with AI embedding providers\n\nSee docs/architecture/SECONDARY_INDEXES.md for index design patterns.","status":"closed","priority":2,"issue_type":"feature","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-01T13:36:03.350503-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:42:14.168569-06:00","closed_at":"2026-02-01T14:42:14.168569-06:00","close_reason":"Closed"}
{"id":"parquedb-2xf","title":"[REFACTOR] Bloom filter optimization","description":"Optimize bloom filter size and FPR","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:48.286197-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:24:19.506156-06:00","closed_at":"2026-02-01T14:24:19.506156-06:00","close_reason":"Closed"}
{"id":"parquedb-2zr9","title":"Refactor: Worker - Consolidate event buffering systems in ParqueDBDO","description":"ParqueDBDO has two parallel event buffering systems:\n\n1. eventBuffer + eventBufferSize (generic, lines 189-193)\n2. nsEventBuffers (namespace-based with sequence tracking, line 199)\n\nThe namespace-based system (appendEventWithSeq) is more advanced with Sqids ID generation, but appendEvent() still uses the generic buffer. This duplication is confusing.\n\nFiles:\n- src/worker/ParqueDBDO.ts\n\nRefactor options:\n1. Remove legacy eventBuffer and migrate all callers to appendEventWithSeq\n2. Or consolidate both systems into one unified approach\n\nImpact: Reduces code complexity and prevents confusion about which method to use","status":"open","priority":3,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:32:59.960847-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T06:32:59.960847-06:00"}
{"id":"parquedb-336","title":"[GREEN] Projection implementation","description":"Implement projection to pass tests","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:26.014878-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:15:30.815964-06:00","closed_at":"2026-02-01T14:15:30.815964-06:00","close_reason":"Closed"}
{"id":"parquedb-347","title":"Remove mocks from ParqueDB.test.ts and use real storage","description":"Removed ALL vi.fn() mocks from tests/unit/ParqueDB.test.ts and replaced them with real FsBackend using temp directories. Also fixed ParqueDB.get() to handle FileNotFoundError gracefully for empty databases.","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T14:34:52.010768-06:00","created_by":"Nathan Clevenger","updated_at":"2026-01-30T14:34:56.234738-06:00","closed_at":"2026-01-30T14:34:56.234738-06:00","close_reason":"Closed"}
{"id":"parquedb-353","title":"Implement MemoryBackend","description":"In-memory storage backend for testing","status":"closed","priority":0,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:12.837861-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T13:11:47.872937-06:00","closed_at":"2026-02-01T13:11:47.872937-06:00","close_reason":"Closed","dependencies":[{"issue_id":"parquedb-353","depends_on_id":"parquedb-ezw","type":"blocks","created_at":"2026-01-30T11:51:22.162836-06:00","created_by":"Nathan Clevenger"},{"issue_id":"parquedb-353","depends_on_id":"parquedb-qrm","type":"blocks","created_at":"2026-01-30T11:51:22.250376-06:00","created_by":"Nathan Clevenger"},{"issue_id":"parquedb-353","depends_on_id":"parquedb-d3j","type":"blocks","created_at":"2026-01-30T11:51:22.332374-06:00","created_by":"Nathan Clevenger"}]}
{"id":"parquedb-37c3","title":"Implement ParquetSchemaGenerator for typed collections","description":"## Context\nPart of typed storage implementation (parquedb-k7jj design).\n\n## Requirements\n\n1. Create `src/parquet/schema-generator.ts`:\n   - `ParquetSchemaGenerator` interface\n   - `ParquetSchemaGeneratorImpl` class\n   - `fromTypeDefinition(typeDef, options)` - generate Parquet schema\n   - `fieldToParquet(fieldName, fieldType)` - convert single field\n\n2. Type mapping (IceType/GraphDL to Parquet):\n   - string -\u003e STRING\n   - int -\u003e INT64\n   - float/double/number -\u003e FLOAT/DOUBLE\n   - boolean -\u003e BOOLEAN\n   - date -\u003e DATE (INT32)\n   - datetime/timestamp -\u003e TIMESTAMP_MILLIS (INT64)\n   - uuid -\u003e FIXED_LEN_BYTE_ARRAY(16) + UUID logical type\n   - json -\u003e BYTE_ARRAY + JSON logical type\n   - binary -\u003e BYTE_ARRAY\n   - Support required (!) and array ([]) modifiers\n\n3. System fields:\n   - Always include $id, $type, createdAt, updatedAt, version\n   - Optionally include $data Variant column\n\n4. Testing:\n   - Unit tests for all type mappings\n   - Tests for required vs optional\n   - Tests for array types\n   - Tests for $options.includeDataVariant\n\n## Acceptance Criteria\n- [ ] Type mapping covers all IceType primitives\n- [ ] Required/optional modifiers handled correctly\n- [ ] Array types use REPEATED repetition\n- [ ] System fields always present\n- [ ] $data column respects includeDataVariant option\n- [ ] Tests pass\n\n## References\n- Design: docs/architecture/typed-storage.md\n- Depends on: parquedb-s8yv (StorageRouter)","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:41:20.87395-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T07:11:30.211467-06:00","closed_at":"2026-02-03T07:11:30.211467-06:00","close_reason":"Implemented"}
{"id":"parquedb-38d","title":"Write: Update Operators ($set, $inc, $push)","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T12:40:42.12032-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:35:37.601656-06:00","closed_at":"2026-02-01T14:35:37.601656-06:00","close_reason":"Closed"}
{"id":"parquedb-39d","title":"[RED] FsBackend tests","description":"Write failing tests for FsBackend","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:48.783973-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-02T04:45:59.164984-06:00","closed_at":"2026-02-02T04:45:59.164984-06:00","close_reason":"Tests implemented in earlier waves"}
{"id":"parquedb-3h6n","title":"Add Worker component unit tests","description":"Worker components under-tested. Create tests/unit/worker/ with:\n- IndexCache.test.ts\n- ReadPath.test.ts\n- QueryExecutor.test.ts\n- CacheStrategy.test.ts\n\nFocus on index caching logic, read path optimization, and query planning.","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-01T12:42:21.851024-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T12:54:07.414252-06:00","closed_at":"2026-02-01T12:54:07.414252-06:00","close_reason":"Completed by parallel agents"}
{"id":"parquedb-3ig","title":"[GREEN] Filter logical operators","description":"Implement logical operators to pass tests","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:08.895506-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T13:10:39.921329-06:00","closed_at":"2026-02-01T13:10:39.921329-06:00","close_reason":"Closed"}
{"id":"parquedb-3iwj","title":"Consolidate magic numbers into constants","description":"Magic numbers scattered across files: DEFAULT_MAX_INBOUND=100, CONCURRENCY=4, various size constants in R2Backend. Create src/constants.ts to centralize configuration values.","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-01T17:01:12.328371-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T17:26:04.90627-06:00","closed_at":"2026-02-01T17:26:04.90627-06:00","close_reason":"Closed"}
{"id":"parquedb-3jd","title":"[GREEN] upsertMany implementation","description":"Implement Collection.upsertMany() to pass the tests.","status":"closed","priority":0,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T14:30:05.063918-06:00","created_by":"Nathan Clevenger","updated_at":"2026-01-30T14:36:55.258417-06:00","closed_at":"2026-01-30T14:36:55.258417-06:00","close_reason":"Closed","dependencies":[{"issue_id":"parquedb-3jd","depends_on_id":"parquedb-8p4","type":"blocks","created_at":"2026-01-30T14:30:14.156157-06:00","created_by":"Nathan Clevenger"}]}
{"id":"parquedb-3js3","title":"Add tests for parquet/variant-filter.ts","description":"src/parquet/variant-filter.ts (304 lines) pushes filters into Variant-encoded columns. Performance-critical path with no dedicated tests.","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-02T07:16:03.565102-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-02T07:23:51.456114-06:00","closed_at":"2026-02-02T07:23:51.456114-06:00","close_reason":"Closed"}
{"id":"parquedb-3m8","title":"[REFACTOR] Update operators cleanup","description":"Refactor update operators","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:27.59666-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:08:21.810893-06:00","closed_at":"2026-02-01T14:08:21.810893-06:00","close_reason":"Closed"}
{"id":"parquedb-3nxk","title":"Refactor: core.ts - Replace 'any' type casts with proper typing","description":"In src/ParqueDB/core.ts, there are several implicit 'any' type usages through type assertions that could be tightened:\n\n1. Line 749-750: `const beforeEntity = options?.returnDocument === 'before' ? (isInsert ? null : { ...entity }) : null`\n   - beforeEntity is typed implicitly, should be `Entity | null`\n\n2. Lines 779, 790, 801, etc.: `(entity as Record\u003cstring, unknown\u003e)[key]`\n   - This pattern is used extensively in update operators\n   - Consider a helper type: `type EntityRecord = Entity \u0026 Record\u003cstring, unknown\u003e`\n\n3. Line 1124: `{ predicate, to: linkTarget } as unknown as Entity`\n   - This is a type lie - the object is not an Entity\n   - Should define a proper RelationshipEventData type\n\n4. Line 2217-2218: `before: (e.before ?? null) as Entity | null`\n   - Event.before and Event.after are typed as Variant\n   - Need proper type narrowing or a type guard\n\nConsider creating a types.ts extension with:\n- EntityRecord type for mutation operations\n- RelationshipEventData for link/unlink events\n- Type guards: isEntityVariant(v): v is Entity","status":"open","priority":3,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:33:22.852915-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T06:33:22.852915-06:00","labels":["refactor","types"]}
{"id":"parquedb-3ui","title":"Core Infrastructure","description":"Foundation for ParqueDB: types, storage backends, and basic DB class","status":"closed","priority":0,"issue_type":"epic","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:50:26.777987-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:34:08.760149-06:00","closed_at":"2026-02-01T14:34:08.760149-06:00","close_reason":"Closed","dependencies":[{"issue_id":"parquedb-3ui","depends_on_id":"parquedb-2lf","type":"blocks","created_at":"2026-01-30T11:52:09.664689-06:00","created_by":"Nathan Clevenger"},{"issue_id":"parquedb-3ui","depends_on_id":"parquedb-353","type":"blocks","created_at":"2026-01-30T11:52:09.750379-06:00","created_by":"Nathan Clevenger"},{"issue_id":"parquedb-3ui","depends_on_id":"parquedb-aio","type":"blocks","created_at":"2026-01-30T11:52:09.833468-06:00","created_by":"Nathan Clevenger"},{"issue_id":"parquedb-3ui","depends_on_id":"parquedb-hi2","type":"blocks","created_at":"2026-01-30T11:52:09.913238-06:00","created_by":"Nathan Clevenger"},{"issue_id":"parquedb-3ui","depends_on_id":"parquedb-pt8","type":"blocks","created_at":"2026-01-30T11:52:09.996242-06:00","created_by":"Nathan Clevenger"}]}
{"id":"parquedb-3wv","title":"[GREEN] Upsert implementation","description":"Implement upsert to pass tests","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:38.268485-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:06:28.70388-06:00","closed_at":"2026-02-01T14:06:28.70388-06:00","close_reason":"Closed"}
{"id":"parquedb-3y2","title":"Implement relationship storage","description":"Store relationships in rels.parquet with forward/reverse indexes","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:21.655638-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:08:29.147715-06:00","closed_at":"2026-02-01T14:08:29.147715-06:00","close_reason":"Closed"}
{"id":"parquedb-3yy","title":"[RED] Collection class tests","description":"Write failing tests for Collection methods","status":"closed","priority":0,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:44.890748-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:02:35.488698-06:00","closed_at":"2026-02-01T14:02:35.488698-06:00","close_reason":"Closed"}
{"id":"parquedb-3zab","title":"Implement mutation layer per CLAUDE.md","description":"CLAUDE.md describes src/mutation/ for create/update/delete but this layer doesn't exist. Mutation logic is scattered in ParqueDBImpl and ParqueDBDO. Create mutation layer to centralize validation, authorization, and update logic using Command pattern.","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-01T15:47:20.435448-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T16:37:22.274223-06:00","closed_at":"2026-02-01T16:37:22.274223-06:00","close_reason":"Closed"}
{"id":"parquedb-3zc0","title":"Refactor: Storage - R2Backend.copy reads entire file into memory","description":"R2Backend.copy() at lines 554-591 reads the entire source file into memory before writing to destination:\\n\\n```typescript\\nasync copy(source: string, dest: string): Promise\u003cvoid\u003e {\\n  const sourceObj = await this.bucket.get(sourceKey, undefined)\\n  const data = new Uint8Array(await sourceObj.arrayBuffer())  // Entire file in memory!\\n  await this.bucket.put(destKey, data, ...)\\n}\\n```\\n\\nFor large files, this could cause memory issues. Consider:\\n- Using multipart upload for large files\\n- Streaming the data if possible\\n- Or documenting the size limitation\\n\\nNote: R2 does not currently support server-side copy, so client-side transfer may be necessary, but could use streaming.\\n\\nFiles affected:\\n- /Users/nathanclevenger/projects/parquedb/src/storage/R2Backend.ts","status":"open","priority":3,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:33:02.077617-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T06:33:02.077617-06:00"}
{"id":"parquedb-42ii","title":"Add logging to empty catch blocks","description":"20+ empty catch {} blocks silently swallow errors. Files include: indexes/manager.ts:684, client/service-binding.ts:225, storage/R2Backend.ts:848. Add debug logging or document intentionally ignored errors.","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-02T05:32:36.843432-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-02T06:47:24.049202-06:00","closed_at":"2026-02-02T06:47:24.049202-06:00","close_reason":"Closed"}
{"id":"parquedb-44g","title":"[GREEN] Event archival implementation","description":"Implement event archival to pass tests","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:47.02725-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:22:32.579636-06:00","closed_at":"2026-02-01T14:22:32.579636-06:00","close_reason":"Closed"}
{"id":"parquedb-450n","title":"Evaluate DataFusion-style embedded page indexes (ColumnIndex/OffsetIndex)","description":"## Context\nDataFusion and modern Parquet readers use page-level indexes embedded in row group footers:\n\n1. **ColumnIndex** - min/max per page (not just per row group)\n2. **OffsetIndex** - byte offsets for each page\n3. **Bloom filters** - embedded in row group metadata\n\nCurrently ParqueDB uses:\n- Row group level min/max (coarser granularity)\n- External bloom filter files (indexes/bloom/{ns}.bloom)\n- $index_* columns sorted for row group pruning\n\n## Benefits of DataFusion-style\n- Single file (no separate index files)\n- Page-level pruning (finer than row group)\n- Standard Parquet 2.0 format (better ecosystem compatibility)\n- Works with any Parquet reader that supports these features\n\n## Considerations\n- hyparquet support for ColumnIndex/OffsetIndex\n- hyparquet-writer support for writing page indexes\n- Migration path from external bloom files\n- Performance comparison needed\n\n## Tasks\n1. Check hyparquet support for Parquet 2.0 page indexes\n2. Benchmark page-level vs row-group-level pruning\n3. Decide on migration approach\n4. Implement if beneficial","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T03:59:11.623321-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T04:41:47.943643-06:00","closed_at":"2026-02-03T04:41:47.943643-06:00","close_reason":"Evaluation complete. hyparquet already has full page index support. See docs/architecture/PAGE_INDEXES_EVALUATION.md for detailed findings. Recommendation: ADOPT DataFusion-style page indexes - Phase 1 is trivial (enable columnIndex:true), Phase 2 uses existing parquetQuery()."}
{"id":"parquedb-45u","title":"Implement SQLite blob flush for events WAL","description":"Flush buffered events to DO SQLite as compressed blobs:\n\n```sql\nCREATE TABLE events_wal (\n  id INTEGER PRIMARY KEY,\n  batch BLOB,           -- msgpack array of events, up to 2MB\n  min_ts INTEGER,\n  max_ts INTEGER,\n  count INTEGER\n);\n```\n\n- Serialize events to msgpack/cbor\n- Write as single blob row (cost optimization)\n- Support reading back for replay\n\nFile: src/events/sqlite-wal.ts","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-01T06:37:51.319827-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T07:06:39.742045-06:00","closed_at":"2026-02-01T07:06:39.742045-06:00","close_reason":"Implemented SqliteWal class for storing event batches as blobs in SQLite. Features: batch serialization/deserialization, time-range queries, flush management, batch cleanup. Added 18 passing tests.","dependencies":[{"issue_id":"parquedb-45u","depends_on_id":"parquedb-zqk","type":"blocks","created_at":"2026-02-01T06:38:07.485861-06:00","created_by":"Nathan Clevenger"}]}
{"id":"parquedb-4bp","title":"[RED] Secondary index tests","description":"Write failing tests for index creation and query optimization","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:51.24896-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:24:36.703522-06:00","closed_at":"2026-02-01T14:24:36.703522-06:00","close_reason":"Secondary index tests written covering Hash and SST indexes including lookups, range queries, composite indexes, persistence, and IndexManager integration. All tests passing."}
{"id":"parquedb-4c9e","title":"Remove Collection.ts global state - use storage backend","description":"Collection.ts uses module-level global Maps (globalStorage, globalRelationships, globalEventLog) that bypass the storage backend abstraction. This creates multiple sources of truth. Should use ParqueDB/collection.ts which delegates to storage properly.","status":"closed","priority":0,"issue_type":"bug","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-02T05:32:30.238704-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-02T06:30:19.431419-06:00","closed_at":"2026-02-02T06:30:19.431419-06:00","close_reason":"Closed"}
{"id":"parquedb-4k7","title":"Implement R2Backend (Cloudflare R2)","description":"Storage backend for Cloudflare R2","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:51.7181-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:16:35.487701-06:00","closed_at":"2026-02-01T14:16:35.487701-06:00","close_reason":"R2Backend implementation complete. All 38 tests pass covering: read/write operations, atomic writes, byte range reads, exists/stat/list operations, delete operations (single and prefix), copy/move operations, append operations, directory operations, multipart uploads, streaming writes, and edge cases (special characters, binary data, nested paths). Exports enabled in src/storage/index.ts and src/index.ts."}
{"id":"parquedb-4pk3","title":"Fix catch blocks to use error: unknown","description":"30+ catch blocks use untyped 'catch (error)' despite useUnknownInCatchVariables: true in tsconfig.\n\nUpdate all catch blocks to: catch (error: unknown)\nAdd proper type narrowing with instanceof checks.","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-01T12:42:34.568255-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T12:54:07.444935-06:00","closed_at":"2026-02-01T12:54:07.444935-06:00","close_reason":"Completed by parallel agents"}
{"id":"parquedb-4rve","title":"REFACTOR: Add graceful 404 handling for missing parquet files","description":"## Problem\nWhen a parquet file is missing, the worker throws an unhandled exception causing Error 1101 (500).\n\nThis should return a proper 404 with a helpful error message instead of crashing.\n\n## Current behavior\n```\nError: File not found: onet-graph/occupations.parquet\n  at initializeAsyncBuffer (index.js:17951:11)\n  at async ParquetReader.read (index.js:18002:25)\n  at async QueryExecutor.find (index.js:18704:18)\n  at async handleCollectionList (index.js:20477:18)\n```\n\n## Expected behavior\n```json\n{\n  \"error\": true,\n  \"code\": \"FILE_NOT_FOUND\",\n  \"message\": \"Dataset file not found: onet-graph/occupations.parquet\",\n  \"hint\": \"This dataset may not be uploaded yet. Check R2 bucket contents.\"\n}\n```\nHTTP Status: 404\n\n## Changes needed\n1. Wrap parquet read in try/catch in QueryExecutor.find()\n2. Check if file exists before attempting to read\n3. Return proper 404 response from dataset handlers\n4. Add monitoring/alerting for missing dataset files\n\n## Prevents\n- Cryptic 1101 errors for users\n- Silent failures that go unnoticed\n- Better error messages for debugging","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T02:54:37.400154-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T03:23:26.813968-06:00","closed_at":"2026-02-03T03:23:26.813968-06:00","close_reason":"Closed","dependencies":[{"issue_id":"parquedb-4rve","depends_on_id":"parquedb-uqe4","type":"blocks","created_at":"2026-02-03T02:54:47.224423-06:00","created_by":"Nathan Clevenger"}]}
{"id":"parquedb-4t2","title":"[RED] Link/unlink tests","description":"Write failing tests for $link and $unlink operators","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:35.95815-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-02T04:45:59.327407-06:00","closed_at":"2026-02-02T04:45:59.327407-06:00","close_reason":"Tests implemented in earlier waves"}
{"id":"parquedb-4vyr","title":"Refactor: Query - Remove dead code in update.ts wrapper","description":"## Summary\nThe `src/query/update.ts` file is a thin wrapper around `src/mutation/operators.ts` but contains some redundant code.\n\n### Issues Found\n\n1. **Duplicate require() call** (line 108-109):\n   ```typescript\n   export function sortArray(...) {\n     const { compareValues } = require('../utils')\n   ```\n   This uses CommonJS require() inside a function despite compareValues already being imported at the top via ES6 imports (line 31). Should use the imported version.\n\n2. **Re-exported functions that could be direct re-exports** (lines 27-34):\n   ```typescript\n   export { getField, setField, unsetField } from '../mutation/operators'\n   export { compareValues, deepEqual } from '../utils'\n   export { matchesFilter } from './filter'\n   ```\n   These are fine, but combined with the wrapper functions, makes the module's purpose unclear.\n\n3. **sortArray and applySlice duplicated** (lines 108-149):\n   These are exact copies of functions in `src/mutation/operators.ts` (lines 519-554). Comment says 'for backwards compatibility' but both modules are internal.\n\n### Files to Update\n- `src/query/update.ts` - Clean up duplicates\n- Check for external usages before removing\n\n### Acceptance Criteria\n- [ ] Replace require() with import\n- [ ] Remove duplicate sortArray/applySlice if not used externally\n- [ ] Clarify module purpose in JSDoc\n- [ ] Add deprecation notice if functions should not be used directly","status":"open","priority":3,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:33:35.599123-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T06:33:35.599123-06:00","labels":["refactor"]}
{"id":"parquedb-56ls","title":"Refactor: Storage - validatePath and validateData are unused","description":"validation.ts exports validatePath and validateData functions that are never used:\\n\\n```typescript\\nexport function validatePath(path: string, operation: string): void {\\n  if (path === undefined || path === null) {\\n    throw new Error(\\`${operation}: path is required\\`)\\n  }\\n}\\n\\nexport function validateData(data: Uint8Array | null | undefined, operation: string): void {\\n  if (data === null || data === undefined) {\\n    throw new Error(\\`${operation}: data is required\\`)\\n  }\\n}\\n```\\n\\nOnly validateRange and validatePartNumber are actually imported and used by backends.\\n\\nRefactor to:\\n- Either remove unused functions\\n- Or add validation calls to all backend methods for consistency\\n- Consider if TypeScript's type checking makes these redundant\\n\\nFiles affected:\\n- /Users/nathanclevenger/projects/parquedb/src/storage/validation.ts","status":"open","priority":3,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:34:00.931069-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T06:34:00.931069-06:00"}
{"id":"parquedb-5ay","title":"[RED] Sorting tests","description":"Write failing tests for single and multi-field sorting","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:27.87617-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-02T04:45:59.583335-06:00","closed_at":"2026-02-02T04:45:59.583335-06:00","close_reason":"Tests implemented in earlier waves"}
{"id":"parquedb-5cm6","title":"Remove MockParqueDBDO, use vitest-pool-workers","description":"## Task\n\nRemove the MockSqlStorage and MockParqueDBDO from tests in favor of real DO testing via vitest-pool-workers.\n\n## Current State\n- `tests/unit/worker/ParqueDBDO.test.ts` has ~600 lines of mock code\n- Mocks can drift from real implementation\n- vitest-pool-workers provides real DO SQLite support\n\n## Changes\n1. Move DO tests to `tests/e2e/worker/` or keep in unit but use pool-workers\n2. Remove MockSqlStorage class\n3. Remove MockParqueDBDO class  \n4. Use real ParqueDBDO with real ctx.storage.sql\n5. Update vitest.workspace.ts if needed\n\n## Benefits\n- Tests match real behavior\n- Less code to maintain\n- Catch real SQLite edge cases","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:13:13.255853-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T07:11:30.215657-06:00","closed_at":"2026-02-03T07:11:30.215657-06:00","close_reason":"Implemented"}
{"id":"parquedb-5cn","title":"Implement time-travel queries","description":"Query entities as of a specific timestamp","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:38.846951-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:20:47.034689-06:00","closed_at":"2026-02-01T14:20:47.034689-06:00","close_reason":"Closed"}
{"id":"parquedb-5d0f","title":"Split worker/index.ts into modules","description":"worker/index.ts is 1500+ lines containing HTTP routing, response building, benchmark handlers, and business logic. Extract into: worker/routing.ts, worker/responses.ts, worker/benchmarks.ts","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-01T17:01:04.690231-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T17:24:44.548522-06:00","closed_at":"2026-02-01T17:24:44.548522-06:00","close_reason":"Closed"}
{"id":"parquedb-5eb","title":"[GREEN] IceType integration implementation","description":"Implement IceType integration to pass tests","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:52:08.693793-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:19:33.314581-06:00","closed_at":"2026-02-01T14:19:33.314581-06:00","close_reason":"Closed"}
{"id":"parquedb-5fk","title":"Implement create operations","description":"Create entities with validation and audit fields","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:13.460768-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:05:20.598416-06:00","closed_at":"2026-02-01T14:05:20.598416-06:00","close_reason":"Closed"}
{"id":"parquedb-5g35","title":"Refactor: Query - Unknown operators are silently ignored","description":"## Summary\nThe filter evaluation silently ignores unknown operators instead of throwing an error. This can lead to subtle bugs where filters don't work as expected.\n\n### Current Behavior\n\nIn `src/query/filter.ts` line 322-324:\n```typescript\ndefault:\n  // Unknown operator - ignore\n  break\n```\n\nAnd for primitives (line 95-97):\n```typescript\ndefault:\n  // Unknown operator for primitives - ignore\n  break\n```\n\n### Problem\nIf you typo an operator:\n```typescript\n{ score: { $gtr: 100 } }  // Typo: $gtr instead of $gt\n```\nThis silently matches everything since the unknown operator is ignored.\n\n### Proposed Solution\n\n1. **Strict mode** (opt-in):\n   ```typescript\n   matchesFilter(doc, filter, { strict: true })\n   // Throws on unknown operators\n   ```\n\n2. **Warning mode** (default):\n   ```typescript\n   // Log warning but continue\n   console.warn('Unknown filter operator: $gtr')\n   ```\n\n3. **Validation function**:\n   ```typescript\n   validateFilter(filter)  // Throws if invalid\n   ```\n\n### Files to Update\n- `src/query/filter.ts` - Add strict mode option\n- `src/types/options.ts` - Add FilterOptions type\n\n### Acceptance Criteria\n- [ ] Add strict mode option to matchesFilter\n- [ ] Add validateFilter() function\n- [ ] Add tests for unknown operator handling\n- [ ] Document strict mode in JSDoc","status":"open","priority":3,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:34:07.941444-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T06:34:07.941444-06:00","labels":["refactor"]}
{"id":"parquedb-5him","title":"Refactor: Storage - Add StreamableBackend implementation","description":"The StorageBackend interface defines StreamableBackend at lines 232-243 of types/storage.ts:\\n\\n```typescript\\nexport interface StreamableBackend extends StorageBackend {\\n  createReadStream(path: string, options?: StreamOptions): ReadableStream\u003cUint8Array\u003e\\n  createWriteStream(path: string, options?: WriteOptions): WritableStream\u003cUint8Array\u003e\\n}\\n```\\n\\nHowever, no backend currently implements this interface. This would be valuable for:\\n- Large file handling without loading entire file in memory\\n- Progressive reads for Parquet file parsing\\n- Efficient uploads/downloads\\n\\nConsider implementing StreamableBackend for:\\n- FsBackend using Node.js streams\\n- R2Backend using R2's streaming APIs\\n\\nFiles affected:\\n- /Users/nathanclevenger/projects/parquedb/src/storage/FsBackend.ts\\n- /Users/nathanclevenger/projects/parquedb/src/storage/R2Backend.ts\\n- /Users/nathanclevenger/projects/parquedb/src/types/storage.ts","status":"open","priority":3,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:33:18.874841-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T06:33:18.874841-06:00"}
{"id":"parquedb-5nov","title":"Refactor: Query - Add  operator support at field level","description":"## Summary\nThe filter system supports $not at the top level for negating entire sub-filters, but doesn't support field-level $not operator like MongoDB.\n\n### Current Behavior\nTop-level $not works (line 121-125):\n```typescript\n{ $not: { status: 'published' } }  // Works - negates entire filter\n```\n\nField-level $not doesn't work:\n```typescript\n{ status: { $not: { $regex: '^draft' } } }  // Not supported\n```\n\n### MongoDB Behavior\nMongoDB supports both:\n- Top-level: `{ $not: { ... } }`\n- Field-level: `{ field: { $not: { operator: value } } }`\n\nField-level is useful for negating specific operator results:\n```javascript\n// Find users whose name doesn't start with 'admin'\n{ name: { $not: { $regex: '^admin' } } }\n\n// Find items where score is NOT greater than 100\n{ score: { $not: { $gt: 100 } } }\n```\n\n### Files to Update\n- `src/types/filter.ts` - Add FieldNotOperator type\n- `src/query/filter.ts` - Add field-level $not evaluation\n- `src/query/builder.ts` - Add notWhere() method\n\n### Acceptance Criteria\n- [ ] Add $not to FieldOperator union type\n- [ ] Handle $not in evaluateOperators()\n- [ ] Add QueryBuilder support\n- [ ] Add comprehensive tests\n- [ ] Document difference from top-level $not","status":"open","priority":3,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:33:46.042525-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T06:33:46.042525-06:00","labels":["refactor"]}
{"id":"parquedb-60t","title":"[RED] Create operation tests","description":"Write failing tests for create, createMany with validation","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:15.052836-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:05:20.627398-06:00","closed_at":"2026-02-01T14:05:20.627398-06:00","close_reason":"Closed"}
{"id":"parquedb-63f","title":"Write: Getting Started Guide","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T12:40:28.321653-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:34:35.131018-06:00","closed_at":"2026-02-01T14:34:35.131018-06:00","close_reason":"Closed"}
{"id":"parquedb-63r","title":"[GREEN] FTS implementation","description":"Implement FTS to pass tests","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:55.798637-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:27:18.777573-06:00","closed_at":"2026-02-01T14:27:18.777573-06:00","close_reason":"Closed"}
{"id":"parquedb-69c","title":"Implement link/unlink operations","description":"$link and $unlink update operators","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:34.620458-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:06:34.629587-06:00","closed_at":"2026-02-01T14:06:34.629587-06:00","close_reason":"Closed"}
{"id":"parquedb-69ia","title":"Add error recovery tests","description":"error-recovery.test.ts exists but may not cover: partial write failures, network timeout recovery, corrupted file handling, storage backend failures mid-operation.","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-01T15:47:32.82806-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T16:07:37.150236-06:00","closed_at":"2026-02-01T16:07:37.150236-06:00","close_reason":"Closed"}
{"id":"parquedb-69mg","title":"Complete event sourcing implementation","description":"Events are logged but not the source of truth - entity state stored separately in SQLite. Implement true event sourcing: derive entity state from event replay, add event compaction with snapshots, add event versioning for schema evolution.","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-01T15:47:19.491236-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T16:51:21.99011-06:00","closed_at":"2026-02-01T16:51:21.99011-06:00","close_reason":"Closed"}
{"id":"parquedb-69um","title":"Implement compaction (events to state)","description":"Compact events into materialized state files:\n\n- Read events from SQLite WAL + R2 segments\n- Replay to build current state\n- Write new data.parquet + rels.parquet\n- Create snapshot: snapshots/{ts}/data.parquet, rels.parquet\n- Truncate compacted SQLite rows\n- Archive old event segments\n\nFile: src/events/compaction.ts","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-01T06:37:59.621527-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T07:17:15.096929-06:00","closed_at":"2026-02-01T07:17:15.096929-06:00","close_reason":"Implemented EventCompactor and StateCollector with entity/relationship state collection, multi-segment compaction, snapshot creation, segment deletion, and compactedThrough watermark. All 30 tests passing.","dependencies":[{"issue_id":"parquedb-69um","depends_on_id":"parquedb-czot","type":"blocks","created_at":"2026-02-01T06:38:11.128652-06:00","created_by":"Nathan Clevenger"}]}
{"id":"parquedb-6eob","title":"Make AWS SDK optional dependency","description":"@aws-sdk/client-s3 adds ~200KB to bundle. Not needed for R2/Workers-only deployments. Move to peer/optional dependency, lazy-load only when S3Backend is used.","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-01T15:47:23.024469-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T16:21:33.433995-06:00","closed_at":"2026-02-01T16:21:33.433995-06:00","close_reason":"Closed"}
{"id":"parquedb-6m2y","title":"Remove hash index infrastructure","description":"Remove the hash index infrastructure since native parquet predicate pushdown on $index_* columns is now faster than secondary indexes.\n\n**UPDATE: Scope expansion required**\n\nInvestigation revealed that hash indexes are deeply integrated throughout the codebase. A complete removal requires changes to:\n\n1. **Source files to delete:**\n   - src/indexes/secondary/hash.ts (710 lines)\n   - src/indexes/secondary/sharded-hash.ts (442 lines)\n   - src/indexes/secondary/sst.ts\n   - src/indexes/secondary/sharded-sst.ts\n\n2. **Source files to update:**\n   - src/indexes/secondary/index.ts (remove hash/sst exports)\n   - src/indexes/types.ts (remove 'hash'/'sst' from IndexType)\n   - src/indexes/manager.ts (remove hash selection logic, hashLookup, rangeQuery methods)\n   - src/worker/IndexCache.ts (remove HashIndex import, loadHashIndex, executeHashLookup, loadSSTIndex, executeSSTLookup)\n   - src/worker/QueryExecutor.ts (remove hash/sst cases in executeWithIndex)\n   - src/index.ts (remove HashIndex, SSTIndex exports)\n   - src/aggregation/executor.ts (remove hash/sst type handling)\n   - src/query/executor.ts (remove hash/sst type handling)\n   - src/worker/benchmark-queries.ts (extensive hash/sst references)\n   - Additional files with 'hash' type references\n\n3. **Test files to delete:**\n   - tests/unit/indexes/hash-index.test.ts\n   - tests/unit/indexes/sharded-index.test.ts\n   - tests/unit/indexes/unique-index.test.ts\n   - tests/integration/secondary-index.test.ts\n\n4. **Test files to update:**\n   - tests/unit/worker/IndexCache.test.ts\n   - tests/unit/error-recovery.test.ts\n\nThis is a significant refactoring effort (~2000+ lines of code changes) that should be done carefully to avoid breaking the build. Consider breaking into smaller sub-tasks.","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-02T11:06:06.904067-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-02T12:28:59.3718-06:00","closed_at":"2026-02-02T12:28:59.3718-06:00","close_reason":"Completed: Removed hash index infrastructure. Native parquet predicate pushdown on $index_* columns is now used for equality queries."}
{"id":"parquedb-6qy9","title":"Add Client RPC unit tests","description":"Client code minimally tested (5 files):\n- ParqueDBClient.ts\n- collection.ts\n- rpc-promise.ts\n- service-binding.ts\n\nCreate comprehensive tests for RPC client initialization, collection wrapper, and promise handling.","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-01T12:42:27.889158-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T13:07:24.689069-06:00","closed_at":"2026-02-01T13:07:24.689069-06:00","close_reason":"Completed by parallel agents"}
{"id":"parquedb-6rl","title":"[RED] Upsert tests","description":"Write failing tests for upsert behavior","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:37.403951-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-02T04:45:59.280656-06:00","closed_at":"2026-02-02T04:45:59.280656-06:00","close_reason":"Tests implemented in earlier waves"}
{"id":"parquedb-6sl","title":"Write: API Reference - ParqueDB class","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T12:40:31.875878-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:37:46.762347-06:00","closed_at":"2026-02-01T14:37:46.762347-06:00","close_reason":"Closed"}
{"id":"parquedb-70m","title":"[RED] R2Backend tests","description":"Write failing tests for R2Backend","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:52.537234-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-02T04:45:59.066322-06:00","closed_at":"2026-02-02T04:45:59.066322-06:00","close_reason":"Tests implemented in earlier waves"}
{"id":"parquedb-71j","title":"Query Engine","description":"MongoDB-style query and filter execution","status":"closed","priority":1,"issue_type":"epic","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:50:27.915343-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:34:08.794109-06:00","closed_at":"2026-02-01T14:34:08.794109-06:00","close_reason":"Closed"}
{"id":"parquedb-748","title":"Implement unique indexes","description":"Unique constraint enforcement","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:52:00.719845-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:32:47.12911-06:00","closed_at":"2026-02-01T14:32:47.12911-06:00","close_reason":"Unique indexes implemented with full TDD: 23 tests covering HashIndex and SSTIndex unique constraints, composite keys, sparse indexes"}
{"id":"parquedb-78x6","title":"Fix memory leak from global state","description":"Global Maps (globalEntityStore, globalEventStore, globalSnapshotStore, globalQueryStats) at ParqueDB.ts lines 442-485 are keyed by StorageBackend with no cleanup mechanism. Implement dispose() method or use WeakMap to prevent memory leaks in long-running processes.","status":"closed","priority":1,"issue_type":"bug","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-01T15:47:09.122977-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T15:51:01.980569-06:00","closed_at":"2026-02-01T15:51:01.980569-06:00","close_reason":"Closed"}
{"id":"parquedb-7az","title":"[GREEN] FsxBackend implementation","description":"Implement FsxBackend to pass tests","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:56.500179-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:15:29.808185-06:00","closed_at":"2026-02-01T14:15:29.808185-06:00","close_reason":"Closed"}
{"id":"parquedb-7ci6","title":"Add index awareness to aggregation $match","description":"Aggregation $match stages don't leverage secondary indexes. When $match is the first stage, it should use HashIndex for equality and SSTIndex for range queries like the regular find() does.","status":"closed","priority":1,"issue_type":"feature","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-01T17:01:06.944131-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T17:17:40.971405-06:00","closed_at":"2026-02-01T17:17:40.971405-06:00","close_reason":"Closed"}
{"id":"parquedb-7efk","title":"Wire IndexManager to actual index classes","description":"IndexManager methods hashLookup(), rangeQuery(), ftsSearch() throw 'not implemented'. Wire them to HashIndex, SSTIndex, FTSIndex classes that already exist. IndexCache in worker has separate implementation that should be unified.","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-02T05:32:39.761144-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T03:48:28.09996-06:00","closed_at":"2026-02-03T03:48:28.09996-06:00","close_reason":"Closed"}
{"id":"parquedb-7fy","title":"Implement FsxBackend (fsx for Workers)","description":"Storage backend using fsx for Cloudflare Workers","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:54.854849-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:15:29.623981-06:00","closed_at":"2026-02-01T14:15:29.623981-06:00","close_reason":"Closed"}
{"id":"parquedb-7hw","title":"[RED] Update operator tests - field operators","description":"Write failing tests for $set, $unset, $rename","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:20.532526-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:08:21.621781-06:00","closed_at":"2026-02-01T14:08:21.621781-06:00","close_reason":"Closed"}
{"id":"parquedb-7jin","title":"Add CLI tools","description":"No CLI for database management. Create parquedb CLI with commands: init, migrate, query, import, export, stats, compact.","status":"closed","priority":2,"issue_type":"feature","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-01T15:47:47.409366-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T16:41:29.609431-06:00","closed_at":"2026-02-01T16:41:29.609431-06:00","close_reason":"Closed"}
{"id":"parquedb-7kf","title":"[GREEN] R2Backend implementation","description":"Implement R2Backend to pass tests","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:53.393854-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:16:38.548554-06:00","closed_at":"2026-02-01T14:16:38.548554-06:00","close_reason":"R2Backend implementation complete. GREEN phase achieved - all 38 integration tests pass against real R2/S3-compatible storage."}
{"id":"parquedb-7km1","title":"Fix 19 TypeScript compilation errors","description":"npx tsc --noEmit reports 19 errors: (1) File casing conflict Collection.ts vs collection.ts in query/builder.ts import, (2) 14 errors in mutation/index.ts - need 'export type' for type-only exports, (3) Undefined checks needed in aggregation/executor.ts:367, (4) Missing function argument in mutation/executor.ts:440, (5) EntityId type mismatch in mutation/operators.ts:265,284","status":"closed","priority":0,"issue_type":"bug","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-01T17:00:48.308236-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T17:03:08.122449-06:00","closed_at":"2026-02-01T17:03:08.122449-06:00","close_reason":"Closed"}
{"id":"parquedb-7nn","title":"[GREEN] Time-travel query implementation","description":"Implement time-travel via event replay","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:40.233009-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:20:45.356534-06:00","closed_at":"2026-02-01T14:20:45.356534-06:00","close_reason":"Closed"}
{"id":"parquedb-7tx","title":"[RED] Populate tests","description":"Write failing tests for populating related entities","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:41.764943-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-02T04:45:59.219177-06:00","closed_at":"2026-02-02T04:45:59.219177-06:00","close_reason":"Tests implemented in earlier waves"}
{"id":"parquedb-7ypb","title":"Consolidate duplicate getNestedValue implementations","description":"getNestedValue function is duplicated in: utils/comparison.ts:156-174, indexes/secondary/hash.ts:467-478, indexes/secondary/sst.ts:495-506. Use canonical implementation from utils/comparison.ts everywhere.","status":"closed","priority":3,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-02T05:32:48.286665-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-02T06:32:50.267928-06:00","closed_at":"2026-02-02T06:32:50.267928-06:00","close_reason":"Closed"}
{"id":"parquedb-819m","title":"Refactor: Storage - FsxBackend uses generic Error instead of typed errors","description":"FsxBackend throws generic Error instances instead of using typed error classes:\\n\\nAt lines 274-277 and 284-299:\\n```typescript\\nif (options?.ifNoneMatch === '*') {\\n  const fileExists = await this.fsx.exists(fullPath)\\n  if (fileExists) {\\n    throw new Error('File already exists')  // Should be FileExistsError\\n  }\\n}\\n...\\nthrow new Error('Version mismatch: file exists but expected it not to')  // Should be VersionMismatchError\\nthrow new Error(\\`Version mismatch: expected ${expectedVersion}, got ${stats.etag}\\`)  // Should be VersionMismatchError\\n```\\n\\nRefactor to:\\n- Import and use typed error classes (FileExistsError, VersionMismatchError)\\n- Ensure consistent error handling with other backends\\n- Add proper error mapping from FsxError to typed errors\\n\\nFiles affected:\\n- /Users/nathanclevenger/projects/parquedb/src/storage/FsxBackend.ts","status":"open","priority":3,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:32:54.897938-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T06:32:54.897938-06:00"}
{"id":"parquedb-838h","title":"Remove dangerous new Function() in RPC legacy deserializer","description":"The deserializeLegacyFunction() in src/client/rpc-promise.ts:575-600 uses new Function() which is a code injection risk. Either remove the legacy mapper type entirely or replace with capnweb RPC.do. Critical security issue.","status":"closed","priority":0,"issue_type":"bug","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-02T05:32:27.838601-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-02T06:30:19.428971-06:00","closed_at":"2026-02-02T06:30:19.428971-06:00","close_reason":"Closed"}
{"id":"parquedb-84xq","title":"Refactor ParqueDB.ts into smaller classes","description":"ParqueDB.ts is 3,680 lines - should be 300-500. Extract into:\n- EntityManager - handle entity CRUD\n- RelationshipManager - handle relationships\n- SnapshotManager - handle snapshots\n- EventManager - handle event log\nKeep ParqueDB as orchestrator.","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-01T12:42:17.335174-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:39:45.726096-06:00","closed_at":"2026-02-01T14:39:45.726096-06:00","close_reason":"Deferred: File is large (3749 lines) but internally well-organized with clear section comments. Shared state is deeply intertwined (44+ references across entities, events, snapshots, storage). Extracting 4 managers with proper coordination is not minimal/backwards-compatible. 32+ importing files and 80+ tests make this high-risk. Existing src/events/ module unused - future refactor should integrate. Recommend as future milestone with proper planning."}
{"id":"parquedb-8aar","title":"Add streaming support to migration utilities","description":"Migration utilities load entire files into memory. Add streaming support for large file imports using Node.js streams or async iterators to handle files larger than available memory.","status":"closed","priority":2,"issue_type":"feature","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-01T17:01:06.316852-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-02T04:43:33.83976-06:00","closed_at":"2026-02-02T04:43:33.83976-06:00","close_reason":"Completed by agents"}
{"id":"parquedb-8c4","title":"[RED] Filter evaluation tests - comparison operators","description":"Write failing tests for $eq, $ne, $gt, $gte, $lt, $lte, $in, $nin","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:05.906217-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T13:13:07.40126-06:00","closed_at":"2026-02-01T13:13:07.40126-06:00","close_reason":"Closed"}
{"id":"parquedb-8gi","title":"Benchmark: Node.js FsBackend disk I/O","status":"closed","priority":0,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T15:47:12.48-06:00","created_by":"Nathan Clevenger","updated_at":"2026-01-30T16:05:02.067935-06:00","closed_at":"2026-01-30T16:05:02.067935-06:00","close_reason":"FsBackend Disk I/O Benchmarks completed. Key results: Cold reads ~200-550ms depending on file size, metadata reads ~1.5ms p50, byte-range reads sub-millisecond, column projection shows 4x improvement when reading fewer columns. Standalone benchmark script created at tests/benchmarks/run-fs-benchmark.ts for accurate disk I/O measurement."}
{"id":"parquedb-8gmd","title":"Refactor: Worker - QueryExecutor._extractIdFilter and _fileSizeCache are public but unused","description":"QueryExecutor has several public members prefixed with underscore that appear to be internal or reserved:\n\n1. _extractIdFilter() - documented as '@internal Reserved for compatibility'\n2. _fileSizeCache - commented as 'reserved for future optimization'\n3. _MAX_CACHE_SIZE_LIMIT - 'reserved for future size limits'\n4. _bucket, _cdnBucket, _r2DevUrl - constructor params exposed\n\nFiles:\n- src/worker/QueryExecutor.ts\n\nThese suggest:\n1. Internal methods that shouldn't be public\n2. Future features that aren't implemented\n3. Debug/test exposure of private state\n\nRefactor:\n- Make truly internal methods private\n- Remove reserved fields until needed\n- If public exposure needed for testing, use a dedicated test interface\n\nImpact: Cleaner public API, clearer intent","status":"open","priority":3,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:34:16.441342-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T06:34:16.441342-06:00"}
{"id":"parquedb-8he4","title":"Define ParqueDBDOStub interface for DO RPC casts","description":"worker/index.ts has 8 identical 'as unknown as { method(...) }' casts for DO RPC calls. Define a ParqueDBDOStub interface describing the RPC surface and cast once.","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-02T07:16:02.623685-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T03:38:49.548908-06:00","closed_at":"2026-02-03T03:38:49.548908-06:00","close_reason":"Closed"}
{"id":"parquedb-8jm","title":"[REFACTOR] Schema parsing cleanup","description":"Refactor schema parsing","status":"closed","priority":0,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:52:00.445618-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T13:16:31.069574-06:00","closed_at":"2026-02-01T13:16:31.069574-06:00","close_reason":"Closed"}
{"id":"parquedb-8p4","title":"[RED] upsertMany tests","description":"Write failing tests for Collection.upsertMany(). Bulk upsert with conflict handling for loading large datasets.","status":"closed","priority":0,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T14:30:03.690734-06:00","created_by":"Nathan Clevenger","updated_at":"2026-01-30T14:32:17.069864-06:00","closed_at":"2026-01-30T14:32:17.069864-06:00","close_reason":"Closed"}
{"id":"parquedb-8sg","title":"[GREEN] Unique index implementation","description":"Implement unique indexes to pass tests","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:52:03.275538-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:32:42.825176-06:00","closed_at":"2026-02-01T14:32:42.825176-06:00","close_reason":"GREEN phase complete: Implemented unique constraint enforcement in HashIndex and SSTIndex with UniqueConstraintError, checkUnique method, and sparse index support"}
{"id":"parquedb-8t8","title":"[REFACTOR] Create operation cleanup","description":"Refactor create operations","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:17.816875-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:05:20.687407-06:00","closed_at":"2026-02-01T14:05:20.687407-06:00","close_reason":"Closed"}
{"id":"parquedb-8ybw","title":"Create constants file for magic numbers","description":"Magic numbers scattered throughout code:\n- FNV_OFFSET_BASIS = 2166136261 (encoding.ts, key-encoder.ts)\n- FNV_PRIME = 16777619\n- MAX_CACHE_SIZE = 2*1024*1024 (QueryExecutor.ts - defined twice!)\n- DEFAULT_BLOOM_SIZE = 131072\n- INDEX_PROGRESS_BATCH = 10000\n\nCreate /src/constants.ts and update all references.","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-01T12:42:20.011954-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T12:54:07.355568-06:00","closed_at":"2026-02-01T12:54:07.355568-06:00","close_reason":"Completed by parallel agents"}
{"id":"parquedb-90nf","title":"Replace SimpleDB with real ParqueDB in tests","description":"crud-workflow.test.ts implements a simplified SimpleDB class (lines 28-223) instead of using real ParqueDB. This tests a mock, not actual implementation. Replace with ParqueDB + MemoryBackend to catch real bugs.","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-01T15:47:30.879905-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T16:06:29.267331-06:00","closed_at":"2026-02-01T16:06:29.267331-06:00","close_reason":"Closed"}
{"id":"parquedb-955","title":"[RED] Relationship reading tests","description":"Write failing tests for reading outbound and inbound relationships","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:30.166354-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-02T04:45:59.528318-06:00","closed_at":"2026-02-02T04:45:59.528318-06:00","close_reason":"Tests implemented in earlier waves"}
{"id":"parquedb-96o","title":"Benchmark: Node.js to remote R2Backend","status":"closed","priority":0,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T15:47:13.440909-06:00","created_by":"Nathan Clevenger","updated_at":"2026-01-30T16:03:05.711796-06:00","closed_at":"2026-01-30T16:03:05.711796-06:00","close_reason":"Completed R2 remote benchmark from Node.js to Cloudflare R2.\n\n## Benchmark Results\n\n### Test Environment\n- Location: Node.js on macOS\n- Target: Cloudflare R2 (parquedb bucket)\n- Protocol: S3-compatible API via @aws-sdk/client-s3\n\n### Single File Read Latency\n| Size | Avg | P50 | P95 |\n|------|-----|-----|-----|\n| 1KB | 171ms | 171ms | 196ms |\n| 64KB | 176ms | 191ms | 227ms |\n| 1MB | 232ms | 173ms | 608ms |\n| 8MB | 559ms | 508ms | 970ms |\n\n### Range Read Latency (Parquet Row Groups)\n| Range | Avg | P50 | P95 |\n|-------|-----|-----|-----|\n| footer (8 bytes) | 145ms | 118ms | 227ms |\n| metadata (4KB) | 125ms | 109ms | 194ms |\n| row group 64KB | 140ms | 129ms | 205ms |\n| row group 512KB | 157ms | 138ms | 218ms |\n| middle 1MB | 258ms | 251ms | 318ms |\n\n### List Operations\n| Files | Avg | P50 | P95 |\n|-------|-----|-----|-----|\n| 10 | 129ms | 129ms | 161ms |\n| 50 | 136ms | 124ms | 193ms |\n| 100 | 163ms | 125ms | 413ms |\n\n### HEAD Operations\nAverage: ~121ms (file size independent)\n\n### Concurrent Operations\n| Concurrency | Total | Avg/File |\n|-------------|-------|----------|\n| 5 | 200ms | 40ms |\n| 10 | 224ms | 22ms |\n| 20 | 250ms | 13ms |\n\n## Key Findings\n1. **Base latency**: ~100-120ms for any R2 operation (network RTT)\n2. **Throughput scales**: Concurrent reads show near-linear scaling\n3. **Range reads efficient**: Small range reads (footer, metadata) add minimal overhead over HEAD\n4. **File size impact**: Only significant for files \u003e1MB\n\n## Benchmark File\ntests/benchmarks/r2-remote.bench.ts updated with:\n- dotenv loading for credentials\n- Correct default bucket (parquedb)\n- Comprehensive test coverage\n\nRun with: npx vitest bench tests/benchmarks/r2-remote.bench.ts"}
{"id":"parquedb-9bq3","title":"Add override modifier to error classes","description":"Custom error classes in src/indexes/errors.ts need override modifier for name property per noImplicitOverride. Change 'readonly name = ...' to 'override readonly name = ...' for UniqueConstraintError and other custom errors.","status":"closed","priority":2,"issue_type":"bug","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-01T15:47:40.037332-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T16:19:02.846284-06:00","closed_at":"2026-02-01T16:19:02.846284-06:00","close_reason":"Closed"}
{"id":"parquedb-9f1","title":"[RED] Real R2Backend tests","description":"Write failing tests for R2Backend using real R2 bucket. Use .env S3-compat creds from Node, real bindings in Workers.","status":"closed","priority":0,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T14:30:00.346069-06:00","created_by":"Nathan Clevenger","updated_at":"2026-01-30T14:37:13.832826-06:00","closed_at":"2026-01-30T14:37:13.832826-06:00","close_reason":"Closed"}
{"id":"parquedb-9fmv","title":"Add runtime validation at JSON deserialization boundaries","description":"After safeJsonParse(), code casts directly to IndexCatalog, ShardedIndexManifest etc without shape validation. Add type guard validators for critical JSON boundaries: IndexCache.ts:396, indexes/manager.ts, config/dataset.ts.","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-02T07:16:02.822365-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-02T07:21:13.721116-06:00","closed_at":"2026-02-02T07:21:13.721116-06:00","close_reason":"Closed"}
{"id":"parquedb-9m6","title":"[GREEN] FsBackend implementation","description":"Implement FsBackend to pass tests","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:49.898757-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:12:35.939821-06:00","closed_at":"2026-02-01T14:12:35.939821-06:00","close_reason":"Closed"}
{"id":"parquedb-9wl","title":"[GREEN] Filter string/array operators","description":"Implement string/array operators to pass tests","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:11.161543-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:03:47.588138-06:00","closed_at":"2026-02-01T14:03:47.588138-06:00","close_reason":"Closed"}
{"id":"parquedb-a2hc","title":"Add runtime validation for JSON parsing","description":"Several places cast parsed JSON without validation (e.g., ParqueDBDO.ts: JSON.parse(current.data) as Record\u003cstring, unknown\u003e). Add runtime validation for untrusted data or use Zod/similar.","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-01T15:47:43.646831-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T16:27:32.158586-06:00","closed_at":"2026-02-01T16:27:32.158586-06:00","close_reason":"Closed"}
{"id":"parquedb-a4tk","title":"Fix R2Backend.append() race condition","description":"R2Backend.ts append() reads existing object, concatenates, writes back without locking. Concurrent appends cause lost updates. Use R2 conditional writes (onlyIf: { etagMatches }) and retry.","status":"closed","priority":1,"issue_type":"bug","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-02T07:16:01.965394-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-02T07:21:35.739209-06:00","closed_at":"2026-02-02T07:21:35.739209-06:00","close_reason":"Closed"}
{"id":"parquedb-a817","title":"Extract hydration logic in ParqueDB.ts","description":"The get() method in ParqueDB.ts (lines 984-1241) contains nearly identical hydration blocks repeated twice for maxInbound and hydrate options. Extract into a private hydrateEntity() method to reduce duplication and bug risk.","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-01T15:47:07.953143-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T15:51:16.894957-06:00","closed_at":"2026-02-01T15:51:16.894957-06:00","close_reason":"Closed"}
{"id":"parquedb-ac1","title":"Update GraphDL/IceType integration for v0.3/v0.2","description":"Update integration tests and usage for @graphdl/core@0.3.0, @icetype/core@0.2.0, @icetype/iceberg@0.2.0. Use new unified API.","status":"closed","priority":0,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T14:30:53.852203-06:00","created_by":"Nathan Clevenger","updated_at":"2026-01-30T14:38:25.243872-06:00","closed_at":"2026-01-30T14:38:25.243872-06:00","close_reason":"Closed"}
{"id":"parquedb-aeb5","title":"Fix prototype pollution risk in $set operator","description":"The $set operator with dot notation in ParqueDB.ts (lines 1410-1430) does not sanitize field names. Paths like '__proto__.polluted' or 'constructor.prototype.x' could lead to prototype pollution. Add validation to exclude reserved object properties.","status":"closed","priority":0,"issue_type":"bug","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-01T17:00:46.915388-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T17:06:57.383299-06:00","closed_at":"2026-02-01T17:06:57.383299-06:00","close_reason":"Closed"}
{"id":"parquedb-aewx","title":"Refactor: Storage - FsxBackend list() does not use cursor for pagination","description":"FsxBackend.list() at lines 119-184 implements incomplete pagination:\\n\\n```typescript\\nconst allFiles = await this.fsx.glob(pattern, {})\\n\\nconst limit = options?.limit\\nlet files: string[]\\n\\nif (limit) {\\n  files = allFiles.slice(0, limit)\\n  hasMore = allFiles.length \u003e limit\\n  if (hasMore) {\\n    cursor = btoa(JSON.stringify({ offset: limit }))  // Creates cursor\\n  }\\n}\\n```\\n\\nIssues:\\n1. Cursor is generated but never consumed - the function ignores options?.cursor\\n2. Always fetches ALL files via glob, then slices - inefficient for large directories\\n3. Pattern creates cursor encoding but second call ignores it\\n\\nRefactor to:\\n- Parse and use the cursor on subsequent calls\\n- Consider more efficient glob patterns or caching\\n\\nFiles affected:\\n- /Users/nathanclevenger/projects/parquedb/src/storage/FsxBackend.ts","status":"open","priority":3,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:33:35.548468-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T06:33:35.548468-06:00"}
{"id":"parquedb-ahjh","title":"Indexed queries still scan 400K+ rows: row group skip not effective","description":"Hash index lookup for titleType=movie returns 400K docIds across all 20 row groups. Since all row groups contain 'movie' entries, no row groups are skipped. The index narrows the candidate set but still reads all rows from targeted row groups. For low-selectivity filters (40% of data), the index adds overhead (352ms lookup) without reducing I/O. Need: (1) investigate if -based filtering within row groups can use pushdown, (2) consider returning early if selectivity is too low, (3) benchmark high-selectivity queries separately.","status":"closed","priority":1,"issue_type":"bug","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-02T08:27:41.413158-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-02T08:38:25.485572-06:00","closed_at":"2026-02-02T08:38:25.485572-06:00","close_reason":"Closed"}
{"id":"parquedb-ahw","title":"[RED] Vector index tests","description":"Write failing tests for vector indexing and $near queries","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:59.037193-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:30:37.067608-06:00","closed_at":"2026-02-01T14:30:37.067608-06:00","close_reason":"Created vector index tests in tests/unit/indexes/vector-index.test.ts with 29 comprehensive tests covering basic operations, distance metrics, CRUD operations, persistence, and HNSW parameters"}
{"id":"parquedb-ai8o","title":"[SECURITY] Replace Math.random() with crypto.randomUUID()","description":"ID generation uses Math.random() which is not cryptographically secure. Replace with crypto.randomUUID() or crypto.getRandomValues() for all ID generation.\n\nLocations to fix:\n- src/utils/id.ts (if present)\n- Any direct Math.random() calls for IDs\n- Consider using ULID library consistently","status":"closed","priority":0,"issue_type":"bug","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-01T13:35:44.02468-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T13:40:50.136048-06:00","closed_at":"2026-02-01T13:40:50.136048-06:00","close_reason":"Closed"}
{"id":"parquedb-aio","title":"Implement ParqueDB class with Proxy","description":"Core ParqueDB class with Proxy-based collection access (db.Posts.find())","status":"closed","priority":0,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:26.437509-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:03:00.535157-06:00","closed_at":"2026-02-01T14:03:00.535157-06:00","close_reason":"Closed","dependencies":[{"issue_id":"parquedb-aio","depends_on_id":"parquedb-atd","type":"blocks","created_at":"2026-01-30T11:51:35.312493-06:00","created_by":"Nathan Clevenger"},{"issue_id":"parquedb-aio","depends_on_id":"parquedb-ho9","type":"blocks","created_at":"2026-01-30T11:51:35.398051-06:00","created_by":"Nathan Clevenger"},{"issue_id":"parquedb-aio","depends_on_id":"parquedb-2kk","type":"blocks","created_at":"2026-01-30T11:51:35.483361-06:00","created_by":"Nathan Clevenger"}]}
{"id":"parquedb-an4","title":"Implement event archival","description":"Archive old events by time period","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:44.276134-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:22:33.603114-06:00","closed_at":"2026-02-01T14:22:33.603114-06:00","close_reason":"Closed"}
{"id":"parquedb-aoz","title":"[RED] IceType integration tests","description":"Write failing tests for fromIceType() conversion","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:52:07.959893-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-02T04:45:58.836788-06:00","closed_at":"2026-02-02T04:45:58.836788-06:00","close_reason":"Tests implemented in earlier waves"}
{"id":"parquedb-apv","title":"Implement field projection","description":"Include/exclude fields from query results","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:23.767362-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:15:30.559615-06:00","closed_at":"2026-02-01T14:15:30.559615-06:00","close_reason":"Closed"}
{"id":"parquedb-atar","title":"Replace as any casts with proper types","description":"80+ 'as any' casts found bypassing TypeScript type checking:\n- ParqueDB.ts:749,914-1156 - entity field access\n- types/integrations.ts:182-197 - external schema objects\n- worker/index.ts:846,854,862,919 - R2 bucket casts\n- parquet/writer.ts:440 - element type casting\n\nCreate utility type for dynamic entity access. Use type guards instead of unsafe casts.","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-01T12:42:15.770568-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T13:18:47.813668-06:00","closed_at":"2026-02-01T13:18:47.813668-06:00","close_reason":"Closed"}
{"id":"parquedb-atd","title":"[RED] ParqueDB class tests","description":"Write failing tests for ParqueDB Proxy pattern and collection access","status":"closed","priority":0,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:30.133623-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:02:56.285861-06:00","closed_at":"2026-02-01T14:02:56.285861-06:00","close_reason":"Closed"}
{"id":"parquedb-att","title":"[RED] Delete operation tests","description":"Write failing tests for delete, deleteMany, destroy, restore","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:35.126823-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-02T04:45:59.370873-06:00","closed_at":"2026-02-02T04:45:59.370873-06:00","close_reason":"Tests implemented in earlier waves"}
{"id":"parquedb-awde","title":"Refactor: Storage - DOSqliteBackend.list includeMetadata does N+1 queries","description":"DOSqliteBackend.list() at lines 368-378 has an N+1 query problem:\\n\\n```typescript\\n// Include metadata if requested\\nif (options?.includeMetadata) {\\n  const stats: FileStat[] = []\\n  for (const file of files) {\\n    const stat = await this.stat(file)  // Individual query per file\\!\\n    if (stat) {\\n      stats.push(stat)\\n    }\\n  }\\n  listResult.stats = stats\\n}\\n```\\n\\nThe main query already selects all needed columns but excludes 'data'. Instead of calling stat() N times, the code should:\\n- Use the results already fetched in the main query\\n- Transform result.results directly to FileStat array\\n\\nThis is also a problem in FsxBackend.list() at lines 172-181.\\n\\nFiles affected:\\n- /Users/nathanclevenger/projects/parquedb/src/storage/DOSqliteBackend.ts\\n- /Users/nathanclevenger/projects/parquedb/src/storage/FsxBackend.ts","status":"open","priority":3,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:33:44.599324-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T06:33:44.599324-06:00"}
{"id":"parquedb-ay0r","title":"Add tests for worker HTTP handlers","description":"worker/handlers/ (datasets, entity, relationships, ns, debug, health, root) totaling 752 lines have zero test coverage. Add integration tests with mock request/response pairs. Also test routing.ts path matching and responses.ts.","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-02T07:16:03.188839-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-02T07:24:02.792132-06:00","closed_at":"2026-02-02T07:24:02.792132-06:00","close_reason":"Closed"}
{"id":"parquedb-azlw","title":"DO WAL: Phase 3 - Remove entity table","description":"## TDD Task: Remove entities table, derive state from WAL\n\n### Context\nThe `entities` table duplicates data. Entity state should be derived from events (event sourcing).\n\n### Red (Write failing tests first)\n1. Test entity state reconstructed from events\n2. Test reads work without entities table\n3. Test updates apply to event log only\n4. Test deletes are soft (tombstone event)\n\n### Green (Implement)\n1. Remove INSERT/UPDATE to entities table\n2. Add event replay for entity state\n3. Cache recent entities in memory (LRU)\n4. Update get/find to use cache + events + R2\n\n### Refactor\n- Migration path: read from entities if exists, then events\n- Eventually drop entities table\n\n### Files\n- `src/worker/ParqueDBDO.ts` - remove entity writes\n- `src/worker/EntityCache.ts` - new LRU cache","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:07:35.868013-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T06:54:24.891978-06:00","closed_at":"2026-02-03T06:54:24.891978-06:00","close_reason":"Closed","dependencies":[{"issue_id":"parquedb-azlw","depends_on_id":"parquedb-vq7i","type":"blocks","created_at":"2026-02-03T06:07:44.884396-06:00","created_by":"Nathan Clevenger"}]}
{"id":"parquedb-b1tn","title":"Complete sharded index test coverage","description":"Sharded indexes recently added with skeleton tests:\n- sharded-hash.ts - needs comprehensive tests\n- sharded-sst.ts - needs comprehensive tests\n- v3 compact format support needs validation\n\nAdd tests for all shard operations, edge cases, and format compatibility.","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-01T12:42:46.084372-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T12:54:07.473876-06:00","closed_at":"2026-02-01T12:54:07.473876-06:00","close_reason":"Completed by parallel agents"}
{"id":"parquedb-b445","title":"Standardize input validation across backends","description":"R2Backend validates range parameters (134-150) but MemoryBackend silently handles invalid ranges differently. Standardize validation across all storage backends.","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-01T15:47:15.224257-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T16:16:38.705048-06:00","closed_at":"2026-02-01T16:16:38.705048-06:00","close_reason":"Closed"}
{"id":"parquedb-b603","title":"Refactor: ParqueDB.ts - Remove dead stub methods after Proxy delegation","description":"In src/ParqueDB.ts, lines 250-535 contain stub method implementations that throw 'Not implemented' errors. These methods are never called because the Proxy handler intercepts all method calls and delegates to ParqueDBImpl.\n\nThe stubs exist for TypeScript type inference but could be replaced with a cleaner approach:\n1. Use a type interface for ParqueDB that describes the API\n2. Remove the dead stub methods\n3. Document that ParqueDB uses Proxy delegation\n\nFiles affected:\n- src/ParqueDB.ts (lines 246-536)\n\nThis reduces ~290 lines of dead code that may confuse developers who don't understand the Proxy pattern.","status":"closed","priority":3,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:32:33.573255-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T06:55:48.018247-06:00","closed_at":"2026-02-03T06:55:48.018247-06:00","close_reason":"Implemented by agents","labels":["dead-code","refactor"]}
{"id":"parquedb-bfvt","title":"Refactor: core.ts - Extract sorting logic into reusable utility","description":"In src/ParqueDB/core.ts, sorting logic is duplicated across methods with slight variations:\n\n1. find() lines 256-278 - Handles nulls last, uses compareValues utility\n2. getRelated() lines 569-594 - Different null handling, manual type-specific comparisons\n3. reconstructEntityAtTime() lines 1667-1671 - Sorts by timestamp and ID\n\nThe getRelated() sorting implementation is inconsistent with find() - it handles null/undefined differently and doesn't use the compareValues utility.\n\nSuggested refactor:\n1. Create a generic sortEntities(items, sortSpec, options?) utility in src/query/sort.ts\n2. Options could include { nullsLast: boolean, caseInsensitive: boolean }\n3. Reuse across all methods that need sorting\n\nThis improves consistency and reduces ~50 lines of duplicated sorting logic.","status":"open","priority":3,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:32:56.890456-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T06:32:56.890456-06:00","labels":["consistency","duplication","refactor"]}
{"id":"parquedb-bh1","title":"[RED] Time-travel query tests","description":"Write failing tests for asOf option in find/get","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:39.570046-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:20:43.169168-06:00","closed_at":"2026-02-01T14:20:43.169168-06:00","close_reason":"Closed"}
{"id":"parquedb-bon","title":"E2E: Node.js client to deployed Worker benchmarks","description":"Deploy ParqueDB Worker and benchmark Node.js client calling remote RpcTarget via capnweb. Measure real network latency from local machine to Cloudflare edge.","status":"closed","priority":0,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T15:58:33.108309-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T13:13:03.458067-06:00","closed_at":"2026-02-01T13:13:03.458067-06:00","close_reason":"Closed"}
{"id":"parquedb-breb","title":"[TS] Remove remaining any types in parquet/reader.ts","description":"8 'any' types remain in src/parquet/reader.ts. These should be replaced with proper types:\n\n- Use hyparquet types where available\n- Create interfaces for Parquet metadata structures\n- Use unknown with type guards where necessary\n- Consider contributing types upstream to @types/hyparquet","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-01T13:35:59.546383-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T13:38:42.256702-06:00","closed_at":"2026-02-01T13:38:42.256702-06:00","close_reason":"Closed"}
{"id":"parquedb-bu2f","title":"Stabilize Cloudflare Workers integration","description":"Workers pool tests fail with isolated storage errors. R2Backend and Durable Object integration needs stabilization for production use. This is the core value proposition - must work reliably.","status":"closed","priority":0,"issue_type":"bug","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-01T15:47:42.460528-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T16:31:40.844071-06:00","closed_at":"2026-02-01T16:31:40.844071-06:00","close_reason":"Closed"}
{"id":"parquedb-bu85","title":"Fix circular dependencies in types","description":"3 circular dependencies found: types/index.ts \u003e types/options.ts, types/index.ts \u003e types/update.ts, client/collection.ts \u003e client/rpc-promise.ts. Fix by changing imports to use direct file imports instead of re-export index.","status":"closed","priority":2,"issue_type":"bug","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-01T15:47:41.350149-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T16:06:52.721214-06:00","closed_at":"2026-02-01T16:06:52.721214-06:00","close_reason":"Closed"}
{"id":"parquedb-buh","title":"Implement populate (hydration)","description":"Fetch related entities in find/get operations","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:40.335294-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:14:51.646112-06:00","closed_at":"2026-02-01T14:14:51.646112-06:00","close_reason":"Closed"}
{"id":"parquedb-bxl","title":"[REFACTOR] Relationship storage cleanup","description":"Optimize relationship storage","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:25.321855-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:08:29.242218-06:00","closed_at":"2026-02-01T14:08:29.242218-06:00","close_reason":"Closed"}
{"id":"parquedb-byc","title":"[RED] Schema parsing tests","description":"Write failing tests for parseFieldType, parseRelation, schema validation","status":"closed","priority":0,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:58.922648-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T13:16:30.807713-06:00","closed_at":"2026-02-01T13:16:30.807713-06:00","close_reason":"Closed"}
{"id":"parquedb-c0cg","title":"Add 'Why ParqueDB?' section to README","description":"README lacks compelling comparison to alternatives. Add section explaining: why not DuckDB (no Workers), why not SQLite (no columnar), why not MongoDB (no edge). Include the excellent benchmark numbers.","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-01T17:01:10.292212-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T17:18:59.574692-06:00","closed_at":"2026-02-01T17:18:59.574692-06:00","close_reason":"Closed"}
{"id":"parquedb-c1m","title":"[GREEN] Entity history implementation","description":"Implement history() to pass tests","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:43.396415-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:20:12.677312-06:00","closed_at":"2026-02-01T14:20:12.677312-06:00","close_reason":"Closed"}
{"id":"parquedb-cay","title":"[RED] Filter evaluation tests - logical operators","description":"Write failing tests for $and, $or, $not, $nor","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:08.059483-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T13:12:57.659356-06:00","closed_at":"2026-02-01T13:12:57.659356-06:00","close_reason":"Closed"}
{"id":"parquedb-ce0","title":"[REFACTOR] StorageBackend cleanup","description":"Refactor StorageBackend for clarity and efficiency","status":"closed","priority":0,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:04.272793-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:03:05.115845-06:00","closed_at":"2026-02-01T14:03:05.115845-06:00","close_reason":"Closed"}
{"id":"parquedb-cis","title":"[GREEN] Array operators implementation","description":"Implement array operators to pass tests","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:26.348199-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:08:21.77634-06:00","closed_at":"2026-02-01T14:08:21.77634-06:00","close_reason":"Closed"}
{"id":"parquedb-co9p","title":"Remove dead code: isFilterObject, backup files","description":"query/update.ts has unused isFilterObject function. Source tree has .bak/.backup_working/.orig files that should be deleted and added to .gitignore.","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-02T07:16:02.999667-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-02T07:20:11.959062-06:00","closed_at":"2026-02-02T07:20:11.959062-06:00","close_reason":"Closed"}
{"id":"parquedb-cp1","title":"Epic: Examples using ParqueDB API","description":"All examples must use ParqueDB API (createMany, $link) not raw parquet files. Data flows to data/{ns}/ and rels/ structure.","status":"closed","priority":0,"issue_type":"epic","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T14:30:11.389079-06:00","created_by":"Nathan Clevenger","updated_at":"2026-01-30T14:46:18.256147-06:00","closed_at":"2026-01-30T14:46:18.256147-06:00","close_reason":"Closed"}
{"id":"parquedb-crs","title":"Write: README.md (project overview)","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T12:40:25.239456-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:34:20.474469-06:00","closed_at":"2026-02-01T14:34:20.474469-06:00","close_reason":"Closed"}
{"id":"parquedb-cwtj","title":"Add custom test matchers for domain types","description":"Only 4 custom matchers exist for complex domain. Add:\n- toBeValidParquetFile()\n- toHaveRelationship()\n- toMatchEvent()\n- toBeValidIndex()\n- toHaveRowGroups()\n- toBeCompressed()\n\nUpdate tests/matchers.ts","status":"closed","priority":3,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-01T12:42:32.027919-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T12:54:07.503713-06:00","closed_at":"2026-02-01T12:54:07.503713-06:00","close_reason":"Completed by parallel agents"}
{"id":"parquedb-cyq","title":"Implement bloom filters","description":"Bloom filters for entity and edge existence checks","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:45.162541-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:24:19.192129-06:00","closed_at":"2026-02-01T14:24:19.192129-06:00","close_reason":"Closed"}
{"id":"parquedb-czm","title":"[RED] Event archival tests","description":"Write failing tests for event archival","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:45.729157-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:22:30.088581-06:00","closed_at":"2026-02-01T14:22:30.088581-06:00","close_reason":"Closed"}
{"id":"parquedb-czot","title":"Implement event replay for time-travel queries","description":"Support time-travel queries with { at: timestamp } option:\n\n```typescript\ndb.find('users', filter, { at: timestamp })\ndb.get('users:u1', { at: timestamp })\ndb.rels('users:u1', 'authored', { at: timestamp })\n```\n\n- Read current state from data.parquet\n- Read events from segments in timestamp range\n- Replay events backwards to reconstruct state at point in time\n\nFile: src/events/replay.ts","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-01T06:37:57.72466-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T07:14:07.625806-06:00","closed_at":"2026-02-01T07:14:07.625806-06:00","close_reason":"Implemented EventReplayer with InMemoryEventSource, BatchEventSource, forward/backward replay, batch replay, and state history. All 37 tests passing.","dependencies":[{"issue_id":"parquedb-czot","depends_on_id":"parquedb-o3d3","type":"blocks","created_at":"2026-02-01T06:38:10.11599-06:00","created_by":"Nathan Clevenger"}]}
{"id":"parquedb-d2o","title":"Implement relationship traversal","description":"Traverse relationships with related() and referencedBy()","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:47.027377-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:13:17.040016-06:00","closed_at":"2026-02-01T14:13:17.040016-06:00","close_reason":"Closed"}
{"id":"parquedb-d352","title":"Add path aliases to tsconfig","description":"No path aliases configured. All imports use relative paths.\n\nAdd to tsconfig.json:\n- baseUrl: '.'\n- paths: { '@/*': ['./src/*'] }\n\nUpdate imports throughout codebase.","status":"closed","priority":3,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-01T12:42:35.655996-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:38:56.817237-06:00","closed_at":"2026-02-01T14:38:56.817237-06:00","close_reason":"Closed"}
{"id":"parquedb-d3j","title":"[REFACTOR] MemoryBackend cleanup","description":"Refactor MemoryBackend","status":"closed","priority":0,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:18.081774-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T13:11:45.157306-06:00","closed_at":"2026-02-01T13:11:45.157306-06:00","close_reason":"Closed"}
{"id":"parquedb-d488","title":"Create shared Delta Lake utilities library","description":"Extract shared components between ParqueDB and Delta Lake:\n- Parquet Variant encoding/decoding\n- Storage backend interface alignment\n- Query/filter operators\n- CDC primitives\n\nCreate @dotdo/deltalake package with shared utilities.","status":"closed","priority":2,"issue_type":"feature","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-01T12:42:42.088717-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T13:17:51.176763-06:00","closed_at":"2026-02-01T13:17:51.176763-06:00","close_reason":"Closed"}
{"id":"parquedb-d6ff","title":"Refactor: Query - Add predicate pushdown for Parquet row groups","description":"## Summary\nThe filter system evaluates all filters in-memory after reading rows. For large datasets, we should push predicates down to Parquet row group level using column statistics.\n\n### Current State\n- Filter evaluation happens entirely in `src/query/filter.ts`\n- No integration with Parquet metadata (min/max stats, bloom filters)\n- Every row is read and filtered in memory\n\n### Optimization Opportunities\n\n1. **Row Group Pruning using Column Statistics**:\n   - Skip entire row groups when $gt/$gte/$lt/$lte cannot match\n   - Use min/max values from column metadata\n   - Especially beneficial for time-series or ID-based queries\n\n2. **Bloom Filter Integration**:\n   - For $eq and $in operators, check bloom filter first\n   - Skip row groups that definitely don't contain the value\n\n3. **Filter Analysis**:\n   - Extract pushdown-able predicates from complex filters\n   - Identify fields that have column statistics\n   - Determine which predicates benefit from pushdown\n\n### Files to Update\n- `src/query/filter.ts` - Add filter analysis functions\n- `src/query/executor.ts` - Integrate with Parquet reader\n- New: `src/query/pushdown.ts` - Predicate pushdown logic\n\n### Acceptance Criteria\n- [ ] Create filter analysis to extract pushdown predicates\n- [ ] Implement row group pruning for comparison operators\n- [ ] Integrate with bloom filter index (if available)\n- [ ] Add benchmarks showing improvement\n- [ ] Document pushdown behavior","status":"open","priority":3,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:33:01.993826-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T06:33:01.993826-06:00","labels":["refactor"]}
{"id":"parquedb-dg34","title":"Refactor: core.ts upsertMany() - Reduce code duplication with upsert()","description":"In src/ParqueDB/core.ts, upsertMany() (lines 2524-2667) duplicates significant logic from upsert() (lines 2482-2518):\n\nBoth methods:\n1. Find existing entity by filter\n2. If exists: update with filter fields stripped\n3. If not exists: create from filter fields + $set + $setOnInsert\n\nupsertMany has additional inline logic for handling update operators during creation (lines 2598-2630):\n```typescript\n// Handle $inc - start from 0\nif (item.update.$inc) { ... }\n// Handle $push - create array with single element\nif (item.update.$push) { ... }\n// Handle $addToSet - create array with single element\nif (item.update.$addToSet) { ... }\n// Handle $currentDate\nif (item.update.$currentDate) { ... }\n```\n\nThis logic should be shared:\n1. Extract `buildCreateDataFromUpdate(filter, update)` utility\n2. Have both upsert() and upsertMany() use it\n3. This ensures consistent behavior between single and batch operations\n\nThe $link handling after creation (lines 2644-2649) also duplicates pattern from update().","status":"open","priority":3,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:34:31.623536-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T06:34:31.623536-06:00","labels":["duplication","refactor"]}
{"id":"parquedb-di8","title":"Mutation Engine","description":"Create, update, delete operations with MongoDB-style operators","status":"closed","priority":1,"issue_type":"epic","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:50:29.529479-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:34:08.826072-06:00","closed_at":"2026-02-01T14:34:08.826072-06:00","close_reason":"Closed"}
{"id":"parquedb-diof","title":"Consolidate 3 duplicated update engines into one","description":"Three separate update operator implementations exist: query/update.ts (639 lines), mutation/operators.ts (674 lines), Collection.ts (inline), and ParqueDB/core.ts (inline). Only mutation/operators.ts has prototype pollution protection. Consolidate to mutation/operators.ts and have all others delegate to it.","status":"closed","priority":0,"issue_type":"bug","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-02T07:16:01.064989-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T03:40:58.431625-06:00","closed_at":"2026-02-03T03:40:58.431625-06:00","close_reason":"Closed"}
{"id":"parquedb-djy","title":"[RED] Entity history tests","description":"Write failing tests for history() method","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:42.697431-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:20:12.589353-06:00","closed_at":"2026-02-01T14:20:12.589353-06:00","close_reason":"Closed"}
{"id":"parquedb-dl2","title":"Implement inbound reference pagination","description":"$count and $next for large inbound sets","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:54.357926-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:25:00.541862-06:00","closed_at":"2026-02-01T14:25:00.541862-06:00","close_reason":"Closed"}
{"id":"parquedb-dn3e","title":"Enable noUncheckedIndexedAccess in tsconfig","description":"Currently disabled: noUncheckedIndexedAccess: false\n\nEnable this to catch unsafe obj[key] access patterns. Will require fixing code that assumes indexed access always returns defined values.","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-01T12:42:39.431158-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T13:07:24.823133-06:00","closed_at":"2026-02-01T13:07:24.823133-06:00","close_reason":"Completed by parallel agents"}
{"id":"parquedb-e46t","title":"Refactor: core.ts get() - Extract corruption detection into dedicated function","description":"In src/ParqueDB/core.ts, the get() method (lines 325-478) contains inline corruption detection logic (lines 350-378) that reads event log data and checks for invalid bytes.\n\nThis corruption detection logic:\n```typescript\nif (eventLogData \u0026\u0026 eventLogData.length \u003e 0) {\n  // Parquet files have a magic number 'PAR1' at both start and end\n  if (eventLogData.length \u003e= 4) {\n    const lastBytes = eventLogData.slice(-12)\n    let invalidByteCount = 0\n    for (let i = 0; i \u003c lastBytes.length; i++) {\n      if (lastBytes[i] === 0xFF) {\n        invalidByteCount++\n      }\n    }\n    if (invalidByteCount \u003e= 2) {\n      throw new Error('Event log corruption detected: invalid checksum in parquet file')\n    }\n  }\n}\n```\n\nShould be extracted to:\n```typescript\n// src/utils/parquet.ts\nexport function validateParquetIntegrity(data: Uint8Array): void\nexport function isParquetCorrupted(data: Uint8Array): boolean\n```\n\nBenefits:\n1. Reusable across other read operations\n2. Testable in isolation\n3. Keeps get() focused on entity retrieval\n4. The heuristic (0xFF bytes) could be documented/improved","status":"open","priority":3,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:33:32.272621-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T06:33:32.272621-06:00","labels":["complexity","refactor"]}
{"id":"parquedb-e7mf","title":"Replace Function types in iceberg-native.ts","description":"iceberg-native.ts:172-186 uses generic Function type which provides no type safety. Replace with properly typed function signatures for createTableWithSnapshot, readTableMetadata, etc.","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-02T05:32:46.448264-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-02T06:31:37.463951-06:00","closed_at":"2026-02-02T06:31:37.463951-06:00","close_reason":"Closed"}
{"id":"parquedb-ebu","title":"Benchmark: Workers to DO and R2","status":"closed","priority":0,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T15:47:14.301107-06:00","created_by":"Nathan Clevenger","updated_at":"2026-01-30T15:54:30.031337-06:00","closed_at":"2026-01-30T15:54:30.031337-06:00","close_reason":"Benchmark file created at tests/benchmarks/workers.workers.bench.ts with 39 benchmarks covering R2 read/write, DO RPC cold/warm, DO SQLite queries, sequential vs batched operations. Results show DO cold start ~3ms, warm ops ~1ms, R2 ops \u003c1ms."}
{"id":"parquedb-ec5a","title":"DO WAL: Phase 4 - Relationship batching","description":"## TDD Task: Batch relationship writes\n\n### Context\nCurrently each link() = 1 SQLite row. Relationships should be events in the WAL.\n\n### Red (Write failing tests first)\n1. Test link creates relationship event, not SQLite row\n2. Test bulk links batched together\n3. Test relationship queries work from events\n4. Test flush writes rels to R2 Parquet\n\n### Green (Implement)\n1. Remove relationships table writes\n2. Add REL_CREATE/REL_DELETE event types\n3. Derive relationship state from events\n4. Update getRelated to use events + R2\n\n### Files\n- `src/worker/ParqueDBDO.ts` - relationship events\n- `src/events/types.ts` - new event types","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:07:39.052095-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T07:29:20.32306-06:00","closed_at":"2026-02-03T07:29:20.32306-06:00","close_reason":"Closed","dependencies":[{"issue_id":"parquedb-ec5a","depends_on_id":"parquedb-azlw","type":"blocks","created_at":"2026-02-03T06:07:44.991743-06:00","created_by":"Nathan Clevenger"}]}
{"id":"parquedb-edd","title":"Implement entity history","description":"Get change history for an entity","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:41.39247-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:20:12.481055-06:00","closed_at":"2026-02-01T14:20:12.481055-06:00","close_reason":"Closed"}
{"id":"parquedb-eh0","title":"Implement event logging","description":"Log CREATE, UPDATE, DELETE events to events.parquet","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:34.048308-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:21:44.644082-06:00","closed_at":"2026-02-01T14:21:44.644082-06:00","close_reason":"Closed"}
{"id":"parquedb-ejjw","title":"Replace __date__ sentinel in deepClone with structuredClone","description":"utils/comparison.ts deepClone uses __date__ sentinel key for Date serialization. User data with a field named __date__ gets corrupted into a Date object. Use structuredClone() which is available in Node 17+ and Workers.","status":"closed","priority":1,"issue_type":"bug","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-02T07:16:02.199064-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-02T07:19:02.773549-06:00","closed_at":"2026-02-02T07:19:02.773549-06:00","close_reason":"Closed"}
{"id":"parquedb-em5","title":"[RED] O*NET example using ParqueDB","description":"Rewrite O*NET loader to use db.collection().createMany() and $link for relationships. Test that data appears in data/ and rels/ structure.","status":"closed","priority":0,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T14:30:12.218151-06:00","created_by":"Nathan Clevenger","updated_at":"2026-01-30T14:33:27.45591-06:00","closed_at":"2026-01-30T14:33:27.45591-06:00","close_reason":"Closed"}
{"id":"parquedb-ewif","title":"Refactor: Worker - Incomplete flushToParquet implementation in ParqueDBDO","description":"The flushToParquet() method in ParqueDBDO has a TODO comment and doesn't actually write Parquet files to R2:\n\n```typescript\n// TODO: Actually write Parquet file to R2\n// In a real implementation, we would:\n// 1. Convert events to Parquet format\n// 2. Write to R2: this.env.BUCKET.put(parquetPath, parquetBuffer)\n// 3. Verify the write succeeded\n```\n\nFiles:\n- src/worker/ParqueDBDO.ts (lines 1292-1297)\n\nThis is a critical path for event log archival. Currently events are marked as flushed but not actually persisted to Parquet.\n\nImpact: Data durability - events may be lost if DO restarts","status":"open","priority":3,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:33:25.991035-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T06:33:25.991035-06:00"}
{"id":"parquedb-eyk","title":"Implement query execution","description":"Execute find queries against Parquet files","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:15.921574-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:02:48.162465-06:00","closed_at":"2026-02-01T14:02:48.162465-06:00","close_reason":"Closed"}
{"id":"parquedb-ezw","title":"[RED] MemoryBackend tests","description":"Write failing tests for MemoryBackend","status":"closed","priority":0,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:16.165975-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T13:11:44.88681-06:00","closed_at":"2026-02-01T13:11:44.88681-06:00","close_reason":"Closed"}
{"id":"parquedb-f6e0","title":"Refactor: validation.ts - Add validation for entity ID format","description":"In src/ParqueDB/validation.ts, there's validation for namespaces but no validation for entity IDs. Entity IDs are accepted as raw strings throughout the codebase without validation.\n\nCurrent state:\n- validateNamespace() validates namespace strings\n- normalizeNamespace() lowercases namespace\n- No validateEntityId() exists\n\nIssues this causes:\n1. IDs with '/' are sometimes treated as full IDs, sometimes as partial\n2. No validation that ID portion doesn't contain invalid characters\n3. No validation of EntityId format (`namespace/id`)\n\nSuggested additions to validation.ts:\n```typescript\nexport function validateEntityId(id: string): void {\n  if (\\!id || typeof id \\!== 'string') {\n    throw new Error('Entity ID is required and must be a non-empty string')\n  }\n  // Validate format\n}\n\nexport function parseEntityId(id: string): { namespace: string; id: string } {\n  // Already exists in types.ts as parseEntityTarget, consider consolidating\n}\n\nexport function normalizeEntityId(namespace: string, id: string): EntityId {\n  return (id.includes('/') ? id : `${namespace}/${id}`) as EntityId\n}\n```\n\nThis improves error messages and catches invalid IDs early.","status":"open","priority":3,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:34:01.435211-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T06:34:01.435211-06:00","labels":["consistency","refactor","validation"]}
{"id":"parquedb-f7eb","title":"Refactor: Worker - Duplicate ULID generation logic","description":"ULID generation is implemented twice in the codebase:\n\n1. ParqueDBDO.ts has inline generateULID() function (lines 48-76)\n2. src/utils/id.ts likely has a similar implementation (generateId function)\n\nFiles:\n- src/worker/ParqueDBDO.ts (generateULID, lines 48-76)\n- src/utils/index.ts (generateId)\n\nThe DO implementation uses crypto-secure random via getRandom48Bit, but this logic should be centralized.\n\nRefactor:\n- Move generateULID to src/utils/id.ts\n- Import and use from ParqueDBDO\n- Ensure consistent ULID generation across the codebase\n\nImpact: Single source of truth for ID generation, easier testing","status":"open","priority":3,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:34:06.873131-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T06:34:06.873131-06:00"}
{"id":"parquedb-f7h","title":"[REFACTOR] Populate optimization","description":"Batch relationship fetching for performance","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:43.648403-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:14:51.747804-06:00","closed_at":"2026-02-01T14:14:51.747804-06:00","close_reason":"Closed"}
{"id":"parquedb-f84s","title":"Fix 97 TypeScript type errors","description":"npx tsc --noEmit reports 97 type errors. Most are noUncheckedIndexedAccess issues (array/object index access returning undefined). Priority files: ParqueDBDO.ts (20+ errors), IndexCache.ts (15+ errors), query/bloom.ts (8 errors), parquet/writer.ts (5 errors). Add null checks before array element and object property access.","status":"closed","priority":1,"issue_type":"bug","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-01T15:47:38.534107-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T15:58:30.453502-06:00","closed_at":"2026-02-01T15:58:30.453502-06:00","close_reason":"Closed"}
{"id":"parquedb-feys","title":"Add predicate pushdown for typed mode reads","description":"## Context\nPart of typed storage implementation (parquedb-k7jj design).\n\n## Requirements\n\n1. Extend query execution for typed mode:\n   - Map MongoDB-style filters to Parquet predicates\n   - Apply column statistics for row group skipping\n   - Use native column filtering instead of variant path\n\n2. Filter mapping:\n   - `{ field: value }` -\u003e `{ column: field, op: 'eq', value }`\n   - `{ field: { $gt: n } }` -\u003e `{ column: field, op: 'gt', value: n }`\n   - `{ field: { $in: [...] } }` -\u003e `{ column: field, op: 'in', value: [...] }`\n\n3. Entity reconstruction:\n   - Fast path: use $data if present\n   - Slow path: reconstruct from columns\n\n4. Testing:\n   - Unit tests for filter mapping\n   - Integration tests verifying row group skipping\n   - Performance benchmarks vs flexible mode\n\n## Acceptance Criteria\n- [ ] Filters map to Parquet predicates correctly\n- [ ] Row group statistics used for skipping\n- [ ] Entity reconstruction works with/without $data\n- [ ] Performance improvement measurable\n- [ ] Tests pass\n\n## References\n- Design: docs/architecture/typed-storage.md\n- Depends on: parquedb-xi44 (ParquetWriter typed mode)","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:41:38.645493-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T07:22:10.178199-06:00","closed_at":"2026-02-03T07:22:10.178199-06:00","close_reason":"Implemented with full test coverage"}
{"id":"parquedb-fgij","title":"Refactor: Storage - DOSqliteBackend.copy has dead code","description":"DOSqliteBackend.copy() at lines 543-562 has an unused variable:\\n\\n```typescript\\nasync copy(source: string, dest: string): Promise\u003cvoid\u003e {\\n  this.ensureSchema()\\n  const sourceKey = this.withPrefix(source)\\n  const _destKey = this.withPrefix(dest)  // Unused\\!\\n  void _destKey // Used in future implementation  // Comment acknowledges it's unused\\n\\n  // ... uses sourceKey but not _destKey\\n  await this.write(dest, data)  // Recalculates destKey inside write()\\n}\\n```\\n\\nRefactor to:\\n- Remove the unused _destKey variable and void statement\\n- Or actually use it by writing directly to the table instead of calling write()\\n\\nFiles affected:\\n- /Users/nathanclevenger/projects/parquedb/src/storage/DOSqliteBackend.ts","status":"open","priority":3,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:33:09.83281-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T06:33:09.83281-06:00"}
{"id":"parquedb-fsjn","title":"Fix onet-optimized dataset format mismatch","description":"The onet-optimized dataset expects per-collection files:\n- occupations.parquet\n- skills.parquet\n- abilities.parquet\n- knowledge.parquet\n\nBut the ETL script (scripts/etl-onet-optimized.ts) produces consolidated files:\n- data.parquet\n- rels.parquet\n\nNeed to either:\n1. Update the ETL to produce per-collection files\n2. Update the dataset handler to support consolidated format\n3. Remove onet-optimized from DATASETS config until fixed","status":"closed","priority":2,"issue_type":"bug","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T03:24:43.161855-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T03:33:27.93757-06:00","closed_at":"2026-02-03T03:33:27.93757-06:00","close_reason":"Closed"}
{"id":"parquedb-fv0u","title":"Consolidate filter evaluation logic","description":"Filter evaluation logic is duplicated across 4 files: Collection.ts (211-368), query/filter.ts (22-251), query/predicate.ts (339-529), query/update.ts (566-715). Centralize into a single module and import everywhere.","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-01T15:47:09.860438-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T16:08:26.917767-06:00","closed_at":"2026-02-01T16:08:26.917767-06:00","close_reason":"Closed"}
{"id":"parquedb-fyk","title":"[GREEN] Create operation implementation","description":"Implement create operations to pass tests","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:16.00472-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:05:20.65757-06:00","closed_at":"2026-02-01T14:05:20.65757-06:00","close_reason":"Closed"}
{"id":"parquedb-g8r","title":"Implement FsBackend (Node.js filesystem)","description":"Storage backend for Node.js fs module","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:47.66854-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:12:35.878101-06:00","closed_at":"2026-02-01T14:12:35.878101-06:00","close_reason":"Closed"}
{"id":"parquedb-gacl","title":"Refactor: core.ts getSnapshotManager() - Extract to dedicated class","description":"In src/ParqueDB/core.ts, getSnapshotManager() (lines 2371-2476) returns an inline object literal with ~100 lines of implementation. This makes the code harder to read, test, and maintain.\n\nThe snapshot manager should be extracted to a dedicated class:\n```typescript\n// src/ParqueDB/SnapshotManagerImpl.ts\nexport class SnapshotManagerImpl implements SnapshotManager {\n  constructor(\n    private entities: Map\u003cstring, Entity\u003e,\n    private events: Event[],\n    private snapshots: Snapshot[],\n    private storage: StorageBackend\n  ) {}\n  \n  async createSnapshot(entityId: EntityId): Promise\u003cSnapshot\u003e { ... }\n  async listSnapshots(entityId: EntityId): Promise\u003cSnapshot[]\u003e { ... }\n  // ...\n}\n```\n\nBenefits:\n1. Better separation of concerns\n2. Enables unit testing of snapshot logic in isolation\n3. Cleaner dependency injection\n4. Removes 100 lines from the already large core.ts file","status":"open","priority":3,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:33:04.206027-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T06:33:04.206027-06:00","labels":["complexity","refactor"]}
{"id":"parquedb-gcd","title":"[GREEN] Query execution implementation","description":"Implement query execution to pass tests","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:18.866736-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:02:48.233608-06:00","closed_at":"2026-02-01T14:02:48.233608-06:00","close_reason":"Closed"}
{"id":"parquedb-gd7a","title":"Refactor: Query - Rename non-standard operators to distinguish from MongoDB","description":"## Summary\nParqueDB adds some custom string operators that aren't in MongoDB. These should be clearly marked as extensions to avoid confusion.\n\n### Non-standard Operators\n\n1. **$startsWith** - Not in MongoDB (MongoDB uses $regex)\n2. **$endsWith** - Not in MongoDB (MongoDB uses $regex)  \n3. **$contains** - Not in MongoDB (MongoDB uses $regex)\n\nThese are convenient shortcuts but developers familiar with MongoDB might expect them to work there too.\n\n### Options\n\n1. **Keep as-is but document clearly**:\n   - Add 'ParqueDB extension' notes in JSDoc\n   - Document in README that these are non-standard\n\n2. **Rename to clearly mark as extensions**:\n   - $startsWith -\u003e $pq_startsWith or $_startsWith\n   - This makes it obvious they're not MongoDB standard\n\n3. **Add MongoDB-compatible alternatives**:\n   - Keep both syntaxes\n   - `{ name: { $startsWith: 'foo' } }` (ParqueDB)\n   - `{ name: { $regex: '^foo' } }` (MongoDB)\n\n### Recommendation\nOption 1 - keep names but document clearly. The operators are intuitive and useful.\n\n### Files to Update\n- `src/types/filter.ts` - Add JSDoc noting these are ParqueDB extensions\n- README.md - Document extensions clearly\n\n### Acceptance Criteria\n- [ ] Add 'ParqueDB extension' JSDoc to $startsWith, $endsWith, $contains\n- [ ] Update README filter documentation\n- [ ] Ensure $regex provides equivalent functionality\n- [ ] Add migration guide if renaming","status":"open","priority":3,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:33:57.570764-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T06:33:57.570764-06:00","labels":["refactor"]}
{"id":"parquedb-hcv","title":"Implement relationship reading","description":"Read outbound predicates and inbound reverses","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:29.477507-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:13:17.477055-06:00","closed_at":"2026-02-01T14:13:17.477055-06:00","close_reason":"Closed"}
{"id":"parquedb-hex","title":"[RED] Update operation tests","description":"Write failing tests for update, updateOne, updateMany with version checking","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:32.385821-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-02T04:45:59.415108-06:00","closed_at":"2026-02-02T04:45:59.415108-06:00","close_reason":"Tests implemented in earlier waves"}
{"id":"parquedb-hi2","title":"Implement Collection class","description":"Collection class with MongoDB-style API (find, findOne, get, create, update, delete)","status":"closed","priority":0,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:41.504177-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:02:39.307626-06:00","closed_at":"2026-02-01T14:02:39.307626-06:00","close_reason":"Closed","dependencies":[{"issue_id":"parquedb-hi2","depends_on_id":"parquedb-3yy","type":"blocks","created_at":"2026-01-30T11:51:51.062132-06:00","created_by":"Nathan Clevenger"},{"issue_id":"parquedb-hi2","depends_on_id":"parquedb-18b","type":"blocks","created_at":"2026-01-30T11:51:51.145285-06:00","created_by":"Nathan Clevenger"},{"issue_id":"parquedb-hi2","depends_on_id":"parquedb-xi8","type":"blocks","created_at":"2026-01-30T11:51:51.22681-06:00","created_by":"Nathan Clevenger"}]}
{"id":"parquedb-hibc","title":"Refactor: ParqueDB.ts Proxy - Extract method map to reduce repetitive if-chains","description":"In src/ParqueDB.ts, the Proxy handler's get trap has a long chain of if statements (lines 137-221) checking each method name. This should be refactored to use a method map lookup for cleaner, more maintainable code.\n\nCurrent pattern:\n```typescript\nif (prop === 'registerSchema') {\n  return impl.registerSchema.bind(impl)\n}\nif (prop === 'collection') {\n  return impl.collection.bind(impl)\n}\n// ... 20+ more similar blocks\n```\n\nSuggested refactor:\n```typescript\nconst methodMap: Record\u003cstring, Function\u003e = {\n  registerSchema: impl.registerSchema,\n  collection: impl.collection,\n  find: impl.find,\n  // ...\n}\nconst method = methodMap[prop as string]\nif (method) return method.bind(impl)\n```\n\nThis reduces ~85 lines of code to ~30 lines and makes adding new methods trivial.","status":"open","priority":3,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:32:26.292847-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T06:32:26.292847-06:00","labels":["code-quality","refactor"]}
{"id":"parquedb-ho9","title":"[GREEN] ParqueDB class implementation","description":"Implement ParqueDB class to pass tests","status":"closed","priority":0,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:30.921649-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:02:41.947725-06:00","closed_at":"2026-02-01T14:02:41.947725-06:00","close_reason":"Closed"}
{"id":"parquedb-hrni","title":"Refactor: Worker - ReadPath background revalidation missing waitUntil","description":"ReadPath.revalidateInBackground() has a TODO noting that it should accept ExecutionContext to use ctx.waitUntil() for proper background task lifecycle management.\n\nFrom ReadPath.ts (lines 514-519):\n```typescript\n/**\n * TODO(parquedb-y9aw): Accept ExecutionContext to use ctx.waitUntil() for proper\n * background task lifecycle management in Workers. Without waitUntil, background\n * revalidation may be terminated early if the Worker instance is recycled.\n */\n```\n\nFiles:\n- src/worker/ReadPath.ts\n\nThe current fire-and-forget pattern works but may result in:\n- Dropped background revalidation if Worker terminates\n- Potential cache staleness\n\nFix: Pass ExecutionContext from caller and wrap revalidation in ctx.waitUntil()\n\nImpact: More reliable stale-while-revalidate caching","status":"open","priority":3,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:33:35.443174-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T06:33:35.443174-06:00"}
{"id":"parquedb-hzg","title":"Implement pagination","description":"Cursor-based and offset pagination","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:30.117182-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:11:19.132736-06:00","closed_at":"2026-02-01T14:11:19.132736-06:00","close_reason":"Closed"}
{"id":"parquedb-hztu","title":"Refactor: Storage - R2Backend multipart upload state leaks memory","description":"R2Backend tracks active multipart uploads in a Map at line 654:\\n\\n```typescript\\nprivate activeUploads = new Map\u003cstring, { upload: R2MultipartUpload; createdAt: number }\u003e()\\n```\\n\\nWhile there is a cleanupStaleUploads() method, it only runs:\\n1. When startMultipartUpload is called\\n2. Only cleans uploads older than TTL (default 30 minutes)\\n\\nIssues:\\n- If no new uploads are started, stale uploads persist indefinitely\\n- Memory leak if many uploads are started but not completed/aborted\\n- No periodic cleanup mechanism\\n\\nConsider:\\n- Adding a periodic cleanup timer (though this is tricky in Workers)\\n- Adding a maxActiveUploads limit\\n- Documenting the memory implications\\n- Or making cleanup more aggressive\\n\\nFiles affected:\\n- /Users/nathanclevenger/projects/parquedb/src/storage/R2Backend.ts","status":"open","priority":3,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:34:10.73399-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T06:34:10.73399-06:00"}
{"id":"parquedb-i0q8","title":"Cost: Worker - Add SQLite row reduction opportunities in ParqueDBDO","description":"ParqueDBDO can further reduce SQLite row costs (billed per row read/written):\n\nCurrent optimizations:\n- WAL batching for events (events_wal table)\n- Sequence counters initialized once\n\nPotential improvements:\n1. Batch entity metadata updates instead of individual INSERTs\n2. Cache counters across DO invocations (currently re-initialized)\n3. Consider read-through caching for frequently accessed entities\n4. Batch relationship INSERTs when creating entities with links\n\nFiles:\n- src/worker/ParqueDBDO.ts\n\nSpecific areas:\n- create() does separate INSERT for entity and each relationship (line 419-428)\n- update() does individual UPDATE per entity\n- getUnflushedEventCount() queries SUM on every appendEvent check\n\nImpact: Reduced DO costs at scale","status":"open","priority":3,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:34:34.541605-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T06:34:34.541605-06:00"}
{"id":"parquedb-i0rb","title":"Add observability hooks","description":"Missing monitoring/tracing integration. Add hooks for: OpenTelemetry spans, structured logging, metrics (query latency, cache hits, storage ops).","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-01T15:47:49.792902-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T16:23:42.259423-06:00","closed_at":"2026-02-01T16:23:42.259423-06:00","close_reason":"Closed"}
{"id":"parquedb-i9om","title":"Refactor: Query - Consolidate duplicate operator evaluation logic","description":"## Summary\nThere is duplication between filter evaluation in `src/query/filter.ts` and pull condition matching in `src/mutation/operators.ts`.\n\n### Problem\nBoth files have separate implementations of comparison operator matching:\n- `src/query/filter.ts` line 213-329: `evaluateOperators()`\n- `src/mutation/operators.ts` line 609-639: `matchesComparisonOperators()`\n\nThe mutation operators version is less complete (only handles numbers for $gt/$gte/$lt/$lte) while filter.ts handles all types.\n\n### Files Affected\n- `src/query/filter.ts` - Full implementation\n- `src/mutation/operators.ts` - Partial implementation\n\n### Solution\n- Extract shared operator evaluation to a common utility\n- Have both files use the shared implementation\n- Ensure consistent behavior across filter and update operations\n\n### Acceptance Criteria\n- [ ] Create shared `evaluateComparisonOperator()` utility\n- [ ] Update filter.ts to use shared utility\n- [ ] Update operators.ts to use shared utility\n- [ ] Verify mutation operations handle all types correctly\n- [ ] Add tests for type consistency","status":"open","priority":3,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:32:39.266241-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T06:32:39.266241-06:00","labels":["refactor"]}
{"id":"parquedb-icfw","title":"DO WAL Rewrite: Cost optimization for ParqueDBDO","description":"## Summary\n\nRewrite ParqueDBDO to use SQLite as WAL-only (events buffer) rather than full entity store, with bulk operations bypassing SQLite entirely.\n\n## Problem\n\nCurrent implementation stores each entity as a separate SQLite row, causing cost explosion:\n- DO SQLite is 4.5x more expensive than R2 writes\n- Create 100 entities = 200 SQLite rows (entity + event each)\n- Bulk import 10K = 20,000 rows = massive cost\n\n## Solution\n\n1. **SQLite = WAL only**: Remove `entities` and `relationships` tables. Store event batches as blobs (~1000 events per row).\n2. **Bulk bypass**: 5+ entities stream directly to R2 as pending Parquet row groups.\n3. **Read merge**: QueryExecutor merges `data.parquet` + `pending/*.parquet` + unflushed WAL.\n\n## Implementation Phases\n\n### Phase 1: Add WAL batching (non-breaking)\n- [ ] Add `events_wal` table with blob storage\n- [ ] Add `pending_row_groups` table\n- [ ] Implement BatchCoalescer for event batching\n- [ ] Connect to existing SqliteWal infrastructure\n\n### Phase 2: Implement bulk bypass\n- [ ] Add `createMany()`, `updateMany()`, `deleteMany()` to DO\n- [ ] Implement R2 streaming for bulk ops (\u003e= 5 entities)\n- [ ] Update QueryExecutor to merge pending row groups\n\n### Phase 3: Remove entity storage\n- [ ] Stop writing to `entities` table\n- [ ] Update reads to use merged path\n- [ ] Migration script to flush existing entities to R2\n- [ ] Drop `entities` and `relationships` tables\n\n### Phase 4: Optimize reads\n- [ ] Efficient WAL event querying by namespace\n- [ ] Cache pending row groups\n- [ ] Optimize merge strategy\n\n## Cost Savings\n\n| Operation | Current (rows) | Proposed (rows) | Savings |\n|-----------|---------------|-----------------|---------|\n| Create 1 entity | 2 | 0-1 | 50-100% |\n| Create 100 entities | 200 | 1 | 99.5% |\n| Bulk import 10K | 20,000 | 10 | 99.95% |\n\n## Design Doc\n\nSee `docs/architecture/DO_WAL_REWRITE.md` for full details.\n\n## Acceptance Criteria\n\n- [ ] 90%+ reduction in DO SQLite row operations\n- [ ] Bulk imports 10x faster\n- [ ] All existing tests pass\n- [ ] p50 read latency unchanged or improved","status":"open","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:05:07.977744-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T06:05:07.977744-06:00","labels":["cost-optimization","enhancement","workers"]}
{"id":"parquedb-ip3a","title":"Epic: Pluggable Entity Backends (Iceberg/Delta Lake)","description":"Support multiple table formats for entity storage while keeping relationships in ParqueDB format.\n\n## Goals\n- Native backend (current ParqueDB format)\n- Iceberg backend (DuckDB/Spark/Snowflake compatible)\n- Delta Lake backend\n- R2 Data Catalog integration\n\n## Architecture\n- EntityBackend interface abstracts storage format\n- Relationships always stored in ParqueDB rels/ format\n- IceType schema compatibility\n\n## Docs\n- docs/architecture/pluggable-backends.md\n- docs/architecture/icetype-relationships.md","status":"closed","priority":1,"issue_type":"feature","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T07:04:36.783083-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T07:34:31.458344-06:00","closed_at":"2026-02-03T07:34:31.458344-06:00","close_reason":"Iceberg and Delta Lake backends fully implemented and tested. Native backend and R2 Data Catalog can be tracked separately."}
{"id":"parquedb-ip3a.1","title":"RED: Write tests for IcebergBackend.appendEntities","description":"Write failing tests for appendEntities that:\n- Creates Parquet file in correct Iceberg location\n- Encodes entities with Variant $data column\n- Creates manifest entry with file stats\n- Creates new snapshot\n- Updates table metadata\n\nTest file: tests/unit/backends/iceberg-write.test.ts","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T07:04:45.314689-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T07:06:49.734711-06:00","closed_at":"2026-02-03T07:06:49.734711-06:00","close_reason":"Tests written and failing as expected (14 fail, 5 pass)","dependencies":[{"issue_id":"parquedb-ip3a.1","depends_on_id":"parquedb-ip3a","type":"parent-child","created_at":"2026-02-03T07:04:45.315351-06:00","created_by":"Nathan Clevenger"}]}
{"id":"parquedb-ip3a.2","title":"GREEN: Implement IcebergBackend.appendEntities","description":"Implement appendEntities to pass the tests:\n- Use ParquetWriter to create data file\n- Use encodeVariant for $data column\n- Use @dotdo/iceberg ManifestGenerator\n- Use SnapshotBuilder for new snapshot\n- Use MetadataWriter to commit\n\nLocation: src/backends/iceberg.ts","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T07:04:51.6066-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T07:18:49.522771-06:00","closed_at":"2026-02-03T07:18:49.522771-06:00","close_reason":"Implemented appendEntities with ParquetWriter, Variant encoding, ManifestGenerator, SnapshotBuilder. All 19 tests pass.","dependencies":[{"issue_id":"parquedb-ip3a.2","depends_on_id":"parquedb-ip3a","type":"parent-child","created_at":"2026-02-03T07:04:51.607275-06:00","created_by":"Nathan Clevenger"},{"issue_id":"parquedb-ip3a.2","depends_on_id":"parquedb-ip3a.1","type":"blocks","created_at":"2026-02-03T07:05:11.862212-06:00","created_by":"Nathan Clevenger"}]}
{"id":"parquedb-ip3a.3","title":"RED: Write tests for IcebergBackend.readEntitiesFromSnapshot","description":"Write failing tests for readEntitiesFromSnapshot:\n- Reads manifest list from snapshot\n- Reads data files from manifests\n- Decodes Variant $data column\n- Applies filter predicates\n- Applies sort/limit/skip\n\nTest file: tests/unit/backends/iceberg-read.test.ts","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T07:05:03.914664-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T07:18:54.107734-06:00","closed_at":"2026-02-03T07:18:54.107734-06:00","close_reason":"Tests and implementation for readEntitiesFromSnapshot included in iceberg-write.test.ts. All 19 tests pass.","dependencies":[{"issue_id":"parquedb-ip3a.3","depends_on_id":"parquedb-ip3a","type":"parent-child","created_at":"2026-02-03T07:05:03.915507-06:00","created_by":"Nathan Clevenger"},{"issue_id":"parquedb-ip3a.3","depends_on_id":"parquedb-ip3a.2","type":"blocks","created_at":"2026-02-03T07:05:12.09205-06:00","created_by":"Nathan Clevenger"}]}
{"id":"parquedb-ip3a.4","title":"GREEN: Implement IcebergBackend.readEntitiesFromSnapshot","description":"Implement readEntitiesFromSnapshot:\n- Parse manifest list from snapshot\n- Read manifests to get file list\n- Use hyparquet to read Parquet files\n- Decode Variant $data with decodeVariant\n- Apply filter using matchesFilter\n- Apply sort/limit/skip\n\nLocation: src/backends/iceberg.ts","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T07:05:04.042622-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T07:18:54.136536-06:00","closed_at":"2026-02-03T07:18:54.136536-06:00","close_reason":"Tests and implementation for readEntitiesFromSnapshot included in iceberg-write.test.ts. All 19 tests pass.","dependencies":[{"issue_id":"parquedb-ip3a.4","depends_on_id":"parquedb-ip3a","type":"parent-child","created_at":"2026-02-03T07:05:04.043367-06:00","created_by":"Nathan Clevenger"},{"issue_id":"parquedb-ip3a.4","depends_on_id":"parquedb-ip3a.3","type":"blocks","created_at":"2026-02-03T07:05:11.977463-06:00","created_by":"Nathan Clevenger"}]}
{"id":"parquedb-ip3a.5","title":"REFACTOR: Extract shared Parquet utilities","description":"Refactor common patterns:\n- Entity row serialization (shredding + Variant)\n- Parquet write options (compression, row groups)\n- Schema generation for entities\n- Filter to predicate pushdown\n\nMay create src/backends/parquet-utils.ts","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T07:05:04.165977-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T07:31:04.948288-06:00","closed_at":"2026-02-03T07:31:04.948288-06:00","close_reason":"Extracted shared utilities to parquet-utils.ts: entityToRow, rowToEntity, buildEntityParquetSchema, matchesFilter, generateEntityId, extractDataFields, base64 helpers. All tests passing.","dependencies":[{"issue_id":"parquedb-ip3a.5","depends_on_id":"parquedb-ip3a","type":"parent-child","created_at":"2026-02-03T07:05:04.16679-06:00","created_by":"Nathan Clevenger"},{"issue_id":"parquedb-ip3a.5","depends_on_id":"parquedb-ip3a.4","type":"blocks","created_at":"2026-02-03T07:05:12.205605-06:00","created_by":"Nathan Clevenger"}]}
{"id":"parquedb-ip3a.6","title":"RED: Write integration tests for IcebergBackend","description":"Write integration tests:\n- Full CRUD cycle with Iceberg\n- Time travel queries\n- Schema evolution\n- Compaction/vacuum\n\nTest file: tests/integration/backends/iceberg.test.ts","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T07:05:04.291096-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T07:26:29.375838-06:00","closed_at":"2026-02-03T07:26:29.375838-06:00","close_reason":"Closed","dependencies":[{"issue_id":"parquedb-ip3a.6","depends_on_id":"parquedb-ip3a","type":"parent-child","created_at":"2026-02-03T07:05:04.296423-06:00","created_by":"Nathan Clevenger"},{"issue_id":"parquedb-ip3a.6","depends_on_id":"parquedb-ip3a.4","type":"blocks","created_at":"2026-02-03T07:05:12.322266-06:00","created_by":"Nathan Clevenger"}]}
{"id":"parquedb-ip3a.7","title":"GREEN: Fix integration test failures","description":"Fix any integration test failures discovered during testing.","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T07:05:04.419572-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T07:34:23.706331-06:00","closed_at":"2026-02-03T07:34:23.706331-06:00","close_reason":"All 44 Iceberg integration tests now passing","dependencies":[{"issue_id":"parquedb-ip3a.7","depends_on_id":"parquedb-ip3a","type":"parent-child","created_at":"2026-02-03T07:05:04.420402-06:00","created_by":"Nathan Clevenger"},{"issue_id":"parquedb-ip3a.7","depends_on_id":"parquedb-ip3a.6","type":"blocks","created_at":"2026-02-03T07:05:12.438134-06:00","created_by":"Nathan Clevenger"}]}
{"id":"parquedb-ip3a.8","title":"RED: Write tests for DeltaBackend","description":"Write unit tests for DeltaBackend following TDD:\n- create/bulkCreate operations\n- get/find/count operations  \n- update/delete operations\n- Delta Lake transaction log\n- Time travel queries\n- Schema evolution\n\nTest file: tests/unit/backends/delta-write.test.ts\n\nReference: tests/unit/backends/iceberg-write.test.ts for patterns","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T07:22:51.202609-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T07:26:15.579218-06:00","closed_at":"2026-02-03T07:26:15.579218-06:00","close_reason":"53 RED phase tests written for DeltaBackend, all failing as expected","dependencies":[{"issue_id":"parquedb-ip3a.8","depends_on_id":"parquedb-ip3a","type":"parent-child","created_at":"2026-02-03T07:22:51.203434-06:00","created_by":"Nathan Clevenger"}]}
{"id":"parquedb-ip3a.9","title":"GREEN: Implement DeltaBackend","description":"Implement DeltaBackend to pass tests:\n- Use ParquetWriter for data files\n- Implement Delta Lake transaction log (_delta_log/)\n- JSON-based commit files (00000000000000000000.json)\n- Checkpoint files for optimization\n- Time travel via version/timestamp\n\nLocation: src/backends/delta.ts\n\nReference: src/backends/iceberg.ts for patterns","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T07:23:00.118274-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T07:32:24.702914-06:00","closed_at":"2026-02-03T07:32:24.702914-06:00","close_reason":"DeltaBackend GREEN phase complete - all 53 tests passing","dependencies":[{"issue_id":"parquedb-ip3a.9","depends_on_id":"parquedb-ip3a","type":"parent-child","created_at":"2026-02-03T07:23:00.119276-06:00","created_by":"Nathan Clevenger"},{"issue_id":"parquedb-ip3a.9","depends_on_id":"parquedb-ip3a.8","type":"blocks","created_at":"2026-02-03T07:23:00.235049-06:00","created_by":"Nathan Clevenger"}]}
{"id":"parquedb-j17q","title":"Refactor: Storage - Extract common error classes into shared module","description":"Currently, error classes are duplicated across multiple backends:\\n\\n1. MemoryBackend exports: FileNotFoundError, VersionMismatchError, FileExistsError, DirectoryNotEmptyError, DirectoryNotFoundError\\n2. R2Backend defines its own: R2OperationError, R2ETagMismatchError, R2NotFoundError\\n3. DOSqliteBackend defines its own: DOSqliteNotFoundError, DOSqliteETagMismatchError, DOSqliteFileExistsError\\n4. FsBackend imports errors from MemoryBackend and defines PathTraversalError\\n5. FsxBackend throws generic Error instances instead of typed errors\\n\\nRefactor to:\\n- Create src/storage/errors.ts with base error classes\\n- Have backend-specific errors extend base classes where appropriate\\n- Standardize error handling so consumers can catch by base type\\n- Update FsxBackend to use proper typed errors\\n\\nFiles affected:\\n- /Users/nathanclevenger/projects/parquedb/src/storage/MemoryBackend.ts\\n- /Users/nathanclevenger/projects/parquedb/src/storage/R2Backend.ts\\n- /Users/nathanclevenger/projects/parquedb/src/storage/DOSqliteBackend.ts\\n- /Users/nathanclevenger/projects/parquedb/src/storage/FsBackend.ts\\n- /Users/nathanclevenger/projects/parquedb/src/storage/FsxBackend.ts","status":"closed","priority":3,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:32:25.419597-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T07:11:30.217545-06:00","closed_at":"2026-02-03T07:11:30.217545-06:00","close_reason":"Implemented"}
{"id":"parquedb-j1u5","title":"[DOCS] Document consistency model clearly","description":"The codebase mixes strong consistency (Durable Objects) with eventual consistency (R2 reads) without clear documentation. Users need to understand:\n\n1. When reads are strongly consistent vs eventually consistent\n2. Read-after-write guarantees (or lack thereof)\n3. The CQRS architecture implications\n4. How stale data is handled\n\nAdd CONSISTENCY.md to docs/architecture/ explaining the model.","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-01T13:35:48.345887-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T13:43:25.740429-06:00","closed_at":"2026-02-01T13:43:25.740429-06:00","close_reason":"Closed"}
{"id":"parquedb-j4r","title":"[GREEN] Traversal implementation","description":"Implement traversal methods to pass tests","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:50.024119-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:13:17.266172-06:00","closed_at":"2026-02-01T14:13:17.266172-06:00","close_reason":"Closed"}
{"id":"parquedb-j5n","title":"Indexing","description":"FTS, vector, bloom filter, and secondary indexes","status":"closed","priority":2,"issue_type":"epic","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:50:32.878379-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:34:08.892856-06:00","closed_at":"2026-02-01T14:34:08.892856-06:00","close_reason":"Closed"}
{"id":"parquedb-jc5","title":"Implement full-text search","description":"Inverted index for $text queries","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:53.393831-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:27:18.662101-06:00","closed_at":"2026-02-01T14:27:18.662101-06:00","close_reason":"Closed"}
{"id":"parquedb-jq6u","title":"Secondary index queries slower than full scans","description":"Benchmark reveals indexed queries are 50-70% SLOWER than equivalent full scans:\n\nEvidence:\n- imdb100k-eq-movie: indexed 259ms vs scan 129ms (2x slower)\n- imdb100k-eq-tvseries: indexed 538ms vs scan 157ms (3x slower)\n- imdb100k-range-year-2020s: indexed 321ms vs scan 192ms (1.7x slower)\n\nRoot causes to investigate:\n1. Index fetch from R2 adds latency (extra HTTP request)\n2. Row group hints don't skip enough data to offset index cost\n3. Parquet's native column stats already provide predicate pushdown for * columns\n4. Index lookup overhead (parsing, searching) exceeds benefits\n\nPotential solutions:\n- Cache index files in memory after first load\n- Only use indexes when selectivity is very high (\u003c 1% of rows)\n- Consider columnar bloom filters instead of separate index files\n- Pre-warm index cache on worker startup","status":"closed","priority":1,"issue_type":"bug","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-02T08:48:41.66548-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T03:44:34.272482-06:00","closed_at":"2026-02-03T03:44:34.272482-06:00","close_reason":"Issue resolved - Hash and SST secondary indexes were removed in commits b45ebf0 and 092fa88. Native Parquet predicate pushdown on $index_* columns is now used for equality and range queries, which is faster than the previous secondary index approach. The benchmarks that showed indexed queries being 50-70% slower than full scans led to this architectural change. The codebase now uses: (1) Parquet min/max column statistics for row group skipping, (2) Native bloom filters in Parquet for equality checks, (3) FTS and Vector indexes for specialized search. Equality queries ($eq/$in) and range queries ($gt/$gte/$lt/$lte) now go through the same optimized path."}
{"id":"parquedb-jusb","title":"Add fluent query builder","description":"Query construction is ad-hoc. Add fluent builder pattern: db.collection('posts').where('status', '=', 'published').orderBy('createdAt', 'desc').limit(10).select(['title', 'author'])","status":"closed","priority":2,"issue_type":"feature","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-01T15:47:24.106446-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T16:36:22.871128-06:00","closed_at":"2026-02-01T16:36:22.871128-06:00","close_reason":"Closed"}
{"id":"parquedb-jvj","title":"Implement IceType schema integration","description":"Parse IceType schemas for ParqueDB","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:52:07.270671-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:19:33.208855-06:00","closed_at":"2026-02-01T14:19:33.208855-06:00","close_reason":"Closed"}
{"id":"parquedb-jzb","title":"[REFACTOR] Event logging optimization","description":"Buffer and batch event writes","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:37.613343-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:21:45.207573-06:00","closed_at":"2026-02-01T14:21:45.207573-06:00","close_reason":"Closed"}
{"id":"parquedb-k0d2","title":"Add concurrency and race condition tests","description":"No concurrency tests exist:\n- Parallel CRUD operations\n- Index update conflicts\n- Event ordering under load\n- Race conditions\n- Deadlock scenarios\n- Transaction conflicts\n\nAdd stress tests for concurrent operations.","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-01T12:42:36.991574-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T13:07:24.755743-06:00","closed_at":"2026-02-01T13:07:24.755743-06:00","close_reason":"Completed by parallel agents"}
{"id":"parquedb-k38b","title":"Add concurrent write scenario tests","description":"Limited testing for concurrent write scenarios. Add tests for: concurrent writes to same entity, version conflicts under contention, race conditions between create and update.","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-01T17:01:09.151699-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T17:20:19.255239-06:00","closed_at":"2026-02-01T17:20:19.255239-06:00","close_reason":"Closed"}
{"id":"parquedb-k5d","title":"[GREEN] Numeric operators implementation","description":"Implement numeric operators to pass tests","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:23.45089-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:08:21.711439-06:00","closed_at":"2026-02-01T14:08:21.711439-06:00","close_reason":"Closed"}
{"id":"parquedb-k7jj","title":"Redesign API: DB() factory with inline schema objects","description":"## Design Complete\n\nFull design documented in `docs/architecture/typed-storage.md`.\n\n## Key Design Decisions\n\n### 1. Two Storage Modes\n- **Typed Mode**: Schema-defined collections use native Parquet columns at `data/{collection}.parquet`\n- **Flexible Mode**: Schema-less collections use existing variant-shredded storage at `data/{ns}/data.parquet`\n\n### 2. $data Variant Column\n- Enabled by default for fast full-row reads (O(1) vs O(columns) reconstruction)\n- Can be disabled via `$options: { includeDataVariant: false }` for append-only logs\n- Contains complete entity as Variant/JSON\n\n### 3. Configuration API\n```typescript\nconst db = DB({\n  Occupation: {\n    $options: { includeDataVariant: true },\n    name: 'string\\!',\n    socCode: 'string\\!#',\n    jobZone: 'int',\n  },\n  Logs: {\n    $options: { includeDataVariant: false },\n    level: 'string',\n  },\n  Posts: 'flexible'  // variant-shredded mode\n})\n```\n\n### 4. Type Mapping\nComplete mapping from IceType/GraphDL to Parquet types including:\n- Primitives (string, int, float, boolean, etc.)\n- Dates/timestamps\n- JSON/binary\n- Required/optional modifiers\n- Array types\n\n### 5. Components\n- **StorageRouter**: Routes operations based on schema presence\n- **ParquetSchemaGenerator**: Converts TypeDefinition to ParquetSchema\n- **Extended ParquetWriter**: Handles typed mode with $data column\n- **Predicate Pushdown**: Native column filtering for typed mode\n\n## Implementation Issues\n\n1. **parquedb-s8yv**: StorageRouter interface and routing logic\n2. **parquedb-37c3**: ParquetSchemaGenerator for typed collections\n3. **parquedb-xi44**: ParquetWriter typed mode with $data column\n4. **parquedb-feys**: Predicate pushdown for typed mode reads\n5. **parquedb-u5lp**: $options support in collection schema\n6. **parquedb-lyuh**: Final integration into ParqueDB\n\n## Dependency Graph\n```\nparquedb-s8yv (StorageRouter)\n    |\n    +-- parquedb-37c3 (SchemaGenerator)\n    |       |\n    |       +-- parquedb-xi44 (TypedWriter)\n    |               |\n    |               +-- parquedb-feys (PredicatePushdown)\n    |\n    +-- parquedb-u5lp ($options)\n            |\n            +-- parquedb-lyuh (Integration)\n```","notes":"## Additional Design Decision: $data Variant\n\nFor typed/table mode, store BOTH native columns AND `$data` variant:\n\n```\noccupations.parquet:\n $id        (string)     # always indexed\n $data      (variant)    # full row as single value\n name       (string)     # native column\n socCode    (string)     # native column  \n ...\n```\n\n**Default: `includeDataVariant: true`**\n\nRationale:\n- 1 column read vs assembling 20+ columns for SELECT *\n- ~10-30% storage overhead for 10x read speedup on full docs\n- Can disable per-collection for append-only logs\n\nConfig:\n```typescript\nconst db = DB({\n  Occupation: { name: 'string!' },\n}, { includeDataVariant: true })\n\n// Or per-collection:\nconst db = DB({\n  Occupation: {\n    $options: { includeDataVariant: true },\n    name: 'string!',\n  },\n  Logs: {\n    $options: { includeDataVariant: false },\n    level: 'string',\n  }\n})\n```","status":"closed","priority":1,"issue_type":"feature","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T05:08:19.166639-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T06:42:13.902818-06:00","closed_at":"2026-02-03T06:42:13.902818-06:00","close_reason":"Closed"}
{"id":"parquedb-kds","title":"[GREEN] Filter comparison operators","description":"Implement comparison operators to pass tests","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:07.144286-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T13:10:43.898146-06:00","closed_at":"2026-02-01T13:10:43.898146-06:00","close_reason":"Closed"}
{"id":"parquedb-kho","title":"Implement filter evaluation","description":"Evaluate MongoDB-style filters against entity data","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:04.510805-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:03:47.525586-06:00","closed_at":"2026-02-01T14:03:47.525586-06:00","close_reason":"Closed"}
{"id":"parquedb-kpj","title":"Limit vitest parallelism to prevent OOM","description":"Agents consumed over 100GB RAM running tests. Need to limit vitest parallelism and worker count.\n\n**Solution:**\n1. Add to vitest.config.ts:\n   - `maxWorkers: 2` or `poolOptions.threads.maxThreads: 2`\n   - `minWorkers: 1`\n   - `fileParallelism: false` for memory-constrained environments\n\n2. Add CI-specific config:\n   - `--no-file-parallelism` flag\n   - `--pool=forks --poolOptions.forks.maxForks=2`\n\n3. Consider splitting test suites into smaller batches","status":"closed","priority":0,"issue_type":"bug","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T12:10:59.754266-06:00","created_by":"Nathan Clevenger","updated_at":"2026-01-30T12:11:25.25645-06:00","closed_at":"2026-01-30T12:11:25.25645-06:00","close_reason":"Added memory limiting config: maxForks=2, fileParallelism=false, maxConcurrency=5"}
{"id":"parquedb-kqs9","title":"Add index debug info to query stats and explain output","description":"Query responses and explain() output don't include index selection information. When a secondary index is used, the extended stats (indexUsed, indexType, indexLookupMs, rowGroupsTotal, rowGroupsRead) are tracked internally but not surfaced in explain(). Add: (1) index info to explain() output, (2) a /debug/query-plan endpoint that shows the full execution plan including index selection, (3) indexFallback/indexError to stats when index fails silently.","status":"closed","priority":1,"issue_type":"feature","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-02T08:27:38.885461-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-02T08:38:25.483794-06:00","closed_at":"2026-02-02T08:38:25.483794-06:00","close_reason":"Closed"}
{"id":"parquedb-l11q","title":"Add tests for embeddings module","description":"Missing test coverage for: workers-ai.ts (Workers AI embedding integration), auto-embed.ts (auto-embedding logic). These modules have no dedicated tests.","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-02T05:32:45.050975-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T03:46:31.057678-06:00","closed_at":"2026-02-03T03:46:31.057678-06:00","close_reason":"Closed"}
{"id":"parquedb-le4a","title":"Fix race condition in ID generation","description":"ID generation in ParqueDB.ts (280-298) uses non-atomic global counter. Possible duplicate IDs under concurrent access. Use atomic operations or proper ULID library.","status":"closed","priority":2,"issue_type":"bug","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-01T15:47:14.538715-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T16:07:29.136774-06:00","closed_at":"2026-02-01T16:07:29.136774-06:00","close_reason":"Closed"}
{"id":"parquedb-lh4f","title":"Simplify index build scripts","description":"Update scripts/build-indexes.mjs to only build FTS and bloom filter indexes:\n- Remove hash index building code\n- Remove SST index building code\n- Keep FTS index building\n- Keep bloom filter building\n- Update INDEX_DEFINITIONS to only include fts type\n- Update catalog format to reflect simplified structure","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-02T11:06:17.427772-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-02T11:54:07.40776-06:00","closed_at":"2026-02-02T11:54:07.40776-06:00","close_reason":"Closed"}
{"id":"parquedb-lkhc","title":"Fix CLI circular dependencies","description":"7 circular dependency cycles found: 6 in src/cli/ (commands importing from cli/index.ts which imports commands) and 1 in worker/ (index-\u003ehandlers-\u003edatasets-\u003etypes). Extract shared types into cli/types.ts and worker/handlers/types.ts.","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-02T07:16:03.748202-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-02T07:24:52.479449-06:00","closed_at":"2026-02-02T07:24:52.479449-06:00","close_reason":"Closed"}
{"id":"parquedb-ll0r","title":"Add migration utilities","description":"No tools for migrating from other databases. Create importers for: MongoDB (BSON), SQLite, JSON files. Include schema inference.","status":"closed","priority":2,"issue_type":"feature","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-01T15:47:48.510358-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T16:37:36.189699-06:00","closed_at":"2026-02-01T16:37:36.189699-06:00","close_reason":"Closed"}
{"id":"parquedb-lpi","title":"[RED] Update operator tests - array operators","description":"Write failing tests for $push, $pull, $addToSet, $pop","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:25.139486-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:08:21.743598-06:00","closed_at":"2026-02-01T14:08:21.743598-06:00","close_reason":"Closed"}
{"id":"parquedb-lte","title":"Implement update operations","description":"Update entities with optimistic concurrency","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:31.523268-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:08:21.531625-06:00","closed_at":"2026-02-01T14:08:21.531625-06:00","close_reason":"Closed"}
{"id":"parquedb-lyuh","title":"Wire StorageRouter into ParqueDB write/read paths","description":"## Context\nPart of typed storage implementation (parquedb-k7jj design). Final integration phase.\n\n## Requirements\n\n1. Update `src/ParqueDB/core.ts`:\n   - Inject StorageRouter via config\n   - Route create/update/delete through router\n   - Route find/get through router\n\n2. Update `src/db.ts`:\n   - Create StorageRouter with schema info\n   - Pass router to ParqueDB constructor\n\n3. Ensure backward compatibility:\n   - Collections without schema use flexible mode\n   - Existing APIs unchanged\n   - Migration path documented\n\n4. Testing:\n   - Integration tests with mixed mode collections\n   - E2E tests with typed + flexible collections\n   - Verify existing tests still pass\n\n## Acceptance Criteria\n- [ ] StorageRouter integrated into ParqueDB\n- [ ] Typed collections use native columns\n- [ ] Flexible collections use variant-shredded storage\n- [ ] Mixed mode works (some typed, some flexible)\n- [ ] All existing tests pass\n- [ ] New integration tests pass\n\n## References\n- Design: docs/architecture/typed-storage.md\n- Depends on:\n  - parquedb-s8yv (StorageRouter)\n  - parquedb-37c3 (ParquetSchemaGenerator)\n  - parquedb-xi44 (ParquetWriter typed mode)\n  - parquedb-feys (Predicate pushdown)\n  - parquedb-u5lp ($options support)","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:41:57.219105-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T07:22:10.179878-06:00","closed_at":"2026-02-03T07:22:10.179878-06:00","close_reason":"Implemented with full test coverage"}
{"id":"parquedb-m4va","title":"[FEATURE] Cloudflare Workers AI integration with m3 embeddings","description":"Integrate ParqueDB with Cloudflare Workers AI for automatic embedding generation.\n\nRequirements:\n1. Add Cloudflare Workers AI binding support (AI binding in wrangler.toml)\n2. Use @cf/baai/bge-m3 as default embedding model (1024 dimensions)\n3. Auto-generate embeddings for fields with $vector index on create/update\n4. Support $embed operator for manual embedding generation\n5. Wire into fuzzy relations (~\u003e and \u003c~) for semantic matching\n6. Add comprehensive tests for embedding generation and vector search\n\nConfiguration:\n- AI binding: env.AI\n- Default model: @cf/baai/bge-m3\n- Dimensions: 1024\n- Support for alternative models via options","status":"closed","priority":1,"issue_type":"feature","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-01T14:47:08.337581-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:54:28.269378-06:00","closed_at":"2026-02-01T14:54:28.269378-06:00","close_reason":"Closed"}
{"id":"parquedb-m9fx","title":"Add dataset config for events mode","description":"Support per-dataset configuration for events:\n\n```json\n{\n  \"events\": true,\n  \"compaction\": { \"interval\": \"1h\", \"retention\": \"30d\" }\n}\n```\n\n- events: false (default) = read-only snapshot mode (simple datasets like IMDB)\n- events: true = mutable with history, time-travel enabled\n- Wire config into write path to emit events\n- Wire config into read path to support { at: timestamp }\n\nFile: src/config/dataset.ts","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-01T06:38:02.153055-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T07:19:51.747086-06:00","closed_at":"2026-02-01T07:19:51.747086-06:00","close_reason":"Created DatasetConfigManager with events enable/disable, compaction config, time-travel validation, and helper functions. All 32 tests passing.","dependencies":[{"issue_id":"parquedb-m9fx","depends_on_id":"parquedb-69um","type":"blocks","created_at":"2026-02-01T06:38:12.324415-06:00","created_by":"Nathan Clevenger"}]}
{"id":"parquedb-mbvg","title":"Add ReDoS protection for regex filters","description":"User-provided regex patterns in $regex operator are passed directly to new RegExp() without validation (Collection.ts 313-322, predicate.ts 459-465). Add regex complexity limits or use safe-regex library.","status":"closed","priority":2,"issue_type":"bug","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-01T15:47:12.250144-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T16:10:46.088303-06:00","closed_at":"2026-02-01T16:10:46.088303-06:00","close_reason":"Closed"}
{"id":"parquedb-mdcx","title":"Fix WebAssembly/hysnappy compatibility in Workers","description":"hysnappy WebAssembly instantiation fails in Worker environment. Affects Worker benchmark tests. 2 unhandled errors blocking Worker deployment.","status":"closed","priority":0,"issue_type":"bug","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-01T12:42:08.494592-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T13:15:17.983075-06:00","closed_at":"2026-02-01T13:15:17.983075-06:00","close_reason":"Closed"}
{"id":"parquedb-mf7","title":"Implement delete operations","description":"Soft delete with optional hard delete","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:34.366659-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:06:19.085913-06:00","closed_at":"2026-02-01T14:06:19.085913-06:00","close_reason":"Closed"}
{"id":"parquedb-mhhm","title":"Consolidate entity storage - remove dual implementation","description":"ParqueDB.ts maintains in-memory globalEntityStore while ParqueDBDO uses SQLite, creating confusion about source of truth. Remove in-memory store from ParqueDB.ts, make ParqueDBDO the single write authority. ParqueDB.ts should be a thin client or removed.","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-01T15:47:18.387768-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T16:48:22.455635-06:00","closed_at":"2026-02-01T16:48:22.455635-06:00","close_reason":"Closed"}
{"id":"parquedb-mj0o","title":"Validate HTTP inputs in worker handlers","description":"worker/handlers/ns.ts casts request.json() directly to domain types without validation. routing.ts parseQueryFilter returns empty filter {} on invalid JSON (silent data leak). Add input validation for create/update payloads and return 400 on invalid filter JSON.","status":"closed","priority":1,"issue_type":"bug","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-02T07:16:01.727855-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-02T07:24:54.206345-06:00","closed_at":"2026-02-02T07:24:54.206345-06:00","close_reason":"Closed"}
{"id":"parquedb-mrti","title":"Update benchmark to use native pushdown","description":"Refactor benchmark-indexed.ts to test native parquet predicate pushdown instead of secondary indexes:\n- Remove indexed vs scan comparison (both now use same path)\n- Benchmark pushdown filter performance on $index_* columns\n- Test row-group skipping effectiveness\n- Measure latency with different selectivity levels\n- Update benchmark queries to use direct filters","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-02T11:06:15.375126-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-02T12:00:29.841592-06:00","closed_at":"2026-02-02T12:00:29.841592-06:00","close_reason":"Closed"}
{"id":"parquedb-muwo","title":"Refactor: types.ts - Consolidate re-exports to prevent circular dependencies","description":"In src/ParqueDB/types.ts, lines 426-446 re-export types from '../types':\n\n```typescript\nexport type {\n  Entity,\n  EntityId,\n  CreateInput,\n  PaginatedResult,\n  DeleteResult,\n  Filter,\n  UpdateInput,\n  FindOptions,\n  // ... more\n}\n```\n\nAnd then src/ParqueDB.ts imports from both:\n```typescript\nimport type { Entity, ... } from './types'\nimport type { ParqueDBConfig, ... } from './ParqueDB/types'\n```\n\nThis creates potential confusion about where types should be imported from. Consider:\n\n1. Make src/ParqueDB/types.ts the internal-only types module (no re-exports)\n2. Import core types directly from '../types' in consuming files\n3. Or create a single types barrel file that re-exports everything\n\nCurrent structure risks:\n- Circular import issues if not careful\n- Developer confusion about canonical import paths\n- Duplicate type re-exports increase bundle complexity","status":"open","priority":3,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:34:10.511051-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T06:34:10.511051-06:00","labels":["architecture","refactor","types"]}
{"id":"parquedb-mvw","title":"Implement GraphDL schema integration","description":"Parse GraphDL schemas for ParqueDB","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:52:04.26749-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:18:31.938852-06:00","closed_at":"2026-02-01T14:18:31.938852-06:00","close_reason":"Closed"}
{"id":"parquedb-mwj","title":"[RED] FTS tests","description":"Write failing tests for $text operator and ranking","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:54.420118-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:27:18.710594-06:00","closed_at":"2026-02-01T14:27:18.710594-06:00","close_reason":"Closed"}
{"id":"parquedb-mz5h","title":"Epic: Website \u0026 Documentation","description":"Complete overhaul of ParqueDB documentation for user-facing website at parquedb.com. Each content section needs three phases: write (initial draft), edit (technical review), rewrite (polish for users).","status":"open","priority":1,"issue_type":"feature","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T05:59:59.975536-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T05:59:59.975536-06:00"}
{"id":"parquedb-mz5h.1","title":"Write: Getting Started","description":"Create comprehensive Getting Started guide covering installation, prerequisites, first steps, and common patterns.","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:00:15.188312-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T07:22:10.18622-06:00","closed_at":"2026-02-03T07:22:10.18622-06:00","close_reason":"Implemented with full test coverage","dependencies":[{"issue_id":"parquedb-mz5h.1","depends_on_id":"parquedb-mz5h","type":"parent-child","created_at":"2026-02-03T06:00:15.189063-06:00","created_by":"Nathan Clevenger"}]}
{"id":"parquedb-mz5h.10","title":"Edit: Query API","description":"Technical review of Query API guide. Verify filter operators work correctly, check edge cases, ensure all options documented.","status":"in_progress","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:00:32.08335-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T07:34:02.647009-06:00","dependencies":[{"issue_id":"parquedb-mz5h.10","depends_on_id":"parquedb-mz5h","type":"parent-child","created_at":"2026-02-03T06:00:32.084119-06:00","created_by":"Nathan Clevenger"},{"issue_id":"parquedb-mz5h.10","depends_on_id":"parquedb-mz5h.3","type":"blocks","created_at":"2026-02-03T06:00:32.085085-06:00","created_by":"Nathan Clevenger"}]}
{"id":"parquedb-mz5h.11","title":"Edit: Update Operators","description":"Technical review of Update Operators guide. Verify all operators work as documented, check edge cases, ensure MongoDB compatibility notes are accurate.","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:00:32.699567-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T07:35:55.710072-06:00","closed_at":"2026-02-03T07:35:55.710072-06:00","close_reason":"Closed","dependencies":[{"issue_id":"parquedb-mz5h.11","depends_on_id":"parquedb-mz5h","type":"parent-child","created_at":"2026-02-03T06:00:32.700318-06:00","created_by":"Nathan Clevenger"},{"issue_id":"parquedb-mz5h.11","depends_on_id":"parquedb-mz5h.4","type":"blocks","created_at":"2026-02-03T06:00:32.701694-06:00","created_by":"Nathan Clevenger"}]}
{"id":"parquedb-mz5h.12","title":"Edit: ParqueDB Class API","description":"Technical review of ParqueDB Class API reference (api/parquedb.md) for accuracy and completeness. Verify method signatures match implementation, check parameter types, validate examples, ensure all edge cases are documented.","status":"open","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:00:32.94642-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T06:00:32.94642-06:00","dependencies":[{"issue_id":"parquedb-mz5h.12","depends_on_id":"parquedb-mz5h","type":"parent-child","created_at":"2026-02-03T06:00:32.947264-06:00","created_by":"Nathan Clevenger"},{"issue_id":"parquedb-mz5h.12","depends_on_id":"parquedb-mz5h.5","type":"blocks","created_at":"2026-02-03T06:00:32.948191-06:00","created_by":"Nathan Clevenger"}]}
{"id":"parquedb-mz5h.13","title":"Write: Architecture Docs","description":"Create and review all architecture documentation for ParqueDB. This includes all documents in docs/architecture/ covering:\n- GRAPH_FIRST_ARCHITECTURE.md - Relationship indexing\n- SECONDARY_INDEXES.md - Index types and strategies  \n- BLOOM_FILTER_INDEXES.md - Probabilistic indexes\n- NAMESPACE_SHARDED_ARCHITECTURE.md - Multi-tenant sharding\n- ENTITY_STORAGE.md - Dual storage architecture\n- Any other architecture documents\n\nTasks:\n- Review existing architecture docs for accuracy\n- Fill in any missing sections\n- Ensure consistency across documents\n- Add diagrams where helpful","status":"in_progress","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:00:34.297018-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T07:34:00.594589-06:00","labels":["architecture","docs"],"dependencies":[{"issue_id":"parquedb-mz5h.13","depends_on_id":"parquedb-mz5h","type":"parent-child","created_at":"2026-02-03T06:00:34.297899-06:00","created_by":"Nathan Clevenger"}]}
{"id":"parquedb-mz5h.14","title":"Edit: Collection Class API","description":"Technical review of Collection Class API reference (api/collection.md) for accuracy and completeness. Verify method signatures match implementation, check filter/update operator coverage, validate examples, ensure all edge cases are documented.","status":"open","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:00:34.631331-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T06:00:34.631331-06:00","dependencies":[{"issue_id":"parquedb-mz5h.14","depends_on_id":"parquedb-mz5h","type":"parent-child","created_at":"2026-02-03T06:00:34.632155-06:00","created_by":"Nathan Clevenger"},{"issue_id":"parquedb-mz5h.14","depends_on_id":"parquedb-mz5h.6","type":"blocks","created_at":"2026-02-03T06:00:34.633171-06:00","created_by":"Nathan Clevenger"}]}
{"id":"parquedb-mz5h.15","title":"Write: Cloudflare Workers Deployment","description":"Create initial draft with comprehensive content for deployment/cloudflare-workers.md. Cover wrangler setup, DO configuration, R2 binding, worker entry points, and environment variables.","status":"open","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:00:35.527107-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T06:00:35.527107-06:00","dependencies":[{"issue_id":"parquedb-mz5h.15","depends_on_id":"parquedb-mz5h","type":"parent-child","created_at":"2026-02-03T06:00:35.527833-06:00","created_by":"Nathan Clevenger"}]}
{"id":"parquedb-mz5h.16","title":"Edit: Benchmarks","description":"Technical review of benchmarks documentation (benchmarks.md) for accuracy and completeness. Verify benchmark methodology is sound, check that numbers are reproducible, validate comparison methodology, ensure test environment is documented.","status":"open","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:00:35.854746-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T06:00:35.854746-06:00","dependencies":[{"issue_id":"parquedb-mz5h.16","depends_on_id":"parquedb-mz5h","type":"parent-child","created_at":"2026-02-03T06:00:35.855492-06:00","created_by":"Nathan Clevenger"},{"issue_id":"parquedb-mz5h.16","depends_on_id":"parquedb-mz5h.7","type":"blocks","created_at":"2026-02-03T06:00:35.856383-06:00","created_by":"Nathan Clevenger"}]}
{"id":"parquedb-mz5h.17","title":"Write: Homepage","description":"Create compelling homepage content for ParqueDB website.\n\nTasks:\n- Write hero section with clear value proposition\n- Create feature highlights section\n- Write getting started quick guide\n- Add code examples showcasing key features\n- Include comparison with alternatives\n- Design call-to-action sections","status":"open","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:00:36.188774-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T06:00:36.188774-06:00","labels":["docs","homepage"],"dependencies":[{"issue_id":"parquedb-mz5h.17","depends_on_id":"parquedb-mz5h","type":"parent-child","created_at":"2026-02-03T06:00:36.189394-06:00","created_by":"Nathan Clevenger"}]}
{"id":"parquedb-mz5h.18","title":"Rewrite: Getting Started","description":"Polish Getting Started guide for user-facing website. Improve clarity, add helpful tips, ensure engaging tone.","status":"open","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:00:37.670306-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T06:00:37.670306-06:00","dependencies":[{"issue_id":"parquedb-mz5h.18","depends_on_id":"parquedb-mz5h","type":"parent-child","created_at":"2026-02-03T06:00:37.671052-06:00","created_by":"Nathan Clevenger"},{"issue_id":"parquedb-mz5h.18","depends_on_id":"parquedb-mz5h.8","type":"blocks","created_at":"2026-02-03T06:00:37.672006-06:00","created_by":"Nathan Clevenger"}]}
{"id":"parquedb-mz5h.19","title":"Write: Node.js Standalone Deployment","description":"Create initial draft with comprehensive content for deployment/node-standalone.md. Cover npm installation, filesystem storage setup, basic server configuration, and production considerations.","status":"open","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:00:38.084905-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T06:00:38.084905-06:00","dependencies":[{"issue_id":"parquedb-mz5h.19","depends_on_id":"parquedb-mz5h","type":"parent-child","created_at":"2026-02-03T06:00:38.08571-06:00","created_by":"Nathan Clevenger"}]}
{"id":"parquedb-mz5h.2","title":"Write: Schema Definition","description":"Create comprehensive Schema Definition guide covering schema syntax, types, relationships, validation, and best practices.","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:00:16.246551-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T07:25:22.119577-06:00","closed_at":"2026-02-03T07:25:22.119577-06:00","close_reason":"Closed","dependencies":[{"issue_id":"parquedb-mz5h.2","depends_on_id":"parquedb-mz5h","type":"parent-child","created_at":"2026-02-03T06:00:16.247234-06:00","created_by":"Nathan Clevenger"}]}
{"id":"parquedb-mz5h.20","title":"Rewrite: Schema Definition","description":"Polish Schema Definition guide for user-facing website. Improve clarity, add helpful examples, ensure engaging tone.","status":"open","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:00:38.576858-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T06:00:38.576858-06:00","dependencies":[{"issue_id":"parquedb-mz5h.20","depends_on_id":"parquedb-mz5h","type":"parent-child","created_at":"2026-02-03T06:00:38.577572-06:00","created_by":"Nathan Clevenger"},{"issue_id":"parquedb-mz5h.20","depends_on_id":"parquedb-mz5h.9","type":"blocks","created_at":"2026-02-03T06:00:38.578529-06:00","created_by":"Nathan Clevenger"}]}
{"id":"parquedb-mz5h.21","title":"Write: R2 Setup","description":"Create initial draft with comprehensive content for deployment/r2-setup.md. Cover bucket creation, IAM permissions, CORS configuration, binding to workers, and data migration.","status":"open","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:00:38.70068-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T06:00:38.70068-06:00","dependencies":[{"issue_id":"parquedb-mz5h.21","depends_on_id":"parquedb-mz5h","type":"parent-child","created_at":"2026-02-03T06:00:38.701513-06:00","created_by":"Nathan Clevenger"}]}
{"id":"parquedb-mz5h.22","title":"Write: Configuration Reference","description":"Create initial draft with comprehensive content for deployment/configuration.md. Document all configuration options, environment variables, storage backend options, and performance tuning parameters.","status":"open","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:00:39.261638-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T06:00:39.261638-06:00","dependencies":[{"issue_id":"parquedb-mz5h.22","depends_on_id":"parquedb-mz5h","type":"parent-child","created_at":"2026-02-03T06:00:39.262261-06:00","created_by":"Nathan Clevenger"}]}
{"id":"parquedb-mz5h.23","title":"Rewrite: Query API","description":"Polish Query API guide for user-facing website. Improve clarity, add real-world examples, ensure engaging tone.","status":"open","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:00:39.504873-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T06:00:39.504873-06:00","dependencies":[{"issue_id":"parquedb-mz5h.23","depends_on_id":"parquedb-mz5h","type":"parent-child","created_at":"2026-02-03T06:00:39.50558-06:00","created_by":"Nathan Clevenger"},{"issue_id":"parquedb-mz5h.23","depends_on_id":"parquedb-mz5h.10","type":"blocks","created_at":"2026-02-03T06:00:39.506607-06:00","created_by":"Nathan Clevenger"}]}
{"id":"parquedb-mz5h.24","title":"Rewrite: ParqueDB Class API","description":"Polish ParqueDB Class API reference (api/parquedb.md) for user-facing clarity and engagement. Improve readability, add helpful context, ensure consistent tone, add cross-references to related documentation, optimize for developer experience.","status":"open","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:00:39.98886-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T06:00:39.98886-06:00","dependencies":[{"issue_id":"parquedb-mz5h.24","depends_on_id":"parquedb-mz5h","type":"parent-child","created_at":"2026-02-03T06:00:39.989553-06:00","created_by":"Nathan Clevenger"},{"issue_id":"parquedb-mz5h.24","depends_on_id":"parquedb-mz5h.12","type":"blocks","created_at":"2026-02-03T06:00:39.990512-06:00","created_by":"Nathan Clevenger"}]}
{"id":"parquedb-mz5h.25","title":"Rewrite: Update Operators","description":"Polish Update Operators guide for user-facing website. Improve clarity, add practical examples, ensure engaging tone.","status":"open","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:00:40.727589-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T06:00:40.727589-06:00","dependencies":[{"issue_id":"parquedb-mz5h.25","depends_on_id":"parquedb-mz5h","type":"parent-child","created_at":"2026-02-03T06:00:40.728491-06:00","created_by":"Nathan Clevenger"},{"issue_id":"parquedb-mz5h.25","depends_on_id":"parquedb-mz5h.11","type":"blocks","created_at":"2026-02-03T06:00:40.729597-06:00","created_by":"Nathan Clevenger"}]}
{"id":"parquedb-mz5h.26","title":"Edit: Architecture Docs","description":"Technical review of all ParqueDB architecture documentation.\n\nTasks:\n- Verify technical accuracy of all architecture docs\n- Check code examples compile and work\n- Ensure diagrams match current implementation\n- Review for completeness and clarity\n- Flag any outdated information\n- Suggest improvements for technical depth","status":"open","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:00:41.434095-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T06:00:41.434095-06:00","labels":["architecture","docs"],"dependencies":[{"issue_id":"parquedb-mz5h.26","depends_on_id":"parquedb-mz5h","type":"parent-child","created_at":"2026-02-03T06:00:41.435155-06:00","created_by":"Nathan Clevenger"},{"issue_id":"parquedb-mz5h.26","depends_on_id":"parquedb-mz5h.13","type":"blocks","created_at":"2026-02-03T06:00:41.436642-06:00","created_by":"Nathan Clevenger"}]}
{"id":"parquedb-mz5h.27","title":"Rewrite: Collection Class API","description":"Polish Collection Class API reference (api/collection.md) for user-facing clarity and engagement. Improve readability, add helpful context, ensure consistent tone, add cross-references to related documentation, optimize for developer experience.","status":"open","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:00:41.476816-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T06:00:41.476816-06:00","dependencies":[{"issue_id":"parquedb-mz5h.27","depends_on_id":"parquedb-mz5h","type":"parent-child","created_at":"2026-02-03T06:00:41.477461-06:00","created_by":"Nathan Clevenger"},{"issue_id":"parquedb-mz5h.27","depends_on_id":"parquedb-mz5h.14","type":"blocks","created_at":"2026-02-03T06:00:41.478611-06:00","created_by":"Nathan Clevenger"}]}
{"id":"parquedb-mz5h.28","title":"Rewrite: Benchmarks","description":"Polish benchmarks documentation (benchmarks.md) for user-facing clarity and engagement. Add visualizations or tables, improve narrative flow, ensure results are presented clearly, add actionable insights for performance optimization.","status":"open","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:00:42.534961-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T06:00:42.534961-06:00","dependencies":[{"issue_id":"parquedb-mz5h.28","depends_on_id":"parquedb-mz5h","type":"parent-child","created_at":"2026-02-03T06:00:42.535747-06:00","created_by":"Nathan Clevenger"},{"issue_id":"parquedb-mz5h.28","depends_on_id":"parquedb-mz5h.16","type":"blocks","created_at":"2026-02-03T06:00:42.536981-06:00","created_by":"Nathan Clevenger"}]}
{"id":"parquedb-mz5h.29","title":"Edit: Homepage","description":"Review homepage content for ParqueDB website.\n\nTasks:\n- Review copy for clarity and impact\n- Verify code examples work correctly\n- Check technical accuracy of claims\n- Ensure messaging resonates with target audience\n- Review flow and user journey\n- Suggest improvements for conversion","status":"open","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:00:43.261714-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T06:00:43.261714-06:00","labels":["docs","homepage"],"dependencies":[{"issue_id":"parquedb-mz5h.29","depends_on_id":"parquedb-mz5h","type":"parent-child","created_at":"2026-02-03T06:00:43.262379-06:00","created_by":"Nathan Clevenger"},{"issue_id":"parquedb-mz5h.29","depends_on_id":"parquedb-mz5h.17","type":"blocks","created_at":"2026-02-03T06:00:43.264-06:00","created_by":"Nathan Clevenger"}]}
{"id":"parquedb-mz5h.3","title":"Write: Query API","description":"Create comprehensive Query API guide covering find operations, filter operators, projections, sorting, pagination, and relationship traversal.","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:00:17.276148-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T07:26:06.618671-06:00","closed_at":"2026-02-03T07:26:06.618671-06:00","close_reason":"Closed","dependencies":[{"issue_id":"parquedb-mz5h.3","depends_on_id":"parquedb-mz5h","type":"parent-child","created_at":"2026-02-03T06:00:17.276838-06:00","created_by":"Nathan Clevenger"}]}
{"id":"parquedb-mz5h.30","title":"Edit: Cloudflare Workers Deployment","description":"Technical review for accuracy and completeness of deployment/cloudflare-workers.md. Verify code examples work, check for missing steps, ensure wrangler commands are current.","status":"open","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:00:44.387591-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T06:00:44.387591-06:00","dependencies":[{"issue_id":"parquedb-mz5h.30","depends_on_id":"parquedb-mz5h","type":"parent-child","created_at":"2026-02-03T06:00:44.388195-06:00","created_by":"Nathan Clevenger"},{"issue_id":"parquedb-mz5h.30","depends_on_id":"parquedb-mz5h.15","type":"blocks","created_at":"2026-02-03T06:00:44.38948-06:00","created_by":"Nathan Clevenger"}]}
{"id":"parquedb-mz5h.31","title":"Edit: Node.js Standalone Deployment","description":"Technical review for accuracy and completeness of deployment/node-standalone.md. Verify code examples work, check for missing steps, test installation instructions.","status":"open","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:00:46.155685-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T06:00:46.155685-06:00","dependencies":[{"issue_id":"parquedb-mz5h.31","depends_on_id":"parquedb-mz5h","type":"parent-child","created_at":"2026-02-03T06:00:46.156408-06:00","created_by":"Nathan Clevenger"},{"issue_id":"parquedb-mz5h.31","depends_on_id":"parquedb-mz5h.19","type":"blocks","created_at":"2026-02-03T06:00:46.157582-06:00","created_by":"Nathan Clevenger"}]}
{"id":"parquedb-mz5h.32","title":"Edit: R2 Setup","description":"Technical review for accuracy and completeness of deployment/r2-setup.md. Verify bucket creation steps, IAM policies, CORS configuration, and binding examples are correct.","status":"open","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:00:46.772137-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T06:00:46.772137-06:00","dependencies":[{"issue_id":"parquedb-mz5h.32","depends_on_id":"parquedb-mz5h","type":"parent-child","created_at":"2026-02-03T06:00:46.773023-06:00","created_by":"Nathan Clevenger"},{"issue_id":"parquedb-mz5h.32","depends_on_id":"parquedb-mz5h.21","type":"blocks","created_at":"2026-02-03T06:00:46.774185-06:00","created_by":"Nathan Clevenger"}]}
{"id":"parquedb-mz5h.33","title":"Edit: Configuration Reference","description":"Technical review for accuracy and completeness of deployment/configuration.md. Verify all options are documented, defaults are correct, and examples are functional.","status":"open","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:00:47.385037-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T06:00:47.385037-06:00","dependencies":[{"issue_id":"parquedb-mz5h.33","depends_on_id":"parquedb-mz5h","type":"parent-child","created_at":"2026-02-03T06:00:47.385679-06:00","created_by":"Nathan Clevenger"},{"issue_id":"parquedb-mz5h.33","depends_on_id":"parquedb-mz5h.22","type":"blocks","created_at":"2026-02-03T06:00:47.387088-06:00","created_by":"Nathan Clevenger"}]}
{"id":"parquedb-mz5h.34","title":"Rewrite: Architecture Docs","description":"Polish architecture documentation for user-facing website.\n\nTasks:\n- Rewrite for broader audience accessibility\n- Improve narrative flow across documents\n- Add executive summaries to each document\n- Create visual aids and diagrams\n- Ensure consistent voice and tone\n- Optimize for discoverability (SEO)\n- Final proofread and formatting","status":"open","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:00:48.297224-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T06:00:48.297224-06:00","labels":["architecture","docs"],"dependencies":[{"issue_id":"parquedb-mz5h.34","depends_on_id":"parquedb-mz5h","type":"parent-child","created_at":"2026-02-03T06:00:48.297952-06:00","created_by":"Nathan Clevenger"},{"issue_id":"parquedb-mz5h.34","depends_on_id":"parquedb-mz5h.26","type":"blocks","created_at":"2026-02-03T06:00:48.299477-06:00","created_by":"Nathan Clevenger"}]}
{"id":"parquedb-mz5h.35","title":"Rewrite: Homepage","description":"Polish homepage for ParqueDB launch.\n\nTasks:\n- Final copy polish for impact\n- Optimize for conversion\n- Ensure mobile responsiveness considerations\n- Final proofread\n- A/B test headline options\n- Prepare for launch","status":"open","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:00:50.571829-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T06:00:50.571829-06:00","labels":["docs","homepage"],"dependencies":[{"issue_id":"parquedb-mz5h.35","depends_on_id":"parquedb-mz5h","type":"parent-child","created_at":"2026-02-03T06:00:50.57248-06:00","created_by":"Nathan Clevenger"},{"issue_id":"parquedb-mz5h.35","depends_on_id":"parquedb-mz5h.29","type":"blocks","created_at":"2026-02-03T06:00:50.573819-06:00","created_by":"Nathan Clevenger"}]}
{"id":"parquedb-mz5h.36","title":"Rewrite: Cloudflare Workers Deployment","description":"Polish deployment/cloudflare-workers.md for user-facing clarity and engagement. Improve readability, add helpful tips, ensure consistent tone, optimize for developer experience.","status":"open","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:00:51.864733-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T06:00:51.864733-06:00","dependencies":[{"issue_id":"parquedb-mz5h.36","depends_on_id":"parquedb-mz5h","type":"parent-child","created_at":"2026-02-03T06:00:51.865419-06:00","created_by":"Nathan Clevenger"},{"issue_id":"parquedb-mz5h.36","depends_on_id":"parquedb-mz5h.30","type":"blocks","created_at":"2026-02-03T06:00:51.866842-06:00","created_by":"Nathan Clevenger"}]}
{"id":"parquedb-mz5h.37","title":"Rewrite: Node.js Standalone Deployment","description":"Polish deployment/node-standalone.md for user-facing clarity and engagement. Improve readability, add helpful tips, ensure consistent tone, optimize for developer experience.","status":"open","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:00:52.798539-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T06:00:52.798539-06:00","dependencies":[{"issue_id":"parquedb-mz5h.37","depends_on_id":"parquedb-mz5h","type":"parent-child","created_at":"2026-02-03T06:00:52.79918-06:00","created_by":"Nathan Clevenger"},{"issue_id":"parquedb-mz5h.37","depends_on_id":"parquedb-mz5h.31","type":"blocks","created_at":"2026-02-03T06:00:52.800303-06:00","created_by":"Nathan Clevenger"}]}
{"id":"parquedb-mz5h.38","title":"Rewrite: R2 Setup","description":"Polish deployment/r2-setup.md for user-facing clarity and engagement. Improve readability, add helpful tips, ensure consistent tone, optimize for developer experience.","status":"open","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:00:53.784786-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T06:00:53.784786-06:00","dependencies":[{"issue_id":"parquedb-mz5h.38","depends_on_id":"parquedb-mz5h","type":"parent-child","created_at":"2026-02-03T06:00:53.785665-06:00","created_by":"Nathan Clevenger"},{"issue_id":"parquedb-mz5h.38","depends_on_id":"parquedb-mz5h.32","type":"blocks","created_at":"2026-02-03T06:00:53.786922-06:00","created_by":"Nathan Clevenger"}]}
{"id":"parquedb-mz5h.39","title":"Rewrite: Configuration Reference","description":"Polish deployment/configuration.md for user-facing clarity and engagement. Improve readability, add helpful tips, ensure consistent tone, optimize for developer experience.","status":"open","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:00:54.488738-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T06:00:54.488738-06:00","dependencies":[{"issue_id":"parquedb-mz5h.39","depends_on_id":"parquedb-mz5h","type":"parent-child","created_at":"2026-02-03T06:00:54.489446-06:00","created_by":"Nathan Clevenger"},{"issue_id":"parquedb-mz5h.39","depends_on_id":"parquedb-mz5h.33","type":"blocks","created_at":"2026-02-03T06:00:54.490792-06:00","created_by":"Nathan Clevenger"}]}
{"id":"parquedb-mz5h.4","title":"Write: Update Operators","description":"Create comprehensive Update Operators guide covering $set, $inc, $push, $pull, $unset, and other MongoDB-style update operators with examples.","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:00:18.486721-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T07:25:33.278677-06:00","closed_at":"2026-02-03T07:25:33.278677-06:00","close_reason":"Closed","dependencies":[{"issue_id":"parquedb-mz5h.4","depends_on_id":"parquedb-mz5h","type":"parent-child","created_at":"2026-02-03T06:00:18.487508-06:00","created_by":"Nathan Clevenger"}]}
{"id":"parquedb-mz5h.5","title":"Write: ParqueDB Class API","description":"Create comprehensive ParqueDB Class API reference (api/parquedb.md) with all methods, parameters, return types, and examples. Cover constructor options, collection access, database-level operations, and RpcTarget integration.","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:00:18.569606-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T07:26:03.80648-06:00","closed_at":"2026-02-03T07:26:03.80648-06:00","close_reason":"Closed","dependencies":[{"issue_id":"parquedb-mz5h.5","depends_on_id":"parquedb-mz5h","type":"parent-child","created_at":"2026-02-03T06:00:18.570448-06:00","created_by":"Nathan Clevenger"}]}
{"id":"parquedb-mz5h.6","title":"Write: Collection Class API","description":"Create comprehensive Collection Class API reference (api/collection.md) with all CRUD methods, query operations, filter operators, update operators, and examples. Cover find, findOne, create, update, delete, and relationship methods.","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:00:20.13454-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T07:26:09.614472-06:00","closed_at":"2026-02-03T07:26:09.614472-06:00","close_reason":"Closed","dependencies":[{"issue_id":"parquedb-mz5h.6","depends_on_id":"parquedb-mz5h","type":"parent-child","created_at":"2026-02-03T06:00:20.135514-06:00","created_by":"Nathan Clevenger"}]}
{"id":"parquedb-mz5h.7","title":"Write: Benchmarks","description":"Create comprehensive benchmarks documentation (benchmarks.md) covering performance targets, benchmark methodology, test results for CRUD operations, query performance, relationship traversal, and comparison with other databases.","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:00:21.859992-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T07:28:52.232576-06:00","closed_at":"2026-02-03T07:28:52.232576-06:00","close_reason":"Closed","dependencies":[{"issue_id":"parquedb-mz5h.7","depends_on_id":"parquedb-mz5h","type":"parent-child","created_at":"2026-02-03T06:00:21.860837-06:00","created_by":"Nathan Clevenger"}]}
{"id":"parquedb-mz5h.8","title":"Edit: Getting Started","description":"Technical review of Getting Started guide. Verify code examples work, check for accuracy, ensure completeness.","status":"in_progress","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:00:29.745702-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T07:33:51.17626-06:00","dependencies":[{"issue_id":"parquedb-mz5h.8","depends_on_id":"parquedb-mz5h","type":"parent-child","created_at":"2026-02-03T06:00:29.752068-06:00","created_by":"Nathan Clevenger"},{"issue_id":"parquedb-mz5h.8","depends_on_id":"parquedb-mz5h.1","type":"blocks","created_at":"2026-02-03T06:00:29.753101-06:00","created_by":"Nathan Clevenger"}]}
{"id":"parquedb-mz5h.9","title":"Edit: Schema Definition","description":"Technical review of Schema Definition guide. Verify syntax examples, check type definitions, ensure all features documented.","status":"in_progress","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:00:31.272092-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T07:33:52.914456-06:00","dependencies":[{"issue_id":"parquedb-mz5h.9","depends_on_id":"parquedb-mz5h","type":"parent-child","created_at":"2026-02-03T06:00:31.272746-06:00","created_by":"Nathan Clevenger"},{"issue_id":"parquedb-mz5h.9","depends_on_id":"parquedb-mz5h.2","type":"blocks","created_at":"2026-02-03T06:00:31.273625-06:00","created_by":"Nathan Clevenger"}]}
{"id":"parquedb-mzo","title":"[RED] FsxBackend tests","description":"Write failing tests for FsxBackend","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:55.543677-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-02T04:45:58.941067-06:00","closed_at":"2026-02-02T04:45:58.941067-06:00","close_reason":"Tests implemented in earlier waves"}
{"id":"parquedb-n3jx","title":"Refactor: core.ts delete() - Remove heuristic-based ID validation","description":"In src/ParqueDB/core.ts, the delete() method (lines 1160-1238) contains questionable heuristic-based ID validation (lines 1183-1194):\n\n```typescript\n// Check if this looks like a valid entity ID (not a 'nonexistent' placeholder)\nconst looksLikeValidId = idPart.length \u003e 0 \u0026\u0026\n  !idPart.toLowerCase().includes('nonexistent') \u0026\u0026\n  !idPart.toLowerCase().includes('invalid') \u0026\u0026\n  !idPart.toLowerCase().includes('missing')\n\nif (!looksLikeValidId) {\n  return { deletedCount: 0 }\n}\n\n// Treat as existing in storage (soft delete behavior)\nreturn { deletedCount: 1 }\n```\n\nIssues:\n1. Checking for 'nonexistent', 'invalid', 'missing' strings is brittle\n2. Returning deletedCount: 1 for non-existent entities is incorrect semantics\n3. The comment 'handles case where entity exists in persistent storage but not in memory cache' suggests a sync issue that should be fixed properly\n\nThis should either:\n1. Check actual storage for entity existence\n2. Or consistently return { deletedCount: 0 } when entity not in memory\n3. Document why this behavior exists if intentional","status":"open","priority":3,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:33:44.144222-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T06:33:44.144222-06:00","labels":["bug-risk","code-quality","refactor"]}
{"id":"parquedb-n7bp","title":"Add CI check for deployed dataset availability","description":"## Problem\nDataset files can go missing in R2 without any automated detection.\nThis production issue went unnoticed until a user hit the endpoint.\n\n## Solution\nAdd CI/CD check that verifies all configured datasets have their files in R2:\n\n1. After deployment, run a smoke test that:\n   - Hits each /datasets/{dataset}/{collection} endpoint\n   - Verifies 200 response\n   - Verifies response contains data\n\n2. Add scheduled health check:\n   - Cron job that pings dataset endpoints\n   - Alert if any return non-200\n\n3. Add R2 file existence check:\n   - Script that lists expected files vs actual files in R2\n   - Run as part of deploy pipeline\n\n## Files to create/modify\n- scripts/check-datasets.mjs - verify dataset files exist\n- .github/workflows/deploy.yml - add post-deploy smoke test\n- OR add to existing CI workflow","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T02:54:57.521669-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T03:10:43.042668-06:00","closed_at":"2026-02-03T03:10:43.042668-06:00","close_reason":"Closed"}
{"id":"parquedb-ne1h","title":"Clean up IndexCache for FTS/bloom only","description":"Simplify IndexCache.ts to only handle FTS and bloom filters:\n- Remove selectIndex logic for hash/sst\n- Remove executeHashLookup method\n- Remove executeSSTLookup method\n- Remove sharded hash/sst loading\n- Keep FTS loading and execution\n- Keep bloom filter loading for existence checks\n- Simplify index catalog types","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-02T11:06:19.946614-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-02T19:26:43.975183-06:00","closed_at":"2026-02-02T19:26:43.975183-06:00","close_reason":"Completed: IndexCache has been cleaned up. Hash and SST index methods removed. Only FTS and bloom filter support remains. All index selection and loading now focuses on FTS and bloom filters."}
{"id":"parquedb-nh5","title":"[RED] Inbound pagination tests","description":"Write failing tests for $count and $next in entity output","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:55.244167-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-02T04:45:59.00034-06:00","closed_at":"2026-02-02T04:45:59.00034-06:00","close_reason":"Tests implemented in earlier waves"}
{"id":"parquedb-nidt","title":"Add event log rotation","description":"Global event log (Collection.ts line 63) grows unbounded. Implement rotation or configurable maximum size to prevent memory exhaustion in high-write applications.","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-01T15:47:13.275629-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T16:16:20.586429-06:00","closed_at":"2026-02-01T16:16:20.586429-06:00","close_reason":"Closed"}
{"id":"parquedb-nmfa","title":"Create/source wikidata dataset","description":"The wikidata dataset is configured but no data files exist:\n- entities.parquet - missing\n- properties.parquet - missing\n\nNeed to either:\n1. Create a wikidata ETL/import script\n2. Source subset of wikidata and convert to parquet\n3. Remove wikidata from DATASETS config until data available","status":"open","priority":3,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T03:24:45.254062-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T03:24:45.254062-06:00"}
{"id":"parquedb-nuh","title":"[RED] Query execution tests","description":"Write failing tests for find, findOne with filters, sort, limit, skip","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:18.229225-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:02:48.200852-06:00","closed_at":"2026-02-01T14:02:48.200852-06:00","close_reason":"Closed"}
{"id":"parquedb-nuo0","title":"[CLEANUP] Remove backup files from git","description":"Backup files (.bak, .backup, ~) are checked into git. These should be:\n1. Removed from the repository\n2. Added to .gitignore\n\nRun: git ls-files | grep -E '\\.(bak|backup)$|~$' to find them.","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-01T13:35:46.241118-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T13:36:51.130936-06:00","closed_at":"2026-02-01T13:36:51.130936-06:00","close_reason":"Closed"}
{"id":"parquedb-nvh","title":"[RED] StorageBackend interface tests","description":"Write failing tests for StorageBackend: read, write, exists, list, readRange, writeAtomic","status":"closed","priority":0,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:02.290526-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T13:12:29.544715-06:00","closed_at":"2026-02-01T13:12:29.544715-06:00","close_reason":"Closed"}
{"id":"parquedb-nx33","title":"Refactor: Query - Add missing MongoDB comparison operators","description":"## Summary\nThe filter system is missing several MongoDB comparison operators that could be useful:\n\n### Missing Operators\n1. **$mod** - Modulo operation (value % divisor === remainder)\n   - Useful for filtering by multiples (e.g., every 3rd item)\n   \n2. **$expr** - Expression evaluation using aggregation operators\n   - Allows comparing fields to each other within the same document\n\n3. **$comment** - Query comment for logging/debugging\n   - Non-functional but helps with query tracing\n\n### Files to Update\n- `src/types/filter.ts` - Add type definitions\n- `src/query/filter.ts` - Add evaluation logic\n- `src/query/builder.ts` - Add QueryBuilder support\n\n### Acceptance Criteria\n- [ ] Add $mod operator support\n- [ ] Add $expr operator support  \n- [ ] Add $comment operator (pass-through, no effect on matching)\n- [ ] Add tests for each new operator","status":"open","priority":3,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:32:29.59577-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T06:32:29.59577-06:00","labels":["refactor"]}
{"id":"parquedb-o1j","title":"[RED] GraphDL integration tests","description":"Write failing tests for fromGraphDL() conversion","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:52:05.330852-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-02T04:45:58.885825-06:00","closed_at":"2026-02-02T04:45:58.885825-06:00","close_reason":"Tests implemented in earlier waves"}
{"id":"parquedb-o2m","title":"Relationship System","description":"Bidirectional relationships with predicate/reverse support","status":"closed","priority":1,"issue_type":"epic","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:50:30.49885-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:34:08.859159-06:00","closed_at":"2026-02-01T14:34:08.859159-06:00","close_reason":"Closed"}
{"id":"parquedb-o3d3","title":"Implement events manifest tracking","description":"Track event segments with a manifest file:\n\n```\nevents/\n  _manifest.json        # ordered list of segments\n  seg-0001.parquet\n  seg-0002.parquet\n```\n\nManifest structure:\n- Ordered list of segments\n- Min/max timestamps per segment\n- Event counts\n- Compaction watermark\n\nFile: src/events/manifest.ts","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-01T06:37:55.260933-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T07:09:57.644577-06:00","closed_at":"2026-02-01T07:09:57.644577-06:00","close_reason":"Implemented ManifestManager for tracking event segments. Features: segment ordering by timestamp, time range queries, compaction watermark, sequence management, statistics. Added 23 passing tests.","dependencies":[{"issue_id":"parquedb-o3d3","depends_on_id":"parquedb-1c3","type":"blocks","created_at":"2026-02-01T06:38:09.306184-06:00","created_by":"Nathan Clevenger"}]}
{"id":"parquedb-o40","title":"Load all examples with real data","status":"closed","priority":0,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T15:47:15.85633-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T13:13:39.023445-06:00","closed_at":"2026-02-01T13:13:39.023445-06:00","close_reason":"Closed"}
{"id":"parquedb-o5p7","title":"[SECURITY] Replace new Function() with Dynamic Worker Loaders","description":"The src/client/rpc-promise.ts file uses unsafe new Function(params, actualBody) for deserializing mapper functions. This is eval-like behavior that poses security risks.\n\nReplace with Cloudflare Dynamic Worker Loaders (when GA) or implement pre-registered mapper pattern. Research completed: primitives.org.ai ai-evaluate doesn't exist publicly - use Cloudflare sandbox SDK or Worker Loaders.\n\nReferences:\n- https://developers.cloudflare.com/workers/runtime-apis/bindings/worker-loader/\n- https://developers.cloudflare.com/sandbox/","notes":"Fixed by implementing secure mapper patterns:\n\n1. Path-Based Mappers - Simple property access (p =\u003e p.name) auto-converted to safe path-based mappers\n2. Registered Mappers - New registerMapper/getRegisteredMapper API for pre-registered safe functions  \n3. Legacy Mode with Strict Validation - Complex functions validated against dangerous patterns\n4. All 87 tests pass including new security tests\n\nSee commit for full implementation details.","status":"closed","priority":0,"issue_type":"bug","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-01T13:35:41.316032-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T13:45:52.292203-06:00","closed_at":"2026-02-01T13:45:52.292206-06:00"}
{"id":"parquedb-o8ri","title":"Refactor: Storage - Extract duplicate generateEtag function","description":"The generateEtag function using FNV-1a hash is duplicated in:\\n\\n1. MemoryBackend.ts (lines 82-92)\\n2. DOSqliteBackend.ts (lines 118-128)\\n\\nBoth use identical FNV-1a hash algorithm with timestamp suffix:\\n```typescript\\nfunction generateEtag(data: Uint8Array): string {\\n  let hash = 2166136261\\n  for (let i = 0; i \u003c data.length; i++) {\\n    hash ^= data[i]!\\n    hash = (hash * 16777619) \u003e\u003e\u003e 0\\n  }\\n  const timestamp = Date.now().toString(36)\\n  return \\`${hash.toString(16)}-${timestamp}\\`\\n}\\n```\\n\\nRefactor to:\\n- Move generateEtag to src/storage/utils.ts or src/storage/validation.ts\\n- Update both backends to use the shared implementation\\n\\nFiles affected:\\n- /Users/nathanclevenger/projects/parquedb/src/storage/MemoryBackend.ts\\n- /Users/nathanclevenger/projects/parquedb/src/storage/DOSqliteBackend.ts","status":"closed","priority":3,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:32:40.658257-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T07:22:10.18345-06:00","closed_at":"2026-02-03T07:22:10.18345-06:00","close_reason":"Implemented with full test coverage"}
{"id":"parquedb-o98","title":"[GREEN] Inbound pagination implementation","description":"Implement inbound pagination to pass tests","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:56.188806-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:25:01.857572-06:00","closed_at":"2026-02-01T14:25:01.857572-06:00","close_reason":"Closed"}
{"id":"parquedb-ofzl","title":"Benchmark-indexed missing scanFilter: always reports 1x speedup","description":"The benchmark-indexed endpoint reports 1x speedup for all queries because no BenchmarkQuery defines scanFilter. When scanFilter is undefined, the benchmark falls back to using indexed latencies as the scan baseline (line 322 in benchmark-indexed.ts), making indexed and scan times identical. Fix: add scanFilter to every query definition that strips the $index_ prefix from field names.","status":"closed","priority":0,"issue_type":"bug","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-02T08:27:36.88442-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-02T08:38:25.480663-06:00","closed_at":"2026-02-02T08:38:25.480663-06:00","close_reason":"Closed"}
{"id":"parquedb-oisd","title":"Refactor: Worker - Deduplicate schema definitions between DO_SQLITE_SCHEMA and ParqueDBDO","description":"The SQLite schema is defined in two places:\n\n1. src/types/worker.ts - DO_SQLITE_SCHEMA constant with CREATE TABLE statements\n2. src/worker/ParqueDBDO.ts - ensureInitialized() method with inline CREATE TABLE statements\n\nThese are not in sync - worker.ts has outdated schema (missing events_wal, event_batches tables).\n\nFiles:\n- src/types/worker.ts (DO_SQLITE_SCHEMA)\n- src/worker/ParqueDBDO.ts (ensureInitialized method)\n\nRefactor:\n- Either use DO_SQLITE_SCHEMA from worker.ts in ParqueDBDO\n- Or remove DO_SQLITE_SCHEMA since it's not being used\n\nImpact: Single source of truth for schema, prevents drift","status":"open","priority":3,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:33:10.047698-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T06:33:10.047698-06:00"}
{"id":"parquedb-ojlu","title":"Refactor: Storage - Inconsistent readRange end parameter semantics","description":"There's inconsistency in how backends interpret the 'end' parameter for readRange:\\n\\n1. MemoryBackend.ts (line 167): end is exclusive\\n   `return entry.data.slice(start, actualEnd)`\\n\\n2. R2Backend.ts (line 156): end is inclusive\\n   `const length = end - start + 1  // end is inclusive`\\n\\n3. DOSqliteBackend.ts (line 241-242): end is exclusive\\n   `const actualEnd = Math.min(end, data.length)`\\n   `return data.slice(start, actualEnd)`\\n\\n4. FsBackend.ts (lines 139-148): end is exclusive based on length calculation\\n   `const actualEnd = Math.min(end, fileStat.size)`\\n   `const length = actualEnd - start`\\n\\nThe StorageBackend interface should document whether 'end' is inclusive or exclusive, and all backends should be consistent. Standard convention (like Array.slice) treats end as exclusive.\\n\\nFiles affected:\\n- /Users/nathanclevenger/projects/parquedb/src/types/storage.ts (add documentation)\\n- /Users/nathanclevenger/projects/parquedb/src/storage/R2Backend.ts (fix to be exclusive)","status":"open","priority":3,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:33:53.481706-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T06:33:53.481706-06:00"}
{"id":"parquedb-okx6","title":"Refactor: core.ts beginTransaction() - Improve rollback implementation","description":"In src/ParqueDB/core.ts, beginTransaction() (lines 2287-2366) has an incomplete rollback implementation.\n\nCurrent rollback logic (lines 2342-2364):\n```typescript\nasync rollback(): Promise\u003cvoid\u003e {\n  self.inTransaction = false\n  self.pendingEvents = []\n  \n  // Rollback by undoing operations in reverse order\n  for (const op of pendingOps.reverse()) {\n    if (op.type === 'create' \u0026\u0026 op.entity) {\n      self.entities.delete(op.entity.$id as string)\n      // Remove the CREATE event\n      // ...\n    }\n    // For update/delete, we'd need to restore from before state\n    // This is a simplified implementation  \u003c-- COMMENT ACKNOWLEDGES INCOMPLETE\n  }\n}\n```\n\nIssues:\n1. Update rollback is not implemented (comment says 'simplified')\n2. Delete rollback is not implemented\n3. The 'before' state is not captured for updates/deletes\n\nTo properly implement transactions:\n1. Capture before state for all operations in pendingOps\n2. Implement update rollback: restore entity to before state\n3. Implement delete rollback: restore entity and remove from deletedAt\n4. Consider using a proper transactional pattern (command pattern, unit of work)\n\nThis is a correctness issue if transactions are relied upon.","status":"closed","priority":3,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:35:02.726426-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T07:31:58.535831-06:00","closed_at":"2026-02-03T07:31:58.535831-06:00","close_reason":"Closed","labels":["bug-risk","correctness","refactor"]}
{"id":"parquedb-oq4","title":"[RED] Traversal tests","description":"Write failing tests for related() and referencedBy() methods","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:49.051198-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-02T04:45:59.117237-06:00","closed_at":"2026-02-02T04:45:59.117237-06:00","close_reason":"Tests implemented in earlier waves"}
{"id":"parquedb-ov5","title":"Define Event types and schema","description":"Define the core Event interface and schema for the events log:\n\n```typescript\ninterface Event {\n  id: string           // ULID\n  ts: number           // timestamp\n  op: 'CREATE' | 'UPDATE' | 'DELETE'\n  target: string       // 'users:u1' or 'rel:users:u1:authored:posts:p5'\n  before?: Variant     // null for CREATE\n  after?: Variant      // null for DELETE\n  actor?: string\n}\n```\n\nFile: src/events/types.ts","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-01T06:37:47.411258-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T07:01:50.629498-06:00","closed_at":"2026-02-01T07:01:50.629498-06:00","close_reason":"Implemented Event types with new schema: target string (ns:id for entities, from:pred:to for relationships), numeric ts, undefined instead of null for before/after. Updated ParqueDB.ts, ParqueDBDO.ts, and event tests."}
{"id":"parquedb-p0b","title":"[GREEN] GraphDL integration implementation","description":"Implement GraphDL integration to pass tests","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:52:06.492301-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:18:32.144874-06:00","closed_at":"2026-02-01T14:18:32.144874-06:00","close_reason":"Closed"}
{"id":"parquedb-p1v","title":"[REFACTOR] Query execution cleanup","description":"Optimize query execution with predicate pushdown","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:19.940319-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:02:48.265795-06:00","closed_at":"2026-02-01T14:02:48.265795-06:00","close_reason":"Closed"}
{"id":"parquedb-p5w","title":"[GREEN] Relationship reading implementation","description":"Implement relationship reading to pass tests","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:31.149045-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:13:17.670691-06:00","closed_at":"2026-02-01T14:13:17.670691-06:00","close_reason":"Closed"}
{"id":"parquedb-p76","title":"[GREEN] Event logging implementation","description":"Implement event logging to pass tests","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:36.413973-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:21:45.110814-06:00","closed_at":"2026-02-01T14:21:45.110814-06:00","close_reason":"Closed"}
{"id":"parquedb-pl8u","title":"Add ReadPath.ts tests","description":"src/worker/ReadPath.ts has no dedicated tests. Add unit tests for the read path logic separate from full QueryExecutor tests.","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-01T15:47:29.687347-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T15:51:24.330297-06:00","closed_at":"2026-02-01T15:51:24.330297-06:00","close_reason":"Closed"}
{"id":"parquedb-pntz","title":"Refactor: Query - Add QueryBuilder array operator support","description":"## Summary\nThe QueryBuilder class in `src/query/builder.ts` only supports comparison, string, and existence operators. It's missing support for array operators.\n\n### Missing QueryBuilder Operators\n\n1. **$all** - Array contains all specified values\n2. **$elemMatch** - Array element matches filter\n3. **$size** - Array has specific length\n\n### Current QueryBuilder Operators (line 37-58)\n```typescript\nexport type ComparisonOp = 'eq' | '=' | 'ne' | '\\!=' | 'gt' | '\u003e' | ...\nexport type StringOp = 'regex' | 'startsWith' | 'endsWith' | 'contains'\nexport type ExistenceOp = 'exists'\n```\n\n### Proposed API\n```typescript\nbuilder\n  .whereArray('tags', 'all', ['featured', 'published'])\n  .whereArray('items', 'elemMatch', { status: 'active' })\n  .whereArray('tags', 'size', 3)\n```\n\nOr extend existing `where` method:\n```typescript\nbuilder.where('tags', 'all', ['featured', 'published'])\n```\n\n### Files to Update\n- `src/query/builder.ts` - Add array operators\n\n### Acceptance Criteria\n- [ ] Add ArrayOp type with all/elemMatch/size\n- [ ] Update operatorMap with array operators\n- [ ] Add whereArray() method or extend where()\n- [ ] Add tests for array operator building\n- [ ] Update JSDoc examples","status":"open","priority":3,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:33:23.981829-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T06:33:23.981829-06:00","labels":["refactor"]}
{"id":"parquedb-poif","title":"Replace stub index operations with proper errors","description":"IndexManager.ts has stub implementations (hashLookup, sstRange at lines 381-413, 739-757) that silently return empty results instead of throwing 'not implemented' errors. This causes silent failures in production.","status":"closed","priority":1,"issue_type":"bug","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-01T17:00:59.990453-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T17:12:41.401487-06:00","closed_at":"2026-02-01T17:12:41.401487-06:00","close_reason":"Closed"}
{"id":"parquedb-pqqv","title":"Remove SST index infrastructure","description":"Remove SST (sorted string table) index code since native parquet predicate pushdown on $index_* columns is faster for range queries. Includes:\n- Remove src/indexes/secondary/sst.ts\n- Remove src/indexes/secondary/sharded-sst.ts  \n- Remove SST index loading from IndexCache.ts\n- Remove SST index execution from QueryExecutor\n- Update tests to remove SST index tests\nKeep bloom filters and FTS indexes.","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-02T11:06:13.167525-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-02T12:11:19.32487-06:00","closed_at":"2026-02-02T12:11:19.32487-06:00","close_reason":"Removed SST index infrastructure. Native parquet predicate pushdown on $index_* columns is now faster for range queries. Deleted sst.ts, sharded-sst.ts, sst-index.test.ts. Updated all type references from 'hash|sst|fts' to 'hash|fts'. All 5920 tests pass."}
{"id":"parquedb-pt4a","title":"Fix error swallowing in IndexManager event listeners","description":"IndexManager.emit() at lines 628-638 catches listener errors and only logs a warning. Add onError callback or use robust event emitter to surface these errors to callers.","status":"closed","priority":1,"issue_type":"bug","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-01T17:01:02.613933-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T17:10:38.527528-06:00","closed_at":"2026-02-01T17:10:38.527528-06:00","close_reason":"Closed"}
{"id":"parquedb-pt8","title":"Implement schema parsing","description":"Parse schema definitions, extract fields and relationships","status":"closed","priority":0,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:54.745485-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T13:16:33.715358-06:00","closed_at":"2026-02-01T13:16:33.715358-06:00","close_reason":"Closed","dependencies":[{"issue_id":"parquedb-pt8","depends_on_id":"parquedb-byc","type":"blocks","created_at":"2026-01-30T11:52:03.965613-06:00","created_by":"Nathan Clevenger"},{"issue_id":"parquedb-pt8","depends_on_id":"parquedb-ttd","type":"blocks","created_at":"2026-01-30T11:52:04.051579-06:00","created_by":"Nathan Clevenger"},{"issue_id":"parquedb-pt8","depends_on_id":"parquedb-8jm","type":"blocks","created_at":"2026-01-30T11:52:04.142121-06:00","created_by":"Nathan Clevenger"}]}
{"id":"parquedb-ptf9","title":"Fix dynamic import using Function constructor","description":"In src/migration/mongodb.ts lines 219-221, dynamic import uses Function() constructor: BSON = await (Function('return import(\"bson\")')()). This is a security code smell. Replace with standard try/catch around direct dynamic import.","status":"closed","priority":0,"issue_type":"bug","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-01T17:00:45.815791-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T17:01:56.520656-06:00","closed_at":"2026-02-01T17:01:56.520656-06:00","close_reason":"Closed"}
{"id":"parquedb-puq","title":"[GREEN] Relationship storage implementation","description":"Implement relationship storage to pass tests","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:23.779082-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:08:29.211296-06:00","closed_at":"2026-02-01T14:08:29.211296-06:00","close_reason":"Closed"}
{"id":"parquedb-pvl","title":"[RED] Pagination tests","description":"Write failing tests for limit, skip, cursor","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:31.656352-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-02T04:45:59.462876-06:00","closed_at":"2026-02-02T04:45:59.462876-06:00","close_reason":"Tests implemented in earlier waves"}
{"id":"parquedb-py1f","title":"Fix snapshot calculation off-by-one test failure","description":"tests/unit/snapshots.test.ts:375 - Event replay count mismatch. Snapshot selection logic needs review. This is a correctness issue blocking production.","status":"closed","priority":0,"issue_type":"bug","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-01T12:42:05.837817-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T12:54:07.29389-06:00","closed_at":"2026-02-01T12:54:07.29389-06:00","close_reason":"Completed by parallel agents"}
{"id":"parquedb-q5e8","title":"[FEATURE] Add ACID transaction support","description":"No transaction support currently. Durable Objects provide single-entity atomicity but multi-entity transactions need:\n\n1. Transaction API design (begin/commit/rollback)\n2. Optimistic concurrency control (version vectors)\n3. Distributed transaction coordinator (if needed)\n4. Transaction isolation levels\n5. Deadlock detection/prevention\n\nConsider two-phase commit or saga pattern for distributed transactions.","status":"closed","priority":3,"issue_type":"feature","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-01T13:36:08.143212-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:42:33.645085-06:00","closed_at":"2026-02-01T14:42:33.645085-06:00","close_reason":"Closed"}
{"id":"parquedb-q5l3","title":"Create deployment guides","description":"Missing production deployment guidance. Create guides for: Cloudflare Workers deployment, R2 bucket setup, Durable Object configuration, caching strategies, monitoring setup.","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-01T15:47:45.637269-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T16:15:50.520295-06:00","closed_at":"2026-02-01T16:15:50.520295-06:00","close_reason":"Closed"}
{"id":"parquedb-q7ls","title":"Add Parquet infrastructure unit tests","description":"No unit tests exist for 8+ Parquet files. Create tests/unit/parquet/ with:\n- reader.test.ts\n- writer.test.ts\n- schema.test.ts\n- variant.test.ts\n- compression.test.ts\n- lz4.test.ts\n\nEstimated 30% coverage improvement.","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-01T12:42:11.625199-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T12:54:07.384805-06:00","closed_at":"2026-02-01T12:54:07.384805-06:00","close_reason":"Completed by parallel agents"}
{"id":"parquedb-q9x","title":"[RED] Update operator tests - numeric operators","description":"Write failing tests for $inc, $mul, $min, $max","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:22.78472-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:08:21.680604-06:00","closed_at":"2026-02-01T14:08:21.680604-06:00","close_reason":"Closed"}
{"id":"parquedb-qj5d","title":"Enable noUnusedLocals in tsconfig","description":"noUnusedLocals is false in tsconfig.json. Enable it to catch dead local variables during compilation. May require cleanup pass.","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-02T07:16:03.95317-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T03:54:42.609596-06:00","closed_at":"2026-02-03T03:54:42.609596-06:00","close_reason":"Closed"}
{"id":"parquedb-qrm","title":"[GREEN] MemoryBackend implementation","description":"Implement MemoryBackend to pass tests","status":"closed","priority":0,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:17.437898-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T13:11:45.021139-06:00","closed_at":"2026-02-01T13:11:45.021139-06:00","close_reason":"Closed"}
{"id":"parquedb-qu2x","title":"Wire observability hooks into all execution paths","description":"Observability hooks module is well-designed but not fully integrated. MutationExecutor has its own hooks that don't integrate with globalHookRegistry. Wire hooks into query execution and all mutation paths.","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-01T17:01:05.545501-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T17:16:14.920635-06:00","closed_at":"2026-02-01T17:16:14.920635-06:00","close_reason":"Closed"}
{"id":"parquedb-qz1","title":"Event Log \u0026 Time-Travel","description":"CDC event logging and point-in-time queries","status":"closed","priority":2,"issue_type":"epic","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:50:31.757926-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:34:08.927017-06:00","closed_at":"2026-02-01T14:34:08.927017-06:00","close_reason":"Closed"}
{"id":"parquedb-r10h","title":"Consolidate duplicated filter matching in ParqueDB.ts","description":"Filter matching logic is implemented 3 times: ParqueDB.ts (matchesFilter, matchesOperator), query/filter.ts (matchesFilter, matchesCondition), query/executor.ts (toPredicate). ParqueDB.ts has its own inline implementation that doesn't use safe regex. Consolidate to use matchesFilter from query/filter.ts everywhere.","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-01T17:00:58.790682-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T17:05:51.048483-06:00","closed_at":"2026-02-01T17:05:51.048483-06:00","close_reason":"Closed"}
{"id":"parquedb-r3i","title":"[GREEN] Update operation implementation","description":"Implement update operations to pass tests","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:33.562739-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:08:21.561836-06:00","closed_at":"2026-02-01T14:08:21.561836-06:00","close_reason":"Closed"}
{"id":"parquedb-rnky","title":"Standardize error handling patterns","description":"Error handling is inconsistent: IndexManager.load() silently continues, HashIndex.load() logs warnings, QueryExecutor.executeWithIndex() returns null. Establish consistent patterns, consider Result types for expected failures.","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-01T15:47:10.915559-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T16:14:25.319956-06:00","closed_at":"2026-02-01T16:14:25.319956-06:00","close_reason":"Closed"}
{"id":"parquedb-rpnw","title":"Replace any types with proper types","description":"2 any types found: ParqueDB.ts:3005 (const data: any), types/integrations.ts:221 (f: any). Replace with Record\u003cstring, unknown\u003e or more specific interfaces.","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-01T15:47:42.619197-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T16:12:54.30572-06:00","closed_at":"2026-02-01T16:12:54.30572-06:00","close_reason":"Closed"}
{"id":"parquedb-rxhp","title":"Refactor: Storage - Add TransactionalBackend implementation","description":"The StorageBackend interface defines TransactionalBackend at lines 295-321 of types/storage.ts:\\n\\n```typescript\\nexport interface TransactionalBackend extends StorageBackend {\\n  beginTransaction(): Promise\u003cTransaction\u003e\\n}\\n\\nexport interface Transaction {\\n  id: string\\n  read(path: string): Promise\u003cUint8Array\u003e\\n  write(path: string, data: Uint8Array): Promise\u003cvoid\u003e\\n  delete(path: string): Promise\u003cvoid\u003e\\n  commit(): Promise\u003cvoid\u003e\\n  rollback(): Promise\u003cvoid\u003e\\n}\\n```\\n\\nNo backend currently implements this. DOSqliteBackend could naturally support this since SQLite has native transaction support. This would enable:\\n- Atomic multi-file operations\\n- Rollback on error\\n- Consistent reads within a transaction\\n\\nFiles affected:\\n- /Users/nathanclevenger/projects/parquedb/src/storage/DOSqliteBackend.ts\\n- /Users/nathanclevenger/projects/parquedb/src/types/storage.ts","status":"open","priority":3,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:33:26.352873-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T06:33:26.352873-06:00"}
{"id":"parquedb-s19","title":"Configure LZ4 compression","description":"Use hyparquet-compressors with LZ4. Works on Workers without WASM. Update ParquetWriter defaults.","status":"closed","priority":0,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T14:30:13.181126-06:00","created_by":"Nathan Clevenger","updated_at":"2026-01-30T14:41:53.408204-06:00","closed_at":"2026-01-30T14:41:53.408204-06:00","close_reason":"Closed"}
{"id":"parquedb-s2bz","title":"Add delta-utils test coverage","description":"The delta-utils module lacks tests for: transaction-log.ts, cdc.ts, variant.ts, retry.ts. Add dedicated test files for each with unit tests covering success paths, error handling, and edge cases.","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-01T15:47:27.348219-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T15:55:36.85873-06:00","closed_at":"2026-02-01T15:55:36.85873-06:00","close_reason":"Closed"}
{"id":"parquedb-s3o0","title":"Refactor: Storage - Type guard functions could be more robust","description":"The type guard functions in types/storage.ts use simple property checks:\\n\\n```typescript\\nexport function isStreamable(backend: StorageBackend): backend is StreamableBackend {\\n  return 'createReadStream' in backend \u0026\u0026 'createWriteStream' in backend\\n}\\n\\nexport function isMultipart(backend: StorageBackend): backend is MultipartBackend {\\n  return 'createMultipartUpload' in backend\\n}\\n\\nexport function isTransactional(backend: StorageBackend): backend is TransactionalBackend {\\n  return 'beginTransaction' in backend\\n}\\n```\\n\\nIssues:\\n- Doesn't verify the property is a function\\n- Could be fooled by objects with these property names but different types\\n\\nRefactor to:\\n```typescript\\nexport function isStreamable(backend: StorageBackend): backend is StreamableBackend {\\n  return typeof (backend as StreamableBackend).createReadStream === 'function'\\n    \u0026\u0026 typeof (backend as StreamableBackend).createWriteStream === 'function'\\n}\\n```\\n\\nFiles affected:\\n- /Users/nathanclevenger/projects/parquedb/src/types/storage.ts","status":"open","priority":3,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:34:26.867976-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T06:34:26.867976-06:00"}
{"id":"parquedb-s8yv","title":"Implement StorageRouter interface and routing logic","description":"## Context\nPart of typed storage implementation (parquedb-k7jj design).\n\n## Requirements\n\n1. Create `src/storage/router.ts`:\n   - `StorageRouter` interface\n   - `StorageRouterImpl` class\n   - `getStorageMode(collection)` - returns 'typed' or 'flexible'\n   - `getStoragePath(collection)` - returns correct file path\n   - Route writes/reads based on schema presence\n\n2. Integration points:\n   - Extract flexible collections from DB() schema input\n   - Extract `$options` from collection definitions\n   - Wire into ParqueDB constructor\n\n3. Testing:\n   - Unit tests for routing logic\n   - Tests for path generation\n   - Tests for mode detection\n\n## Acceptance Criteria\n- [ ] StorageRouter interface defined\n- [ ] RouterImpl correctly routes typed vs flexible collections\n- [ ] Path generation follows spec: `data/{collection}.parquet` vs `data/{ns}/data.parquet`\n- [ ] Tests pass\n\n## References\n- Design: docs/architecture/typed-storage.md","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:41:10.595919-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T07:11:30.209147-06:00","closed_at":"2026-02-03T07:11:30.209147-06:00","close_reason":"Implemented"}
{"id":"parquedb-skfg","title":"Replace sleep() timing in tests with deterministic alternatives","description":"74 sleep()/setTimeout calls across 20 test files create flaky test risk. Use monotonic counters, injectable clocks, or vitest fake timers instead of wall-clock timing.","status":"closed","priority":3,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-02T07:16:04.180504-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T03:54:50.495269-06:00","closed_at":"2026-02-03T03:54:50.495269-06:00","close_reason":"Closed"}
{"id":"parquedb-sks9","title":"Refactor: core.ts - Consolidate duplicate ID normalization pattern","description":"In src/ParqueDB/core.ts, the ID normalization pattern is duplicated across multiple methods:\n\n```typescript\nconst fullId = id.includes('/') ? id : `${namespace}/${id}`\n```\n\nThis appears in:\n- get() line 333\n- update() line 695\n- delete() line 1168\n- restore() line 1273\n- getHistory() line 1313\n- getAtVersion() line 2241\n- getRelated() line 492\n\nThis should be extracted to a utility function in src/ParqueDB/validation.ts:\n```typescript\nexport function normalizeEntityId(namespace: string, id: string): EntityId {\n  return (id.includes('/') ? id : `${namespace}/${id}`) as EntityId\n}\n```\n\nBenefits:\n1. Single source of truth for ID normalization logic\n2. Easier to add additional normalization rules (e.g., validation)\n3. Improves code readability","status":"open","priority":3,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:32:48.641316-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T06:32:48.641316-06:00","labels":["duplication","refactor"]}
{"id":"parquedb-stdm","title":"Refactor: Worker - Remove legacy events table code from ParqueDBDO","description":"The ParqueDBDO has both new events_wal batching and legacy events table support. The legacy events table (lines ~284-298) is explicitly kept for backward compatibility. Once WAL migration is complete, this dead code can be removed.\n\nFiles:\n- src/worker/ParqueDBDO.ts\n\nCleanup:\n- Remove CREATE TABLE events statement\n- Remove idx_events_unflushed and idx_events_ns indexes\n- Remove any references to the legacy events table\n\nImpact: Reduces code complexity and SQLite row usage","status":"open","priority":3,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:32:52.427764-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T06:32:52.427764-06:00"}
{"id":"parquedb-stx","title":"Write: Schema Definition Guide","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T12:40:45.694171-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:35:25.733184-06:00","closed_at":"2026-02-01T14:35:25.733184-06:00","close_reason":"Closed"}
{"id":"parquedb-svh2","title":"Add aggregation framework","description":"Essential for analytical use cases. Implement MongoDB-style aggregation pipeline with $group, $unwind, $project stages. Consider supporting $lookup for joins.","status":"closed","priority":1,"issue_type":"feature","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-01T15:47:43.813552-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T16:35:42.907985-06:00","closed_at":"2026-02-01T16:35:42.907985-06:00","close_reason":"Closed"}
{"id":"parquedb-sylm","title":"RED: Add e2e tests for deployed dataset endpoints","description":"## Problem\nProduction endpoint /datasets/onet-graph/occupations returns Error 1101 (File not found: onet-graph/occupations.parquet).\n\nThe e2e tests don't catch this because they:\n1. Only test basic R2/DO operations\n2. Only test the root endpoint (/)\n3. Never hit /datasets/* endpoints with real data\n\nUnit tests mock the worker so they don't verify data actually exists in R2.\n\n## Red Test Requirements\nAdd failing e2e tests that:\n1. Hit each configured dataset endpoint and verify 200 response\n2. Test at least one collection per dataset (onet-graph/occupations, imdb/titles, etc.)\n3. Verify response contains actual data (not just valid JSON structure)\n4. Test with and without filters\n5. Test pagination (limit, skip, cursor)\n\n## Files to modify\n- tests/e2e/parquedb.workers.test.ts - add dataset endpoint tests\n- OR create new tests/e2e/datasets.test.ts\n\n## Expected Result\nTests should FAIL currently, exposing the production bug.","status":"closed","priority":0,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T02:54:17.437168-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T03:10:37.497553-06:00","closed_at":"2026-02-03T03:10:37.497553-06:00","close_reason":"Closed"}
{"id":"parquedb-szz","title":"[GREEN] Pagination implementation","description":"Implement pagination to pass tests","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:32.829795-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:11:19.224011-06:00","closed_at":"2026-02-01T14:11:19.224011-06:00","close_reason":"Closed"}
{"id":"parquedb-t2v","title":"[RED] Filter evaluation tests - string/array operators","description":"Write failing tests for $regex, $startsWith, $all, $elemMatch, $size","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:09.882799-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:03:47.557046-06:00","closed_at":"2026-02-01T14:03:47.557046-06:00","close_reason":"Closed"}
{"id":"parquedb-t35m","title":"Use safe-regex in ParqueDB.ts matchesOperator","description":"The matchesOperator method in ParqueDB.ts creates RegExp directly from user input without using the safe-regex utility. While createSafeRegex exists in src/utils/safe-regex.ts and is used in query/filter.ts, ParqueDB.ts has its own inline implementation that doesn't use it. This creates a ReDoS vulnerability.","status":"closed","priority":0,"issue_type":"bug","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-01T17:00:44.754732-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T17:02:14.858463-06:00","closed_at":"2026-02-01T17:02:14.858463-06:00","close_reason":"Closed"}
{"id":"parquedb-tmu","title":"[RED] Real FsBackend tests","description":"Write failing tests for FsBackend that use real Node fs. No mocks. Test CRUD, list, atomic writes.","status":"closed","priority":0,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T14:29:58.767533-06:00","created_by":"Nathan Clevenger","updated_at":"2026-01-30T14:31:29.326162-06:00","closed_at":"2026-01-30T14:31:29.326162-06:00","close_reason":"Closed"}
{"id":"parquedb-tn4","title":"Epic: Real Integration Tests (No Mocks)","description":"Replace all mock storage backends with real tests. Tests must exercise actual storage: FsBackend (Node fs), R2Backend (real R2), FsxBackend (Workers), DOSqliteBackend (Durable Objects). Use vitest-pool-workers with remote:true for real bindings.","status":"closed","priority":0,"issue_type":"epic","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T14:29:50.975228-06:00","created_by":"Nathan Clevenger","updated_at":"2026-01-30T14:46:18.284762-06:00","closed_at":"2026-01-30T14:46:18.284762-06:00","close_reason":"Closed"}
{"id":"parquedb-ttd","title":"[GREEN] Schema parsing implementation","description":"Implement schema parsing to pass tests","status":"closed","priority":0,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:59.704655-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T13:16:30.938595-06:00","closed_at":"2026-02-01T13:16:30.938595-06:00","close_reason":"Closed"}
{"id":"parquedb-tz46","title":"Implement consistent error handling/logging","description":"Error handling inconsistent across codebase:\n- Silent error swallowing in index loading (hash.ts:73, sst.ts:73)\n- console.log in production code (11 files)\n- No consistent logging strategy\n\nImplement logger interface, add error context, use proper error types.","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-01T12:42:43.839849-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T13:07:24.852836-06:00","closed_at":"2026-02-01T13:07:24.852836-06:00","close_reason":"Completed by parallel agents"}
{"id":"parquedb-u5lp","title":"Add $options support to collection schema definitions","description":"## Context\nPart of typed storage implementation (parquedb-k7jj design).\n\n## Requirements\n\n1. Extend `src/db.ts` schema parsing:\n   - Extract `$options` from collection definitions\n   - Support: includeDataVariant, compression, rowGroupSize, sortBy\n   - Validate option values\n\n2. Type definitions:\n   - Add `CollectionOptions` interface to types\n   - Update `CollectionSchemaWithLayout` to include $options\n\n3. Integration:\n   - Pass options to StorageRouter\n   - Apply options during write operations\n   - Document in API docs\n\n4. Testing:\n   - Unit tests for options parsing\n   - Tests for default values\n   - Tests for invalid options\n\n## Configuration API:\n```typescript\nconst db = DB({\n  Occupation: {\n    $options: {\n      includeDataVariant: true,     // default\n      compression: 'lz4',           // default\n      rowGroupSize: 50000,          // default\n      sortBy: ['$id'],             // default\n    },\n    name: 'string!',\n    socCode: 'string!#',\n  },\n})\n```\n\n## Acceptance Criteria\n- [ ] $options parsed correctly from schema\n- [ ] Default values applied when not specified\n- [ ] Options passed through to writer\n- [ ] TypeScript types updated\n- [ ] Tests pass\n\n## References\n- Design: docs/architecture/typed-storage.md\n- Depends on: parquedb-s8yv (StorageRouter)","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:41:48.463784-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T07:11:30.213613-06:00","closed_at":"2026-02-03T07:11:30.213613-06:00","close_reason":"Implemented"}
{"id":"parquedb-ufux","title":"Implement Result\u003cT,E\u003e error handling pattern","description":"All errors are thrown rather than returned. Implement functional error handling:\n\ntype Result\u003cT, E = Error\u003e = { ok: true; value: T } | { ok: false; error: E }\n\nReplace throw-based patterns in critical paths with Result returns for better type safety.","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-01T12:42:30.482725-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T13:07:24.793615-06:00","closed_at":"2026-02-01T13:07:24.793615-06:00","close_reason":"Completed by parallel agents"}
{"id":"parquedb-uhf9","title":"Add prototype pollution guards to query/update.ts and Collection.ts","description":"query/update.ts setField/unsetField and Collection.ts setNestedValue/deleteNestedValue lack prototype pollution checks (__proto__, constructor, prototype). mutation/operators.ts has validatePath/isUnsafePath - extract to shared utility and apply everywhere.","status":"closed","priority":0,"issue_type":"bug","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-02T07:16:01.304264-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T03:41:10.60434-06:00","closed_at":"2026-02-03T03:41:10.60434-06:00","close_reason":"Closed"}
{"id":"parquedb-ujk1","title":"Refactor: core.ts getEventLog() - Extract to dedicated class","description":"In src/ParqueDB/core.ts, getEventLog() (lines 2039-2155) returns an inline object literal with ~115 lines of implementation. Similar to the SnapshotManager, this should be extracted to a dedicated class.\n\nThe event log has several methods that deserve their own tests:\n- getEvents() - filters and sorts events by entity\n- getEventsByTimeRange() - complex boundary handling logic (lines 2073-2116)\n- getEventsByOp() - filters by operation type\n- archiveEvents() - rotation logic\n\nExtract to:\n```typescript\n// src/ParqueDB/EventLogImpl.ts\nexport class EventLogImpl implements EventLog {\n  constructor(\n    private events: Event[],\n    private archivedEvents: Event[],\n    private config: EventLogConfig\n  ) {}\n  // ...\n}\n```\n\nBenefits:\n1. Unit test event log logic in isolation\n2. Reduce core.ts complexity\n3. Cleaner interface boundaries","status":"open","priority":3,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:33:11.074013-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T06:33:11.074013-06:00","labels":["complexity","refactor"]}
{"id":"parquedb-uqe4","title":"GREEN: Restore/upload missing dataset parquet files to R2","description":"## Problem\nProduction error: File not found: onet-graph/occupations.parquet\n\nAll dataset collections are returning 1101 errors:\n- /datasets/onet-graph/occupations\n- /datasets/imdb/titles  \n- /datasets/unspsc/segments\n\nThe parquet files are either:\n1. Never uploaded to R2\n2. Accidentally deleted\n3. In wrong bucket/path\n\n## Investigation needed\n1. Check R2 bucket contents - what files exist?\n2. Check deployment history - when did files disappear?\n3. Check data pipeline - is there a script to generate/upload these?\n4. Check if data exists locally that needs uploading\n\n## Files involved\n- src/worker/datasets.ts - dataset config expects files at {prefix}/{collection}.parquet\n- R2 bucket: needs onet-graph/occupations.parquet, imdb/titles.parquet, etc.\n\n## Acceptance criteria\n- All configured datasets have their parquet files in R2\n- /datasets/onet-graph/occupations returns 200 with data\n- /datasets/imdb/titles returns 200 with data\n- E2e tests from RED issue pass","status":"closed","priority":0,"issue_type":"bug","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T02:54:27.217494-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T03:17:21.044943-06:00","closed_at":"2026-02-03T03:17:21.044943-06:00","close_reason":"Restored onet-graph and unspsc datasets to R2. onet-graph 4/4 and unspsc 4/4 collections working. imdb 2/5 working (sample data). Remaining issues: imdb ratings/principals/crew, onet-optimized, wikidata need separate tickets.","dependencies":[{"issue_id":"parquedb-uqe4","depends_on_id":"parquedb-sylm","type":"blocks","created_at":"2026-02-03T02:54:47.090573-06:00","created_by":"Nathan Clevenger"}]}
{"id":"parquedb-uqpb","title":"Refactor: Worker - Add error handling for missing R2 buckets","description":"In QueryExecutor and ParqueDBWorker, optional R2 buckets (CDN_BUCKET, CDN_R2_DEV_URL) are handled but primary BUCKET access lacks robust error handling.\n\nFiles:\n- src/worker/QueryExecutor.ts\n- src/worker/index.ts\n\nIssues identified:\n1. CdnR2StorageAdapter.loadWholeFile throws generic 'Object not found' error\n2. No distinction between network errors and missing files in some paths\n3. ParqueDBWorker.create/update/delete don't handle DO unavailable scenarios\n\nAdd:\n1. Specific error types for R2 connection issues vs missing files\n2. Graceful degradation when CDN bucket unavailable (fallback already exists but needs logging)\n3. Circuit breaker for repeated R2 failures\n\nImpact: Better operational debugging, more graceful failure modes","status":"open","priority":3,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:33:51.192728-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T06:33:51.192728-06:00"}
{"id":"parquedb-uta6","title":"Add stricter typing to aggregation executor","description":"aggregation/executor.ts uses 'as any' cast and loose type guards with Record\u003cstring, unknown\u003e. Use discriminated unions or branded types for aggregation operators.","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-01T17:01:03.633783-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T17:14:54.72836-06:00","closed_at":"2026-02-01T17:14:54.72836-06:00","close_reason":"Closed"}
{"id":"parquedb-uvie","title":"Fix 6 event sourcing test failures","description":"6 tests failing in event sourcing edge cases: version tracking in events, rapid sequential update ordering, relationship change event ordering. These block 1.0 release. Run npm test to identify and fix.","status":"closed","priority":0,"issue_type":"bug","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-01T17:00:50.549797-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T17:07:49.50068-06:00","closed_at":"2026-02-01T17:07:49.50068-06:00","close_reason":"Closed"}
{"id":"parquedb-v0bg","title":"Add tests for query/bloom.ts integration","description":"src/query/bloom.ts (612 lines) handles bloom filter query planning and row group pruning but has no dedicated tests. The BloomFilter data structure is tested but the query-level integration is not.","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-02T07:16:03.379899-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-02T07:23:52.360123-06:00","closed_at":"2026-02-02T07:23:52.360123-06:00","close_reason":"Closed"}
{"id":"parquedb-v5mo","title":"Add ParqueDBDO unit tests","description":"ParqueDBDO.ts is only tested through e2e tests. Create unit tests independent of full Worker environment to test: SQLite schema initialization, entity CRUD operations, event logging, flush pipeline, optimistic concurrency.","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-01T15:47:28.566847-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T16:02:35.857328-06:00","closed_at":"2026-02-01T16:02:35.857328-06:00","close_reason":"Created comprehensive unit tests for ParqueDBDO covering: SQLite schema initialization, Entity CRUD operations, Event logging, Optimistic concurrency, and Relationship operations (link/unlink)"}
{"id":"parquedb-vfo","title":"[GREEN] Populate implementation","description":"Implement populate to pass tests","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:42.858872-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:14:51.688443-06:00","closed_at":"2026-02-01T14:14:51.688443-06:00","close_reason":"Closed"}
{"id":"parquedb-vn8","title":"Write: Query API (filters, operators)","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T12:40:38.949433-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:35:37.568457-06:00","closed_at":"2026-02-01T14:35:37.568457-06:00","close_reason":"Closed"}
{"id":"parquedb-vnhb","title":"Refactor: Query - Improve null/undefined edge case handling","description":"## Summary\nWhile null/undefined handling is documented and mostly consistent, there are some edge cases and potential inconsistencies.\n\n### Current Behavior (as documented in filter.ts)\n- $eq: null and undefined are equivalent\n- $ne: null and undefined are equivalent  \n- $gt/$gte/$lt/$lte: Return false for null/undefined\n- $exists: Distinguishes undefined (missing) from null (present but null)\n- $type: Both null and undefined return 'null' type\n\n### Edge Cases to Verify/Fix\n\n1. **$elemMatch with null elements** (line 296-300):\n   - What happens when array contains null elements?\n   - Filter uses `matchesFilter(elem, subFilter)` which returns false for null\n\n2. **Nested path access through null** (comparison.ts line 161):\n   - `getNestedValue` returns undefined for path through null\n   - Should this distinguish 'not found' from 'found null'?\n\n3. **Array operators with null** (line 289-294):\n   - $all: Does it match if value is null? (Currently returns false)\n   - $size: Does it match if value is null? (Currently returns false)\n\n4. **Primitive row handling** (line 61-101):\n   - When row is a primitive, operators work but no null checks documented\n\n### Files to Update\n- `src/query/filter.ts` - Add edge case handling\n- `src/utils/comparison.ts` - Document behavior\n- Tests: Add explicit null edge case tests\n\n### Acceptance Criteria\n- [ ] Document all null/undefined behaviors in JSDoc\n- [ ] Add tests for $elemMatch with null array elements\n- [ ] Add tests for nested path through null\n- [ ] Verify array operator null handling matches MongoDB\n- [ ] Add primitive value null handling tests","status":"open","priority":3,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:33:14.699708-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T06:33:14.699708-06:00","labels":["refactor"]}
{"id":"parquedb-vpf","title":"Implement update operators","description":"MongoDB-style update operators ($set, $inc, $push, etc.)","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:19.196293-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:08:21.593295-06:00","closed_at":"2026-02-01T14:08:21.593295-06:00","close_reason":"Closed"}
{"id":"parquedb-vq7i","title":"DO WAL: Phase 2 - Bulk bypass to R2","description":"## TDD Task: Bulk operations bypass SQLite, stream to R2\n\n### Context\nFor 5+ entities, it's cheaper to write directly to R2 than buffer in SQLite. Bulk creates/updates should stream to pending Parquet files.\n\n### Red (Write failing tests first)\n1. Test bulk create (5+ entities) writes to R2, not SQLite\n2. Test pending row group metadata recorded (1 SQLite row)\n3. Test reads include pending row groups\n4. Test flush promotes pending to committed\n\n### Green (Implement)\n1. Add threshold check in create/update/upsertMany\n2. Stream to `data/{ns}/pending/{ulid}.parquet`\n3. Add `pending_row_groups` SQLite table (metadata only)\n4. Update QueryExecutor to merge pending files\n\n### Files\n- `src/worker/ParqueDBDO.ts` - bulk path\n- `src/worker/QueryExecutor.ts` - merge logic\n- `src/parquet/writer.ts` - streaming writes","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:07:31.186988-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T06:37:00.090414-06:00","closed_at":"2026-02-03T06:37:00.090414-06:00","close_reason":"Closed","dependencies":[{"issue_id":"parquedb-vq7i","depends_on_id":"parquedb-w48p","type":"blocks","created_at":"2026-02-03T06:07:44.77406-06:00","created_by":"Nathan Clevenger"}]}
{"id":"parquedb-vr4n","title":"Fix phantom generics on Entity\u003cTData\u003e - TData is unused","description":"Entity\u003cTData\u003e, CreateInput\u003cT\u003e, FindOptions\u003cT\u003e declare generic params that are never used in the interface body due to [key: string]: unknown index signature. Entity\u003cPost\u003e provides no more type safety than Entity\u003cany\u003e. Either put data under a data: TData property or remove phantom generics.","status":"closed","priority":1,"issue_type":"bug","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-02T07:16:02.427737-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T03:37:52.365554-06:00","closed_at":"2026-02-03T03:37:52.365554-06:00","close_reason":"Closed"}
{"id":"parquedb-vtuw","title":"[FEATURE] Enforce schema validation at runtime","description":"Schema inference exists in src/schema/parser.ts but validation is not enforced. Need to:\n\n1. Add validateOnWrite option to Collection\n2. Implement runtime validation against inferred/declared schema\n3. Add schema evolution/migration support\n4. Consider strict vs permissive modes\n5. Add helpful error messages for validation failures","status":"closed","priority":2,"issue_type":"feature","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-01T13:36:05.138775-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:46:29.741121-06:00","closed_at":"2026-02-01T14:46:29.741121-06:00","close_reason":"Closed"}
{"id":"parquedb-w48p","title":"DO WAL: Phase 1 - Batched event storage","description":"## TDD Task: Implement batched event storage in DO\n\n### Context\nCurrently each event = 1 SQLite row. Use the existing `SqliteWal` pattern from `src/events/sqlite-wal.ts` to batch events into blobs.\n\n### Red (Write failing tests first)\n1. Test that events are batched (not 1 row per event)\n2. Test batch threshold (e.g., 100 events or 64KB)\n3. Test reading back batched events\n4. Test flush triggers batch write\n\n### Green (Implement)\n1. Add `events_wal` table with blob storage\n2. Buffer events in memory until threshold\n3. Write batch as single blob row\n4. Update `appendEvent()` to use batching\n\n### Refactor\n- Remove old per-event `events` table usage\n- Ensure backward compat during migration\n\n### Files\n- `src/worker/ParqueDBDO.ts` - main changes\n- `src/events/sqlite-wal.ts` - reuse pattern\n- `tests/unit/worker/ParqueDBDO.test.ts` - new tests","notes":"## Updated Requirements\n\n### Counter for Sqid IDs\nStore counter in event batch metadata (zero extra writes):\n```sql\nCREATE TABLE events_wal (\n  id INTEGER PRIMARY KEY,\n  ns TEXT,\n  first_seq INTEGER,  -- first counter in batch\n  last_seq INTEGER,   -- last counter in batch  \n  events BLOB,\n  created_at TEXT\n)\n```\n\nOn startup: `SELECT MAX(last_seq) FROM events_wal WHERE ns = ?`\nID generation: `sqids.encode([counter])`  'Uk', '86u', 'RHEA'\n\n### Testing\nUse vitest-pool-workers with REAL DO SQLite, NOT mocks.\nTests go in `tests/e2e/worker/` to run in Workers runtime.\n\n### Files\n- Remove/ignore `tests/unit/worker/ParqueDBDO-wal.test.ts` (has mocks)\n- Create `tests/e2e/worker/do-wal.test.ts` instead","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:07:26.511173-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T06:27:04.288283-06:00","closed_at":"2026-02-03T06:27:04.288283-06:00","close_reason":"Implemented: Sqids IDs, events_wal batching, counter persistence, 12 e2e tests"}
{"id":"parquedb-w865","title":"Fix in-place entity mutation in ParqueDBImpl.update()","description":"ParqueDB/core.ts update() mutates entity objects directly in the shared entities Map. Concurrent async updates will overwrite each other (lost update). Clone entity before mutation like query/update.ts does.","status":"closed","priority":0,"issue_type":"bug","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-02T07:16:01.508567-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-02T07:22:09.84826-06:00","closed_at":"2026-02-02T07:22:09.84826-06:00","close_reason":"Closed"}
{"id":"parquedb-wglp","title":"Upload missing IMDB collections (ratings, principals, crew)","description":"The imdb dataset has 5 collections but only 2 have data uploaded:\n- titles \n- names \n- ratings  missing\n- principals  missing\n- crew  missing\n\nNeed to generate sample data or source real IMDB data for these collections.\n\nThe sample data generator (scripts/generate-imdb-sample.ts) creates titles, people, cast but\nthe dataset config expects different collection names.\n\nEither:\n1. Update dataset config to match what generator produces\n2. Update generator to produce expected collections\n3. Source real IMDB data and upload","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T03:24:40.19218-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T03:34:51.964859-06:00","closed_at":"2026-02-03T03:34:51.964859-06:00","close_reason":"Closed"}
{"id":"parquedb-wnn","title":"[RED] IMDB example using ParqueDB","description":"Rewrite IMDB loader to use db.collection().createMany() and $link for relationships. Movies, actors, ratings with proper relationships.","status":"closed","priority":0,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T14:31:40.815894-06:00","created_by":"Nathan Clevenger","updated_at":"2026-01-30T14:46:18.31241-06:00","closed_at":"2026-01-30T14:46:18.31241-06:00","close_reason":"Closed"}
{"id":"parquedb-x3r9","title":"Refactor: core.ts - Add JSDoc comments to private methods","description":"In src/ParqueDB/core.ts, several private methods lack documentation:\n\nMethods with good JSDoc:\n- recordEvent() - lines 1847-1853 have comprehensive docs\n- validateAgainstSchema() - lines 1317-1323\n\nMethods missing documentation:\n- hydrateEntity() - lines 1535-1648, only has one-line comment\n- reconstructEntityAtTime() - lines 1654-1751, only brief comment\n- flushEvents() - line 1756, single line\n- scheduleFlush() - lines 1829-1841, brief\n- maybeRotateEventLog() - lines 1919-1959, no docs\n- isFieldRequired() - lines 1395-1405, no docs\n- hasDefault() - lines 1410-1418, no docs\n- validateFieldType() - lines 1423-1486, no docs\n- applySchemaDefaults() - lines 1491-1529, no docs\n- legacyValidateAgainstSchema() - lines 1366-1390, no docs\n- archiveEvents() - lines 1967-2027, no docs\n\nAdding JSDoc would help developers understand:\n1. What each method does\n2. When/why it's called\n3. What parameters mean\n4. What side effects occur\n\nPriority on public-facing utility methods and complex logic like reconstructEntityAtTime.","status":"open","priority":3,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:34:42.226416-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T06:34:42.226416-06:00","labels":["documentation","refactor"]}
{"id":"parquedb-x53","title":"Write: API Reference - Collection class","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T12:40:35.234239-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:37:46.795057-06:00","closed_at":"2026-02-01T14:37:46.795057-06:00","close_reason":"Closed"}
{"id":"parquedb-x58","title":"[REFACTOR] FTS optimization","description":"Optimize tokenization and BM25 scoring","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:56.499715-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:27:18.834807-06:00","closed_at":"2026-02-01T14:27:18.834807-06:00","close_reason":"Closed"}
{"id":"parquedb-x6m","title":"[RED] Bloom filter tests","description":"Write failing tests for bloom filter creation and lookup","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:45.846772-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:24:19.291861-06:00","closed_at":"2026-02-01T14:24:19.291861-06:00","close_reason":"Closed"}
{"id":"parquedb-x9ie","title":"Split ParqueDB.ts into smaller modules","description":"ParqueDB.ts is 2000+ lines containing multiple classes, validation, filter matching, events, snapshots, relationships. Split into: src/ParqueDB/core.ts, src/ParqueDB/validation.ts, src/ParqueDB/relationships.ts, src/ParqueDB/snapshots.ts","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-01T17:01:01.572979-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-02T04:45:51.664924-06:00","closed_at":"2026-02-02T04:45:51.664924-06:00","close_reason":"Split into 6 modules: core.ts, collection.ts, types.ts, validation.ts, store.ts, index.ts. All 5062 tests pass."}
{"id":"parquedb-xi44","title":"Extend ParquetWriter for typed mode with $data column","description":"## Context\nPart of typed storage implementation (parquedb-k7jj design).\n\n## Requirements\n\n1. Extend `src/parquet/writer.ts`:\n   - Add typed mode write path\n   - Convert entities to native columns using generated schema\n   - Encode $data Variant column when enabled\n\n2. $data column encoding:\n   - Use Parquet Variant encoding if available\n   - Fall back to JSON encoding\n   - Include complete entity for fast full-row reads\n\n3. Integration with StorageRouter:\n   - Writer receives schema from router\n   - Respects per-collection options (compression, rowGroupSize)\n\n4. Testing:\n   - Unit tests for typed mode writing\n   - Tests for $data encoding/decoding roundtrip\n   - Tests with includeDataVariant: true/false\n   - Verify DuckDB can read generated files\n\n## Acceptance Criteria\n- [ ] Typed mode writes native columns per schema\n- [ ] $data column encoded correctly when enabled\n- [ ] Files readable by hyparquet and DuckDB\n- [ ] Per-collection options respected\n- [ ] Tests pass\n\n## References\n- Design: docs/architecture/typed-storage.md\n- Depends on: parquedb-37c3 (ParquetSchemaGenerator)","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:41:29.278642-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T07:22:10.17593-06:00","closed_at":"2026-02-03T07:22:10.17593-06:00","close_reason":"Implemented with full test coverage"}
{"id":"parquedb-xi8","title":"[REFACTOR] Collection class cleanup","description":"Refactor Collection class","status":"closed","priority":0,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:46.846235-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:02:25.580152-06:00","closed_at":"2026-02-01T14:02:25.580152-06:00","close_reason":"Closed"}
{"id":"parquedb-xlpg","title":"Fix null as unknown as Record pattern in migrations","description":"Migration files (mongodb.ts:697,718, csv.ts:474, json.ts:478,494,596) use 'null as unknown as Record\u003cstring,unknown\u003e' pattern. Replace with proper optional types or undefined.","status":"closed","priority":3,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-02T05:32:47.491335-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-02T06:45:38.321621-06:00","closed_at":"2026-02-02T06:45:38.321621-06:00","close_reason":"Closed"}
{"id":"parquedb-xtps","title":"Add performance benchmarks","description":"No published benchmarks to back efficiency claims. Create benchmarks comparing: compression ratios vs JSON/SQLite, query latency by data size, storage costs, predicate pushdown effectiveness.","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-01T15:47:44.725848-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T16:15:27.716037-06:00","closed_at":"2026-02-01T16:15:27.716037-06:00","close_reason":"Closed"}
{"id":"parquedb-xy4c","title":"[TEST] Add E2E tests to CI pipeline","description":"E2E tests exist in scripts/e2e-benchmark.mjs but are not run in CI. Need to:\n\n1. Add GitHub Actions workflow for E2E tests\n2. Configure test environment (Wrangler dev or miniflare)\n3. Add E2E test badge to README\n4. Consider nightly E2E runs against deployed worker","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-01T13:35:54.275202-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T13:43:29.471991-06:00","closed_at":"2026-02-01T13:43:29.471991-06:00","close_reason":"Closed"}
{"id":"parquedb-y66t","title":"Replace Buffer.from with Worker-safe encoding","description":"QueryExecutor.ts line 1618 uses Buffer.from() for cursor encoding. Buffer is Node.js global - Workers support it but prefer btoa() or Uint8Array for proper edge compatibility.","status":"closed","priority":2,"issue_type":"bug","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-01T15:47:21.658511-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T16:20:04.074079-06:00","closed_at":"2026-02-01T16:20:04.074079-06:00","close_reason":"Closed"}
{"id":"parquedb-y7xm","title":"Refactor: Query - Strengthen Filter type safety","description":"## Summary\nThe Filter interface in `src/types/filter.ts` allows too much flexibility, making it easy to construct invalid filters.\n\n### Current Issues\n\n1. **Loose field index signature** (line 262-264):\n   ```typescript\n   export interface Filter {\n     [field: string]: FieldFilter | undefined\n     // ... logical operators\n   }\n   ```\n   This allows any key including ones that look like operators but aren't recognized.\n\n2. **No validation of operator combinations**:\n   - Can combine incompatible operators (e.g., $gt on arrays)\n   - String operators can be used on non-string fields\n   - No type narrowing based on operator usage\n\n3. **Type guards don't cover all cases**:\n   - `isComparisonOperator` only checks for single-key objects (line 296)\n   - Combined operators like `{ $gt: 5, $lt: 10 }` fail the check\n\n### Proposed Improvements\n- Use branded types or template literals for field paths\n- Add strict mode filter type with better inference\n- Improve type guards to handle multi-operator conditions\n- Consider generic Filter\u003cT\u003e that validates against entity type\n\n### Files to Update\n- `src/types/filter.ts` - Improve type definitions\n\n### Acceptance Criteria\n- [ ] Create StrictFilter\u003cT\u003e generic type\n- [ ] Add field path validation type\n- [ ] Fix type guards for multi-operator conditions\n- [ ] Add JSDoc examples for common patterns","status":"open","priority":3,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:32:51.09074-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T06:32:51.09074-06:00","labels":["refactor"]}
{"id":"parquedb-y9aw","title":"[ARCH] Address async-and-forget write semantics","description":"Some write operations don't await completion, leading to:\n- Fire-and-forget patterns that may lose data\n- No confirmation that writes succeeded\n- Potential for silent failures\n\nAudit all write paths and ensure proper await/error handling. Consider adding write acknowledgment options.","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-01T13:35:51.840178-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T13:44:07.212622-06:00","closed_at":"2026-02-01T13:44:07.212622-06:00","close_reason":"Closed"}
{"id":"parquedb-yba1","title":"Refactor: Worker - QueryExecutor has placeholder parsing methods","description":"QueryExecutor has several placeholder implementations that return empty/dummy data:\n\n1. parseMetadata() - returns empty ParquetMetadata (lines 1889-1897)\n2. parseRowGroup() - returns empty EntityRecord[] (lines 1903-1910)  \n3. parseBloomFilter() - returns a bloom filter that always returns true (lines 1916-1924)\n\nThese are used by the legacy code path when ParquetReader is not available.\n\nFiles:\n- src/worker/QueryExecutor.ts\n\nOptions:\n1. Complete the implementations using hyparquet\n2. Remove the legacy path since ParquetReader is now the primary reader\n3. Add clear error messages if these paths are hit unexpectedly\n\nImpact: Cleaner code, better error handling for edge cases","status":"open","priority":3,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:33:43.116612-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T06:33:43.116612-06:00"}
{"id":"parquedb-ycie","title":"Refactor: Storage - Extract duplicate globToRegex function","description":"The globToRegex function is duplicated in multiple files:\\n\\n1. MemoryBackend.ts (lines 97-105) - matchPattern function\\n2. FsBackend.ts (lines 306-312) - globToRegex method\\n3. DOSqliteBackend.ts (lines 602-608) - globToRegex function\\n\\nAll three implementations are nearly identical, converting glob patterns (* and ?) to regex.\\n\\nRefactor to:\\n- Add globToRegex to src/storage/validation.ts or create src/storage/utils.ts\\n- Update all backends to use the shared implementation\\n\\nFiles affected:\\n- /Users/nathanclevenger/projects/parquedb/src/storage/MemoryBackend.ts\\n- /Users/nathanclevenger/projects/parquedb/src/storage/FsBackend.ts\\n- /Users/nathanclevenger/projects/parquedb/src/storage/DOSqliteBackend.ts\\n- /Users/nathanclevenger/projects/parquedb/src/storage/validation.ts","status":"closed","priority":3,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:32:33.21887-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T07:22:10.181778-06:00","closed_at":"2026-02-03T07:22:10.181778-06:00","close_reason":"Implemented with full test coverage"}
{"id":"parquedb-ygh8","title":"Add concurrency tests","description":"No tests for parallel operations on same entities. Add tests for: concurrent reads, concurrent writes, read-write races, optimistic locking under contention.","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-01T15:47:31.847513-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T16:22:48.916818-06:00","closed_at":"2026-02-01T16:22:48.916818-06:00","close_reason":"Closed"}
{"id":"parquedb-ympz","title":"Add tests for vector index components","description":"Missing test coverage for: hnsw.ts (HNSW index), distance.ts (vector distance calculations). Vector search is a key feature that needs test coverage.","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-02T05:32:42.624783-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-02T06:34:55.02098-06:00","closed_at":"2026-02-02T06:34:55.02098-06:00","close_reason":"Closed"}
{"id":"parquedb-yr2","title":"[REFACTOR] Filter evaluation cleanup","description":"Refactor filter evaluation for performance","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:11.791039-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:03:47.622261-06:00","closed_at":"2026-02-01T14:03:47.622261-06:00","close_reason":"Closed"}
{"id":"parquedb-ysgx","title":"Refactor: Storage - ObservedBackend missing MultipartBackend support","description":"ObservedBackend wraps StorageBackend but does not pass through MultipartBackend methods.\\n\\nR2Backend implements MultipartBackend:\\n```typescript\\nexport class R2Backend implements StorageBackend, MultipartBackend {\\n  createMultipartUpload(path: string, options?: WriteOptions): Promise\u003cMultipartUpload\u003e\\n  startMultipartUpload(path: string): Promise\u003cstring\u003e\\n  uploadPart(...): Promise\u003c{ etag: string }\u003e\\n  completeMultipartUpload(...): Promise\u003cvoid\u003e\\n  abortMultipartUpload(...): Promise\u003cvoid\u003e\\n  writeStreaming(...): Promise\u003cWriteResult\u003e\\n}\\n```\\n\\nBut wrapping R2Backend with ObservedBackend loses access to these methods:\\n```typescript\\nconst observed = withObservability(new R2Backend(bucket))\\nobserved.createMultipartUpload // undefined!\\n```\\n\\nRefactor to:\\n- Add conditional multipart method forwarding in ObservedBackend\\n- Use isMultipart() type guard to check and forward calls\\n- Add observability hooks for multipart operations\\n\\nFiles affected:\\n- /Users/nathanclevenger/projects/parquedb/src/storage/ObservedBackend.ts","status":"open","priority":3,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:34:19.51593-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T06:34:19.51593-06:00"}
{"id":"parquedb-zag","title":"[GREEN] Link/unlink implementation","description":"Implement $link and $unlink to pass tests","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-01-30T11:51:37.213952-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T14:06:34.658476-06:00","closed_at":"2026-02-01T14:06:34.658476-06:00","close_reason":"Closed"}
{"id":"parquedb-zkar","title":"Add graph traversal tests","description":"src/relationships/traverse.ts has limited test coverage for complex graph queries. Add tests for: multi-hop traversal, cycle detection, path finding, breadth-first vs depth-first traversal.","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-01T17:01:07.565418-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T17:11:57.367181-06:00","closed_at":"2026-02-01T17:11:57.367181-06:00","close_reason":"Closed"}
{"id":"parquedb-zlwa","title":"Performance: core.ts find() - Avoid full entity scan for indexed queries","description":"In src/ParqueDB/core.ts, find() (lines 196-320) always performs a full scan of all entities:\n\n```typescript\nthis.entities.forEach((entity, id) =\u003e {\n  if (id.startsWith(`${namespace}/`)) {\n    // filter matching\n  }\n})\n```\n\nThis has O(n) complexity where n is total entities across ALL namespaces, not just the target namespace.\n\nPotential optimizations:\n1. **Namespace index**: Store entities keyed by namespace -\u003e Map\u003cnamespace, Map\u003cid, Entity\u003e\u003e\n2. **Use IndexManager**: The class has an indexManager but find() doesn't use it\n3. **Bloom filter pre-check**: Use bloom filters to skip non-matching row groups\n\nThe IndexManager exists (line 113, 129) but is never consulted during find() queries. The createIndex/listIndexes APIs exist (lines 2838-2906) but indexes aren't used for query optimization.\n\nConsider:\n```typescript\nasync find(namespace: string, filter?: Filter): Promise\u003c...\u003e {\n  // Check if any index can accelerate this query\n  const applicableIndex = await this.indexManager.findApplicableIndex(namespace, filter)\n  if (applicableIndex) {\n    return this.indexManager.executeIndexedQuery(namespace, filter, applicableIndex)\n  }\n  // Fall back to full scan\n}\n```","status":"closed","priority":3,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:34:51.276414-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T07:32:27.140437-06:00","closed_at":"2026-02-03T07:32:27.140437-06:00","close_reason":"Closed","labels":["optimization","performance"]}
{"id":"parquedb-zmh6","title":"Set up CI/CD pipeline with GitHub Actions","description":"No CI/CD pipeline detected. Create .github/workflows/ with:\n- test:unit (15 second target)\n- test:integration (30 second target)\n- test:e2e (60 second target)\n- lint and type check\n- Performance regression detection\n- Coverage reporting","status":"closed","priority":1,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-01T12:42:26.190832-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T13:07:24.659465-06:00","closed_at":"2026-02-01T13:07:24.659465-06:00","close_reason":"Completed by parallel agents"}
{"id":"parquedb-zpoh","title":"[TEST] Enforce code coverage thresholds","description":"Add code coverage enforcement to CI:\n\n1. Configure vitest/jest coverage reporting\n2. Set minimum thresholds (suggest 80% line, 70% branch)\n3. Add coverage badge to README\n4. Fail CI if coverage drops below threshold\n5. Generate coverage reports as artifacts","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-01T13:35:56.897188-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T13:38:43.700518-06:00","closed_at":"2026-02-01T13:38:43.700518-06:00","close_reason":"Closed"}
{"id":"parquedb-zqk","title":"Implement Event writer with memory buffer","description":"Create EventWriter class that buffers events in memory before flushing:\n\n- Buffer events in memory\n- Configurable flush triggers (size threshold, time interval, explicit flush)\n- Track min/max timestamps for the buffer\n- Emit batches to flush handlers\n\nFile: src/events/writer.ts","status":"closed","priority":2,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-01T06:37:48.522193-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-01T07:03:58.82561-06:00","closed_at":"2026-02-01T07:03:58.82561-06:00","close_reason":"Implemented EventWriter class with memory buffering, configurable thresholds (size, count, time), flush handlers, statistics tracking, and timed auto-flush. Added 19 passing tests.","dependencies":[{"issue_id":"parquedb-zqk","depends_on_id":"parquedb-ov5","type":"blocks","created_at":"2026-02-01T06:38:06.397637-06:00","created_by":"Nathan Clevenger"}]}
{"id":"parquedb-zs1v","title":"Refactor: core.ts - Improve error messages with context","description":"In src/ParqueDB/core.ts, some error messages lack sufficient context for debugging:\n\n1. Line 117: `throw new Error('Storage backend is required')`\n   - OK but could mention ParqueDBConfig\n\n2. Line 762: `throw new Error(\\`Unsafe path detected: \\\"${key}\\\" contains a prototype pollution attempt\\`)`\n   - Good, includes the key\n\n3. Line 799: `throw new Error(\\`Cannot apply $inc to non-numeric field: ${key}\\`)`\n   - Good, includes field name\n\n4. Line 971: `throw new Error(\\`Relationship '${key}' is not defined in schema for type '${typeName}'\\`)`\n   - Good, includes field and type\n\n5. Line 991: `throw new Error(\\`Target entity '${targetId}' does not exist\\`)`\n   - OK but could include source entity and relationship name\n\nAreas for improvement:\n- Line 2377: `throw new Error(\\`Entity not found: ${entityId}\\`)`\n  - Could specify this is for snapshot creation\n- Line 2761: `throw new Error('Entity did not exist at the target time')`\n  - Should include entityId and targetTime\n- Line 2131: `throw new Error(\\`Event not found: ${id}\\`)`\n  - OK\n\nConsider creating an errors.ts module with factory functions:\n```typescript\nexport const Errors = {\n  entityNotFound: (id: string, operation: string) =\u003e\n    new Error(\\`Entity '${id}' not found during ${operation}\\`),\n  // ...\n}\n```","status":"open","priority":3,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:34:20.920836-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T06:34:20.920836-06:00","labels":["developer-experience","error-handling","refactor"]}
{"id":"parquedb-zzj0","title":"Refactor: Worker - Relationship fromType/fromName always empty in ParqueDBDO","description":"ParqueDBDO.toRelationship() returns empty strings for fromType, fromName, toType, and toName:\n\n```typescript\nreturn {\n  fromNs: stored.from_ns as Namespace,\n  fromId: stored.from_id as Id,\n  fromType: '', // Would need to look up from entity\n  fromName: '', // Would need to look up from entity\n  ...\n}\n```\n\nFiles:\n- src/worker/ParqueDBDO.ts (toRelationship method, lines 1377-1396)\n\nThis makes relationship responses less useful for clients who want display names.\n\nOptions:\n1. Add entity lookups to populate these fields\n2. Denormalize name/type into the relationships table (cost: data duplication)\n3. Document that these are intentionally empty and let clients hydrate\n\nImpact: More complete relationship data, better client UX","status":"open","priority":3,"issue_type":"task","owner":"4130910+nathanclevenger@users.noreply.github.com","created_at":"2026-02-03T06:33:59.945822-06:00","created_by":"Nathan Clevenger","updated_at":"2026-02-03T06:33:59.945822-06:00"}
