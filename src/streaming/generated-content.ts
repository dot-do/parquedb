/**
 * GeneratedContent Materialized View
 *
 * A materialized view for capturing and analyzing AI-generated content.
 * Tracks all text and structured objects generated by AI models, enabling:
 * - Content auditing and compliance
 * - Output quality analysis
 * - Token efficiency tracking
 * - Content categorization and search
 *
 * @example
 * ```typescript
 * import { createGeneratedContentMV, recordGeneratedContent } from 'parquedb/streaming'
 *
 * // Create the MV
 * const mv = createGeneratedContentMV({
 *   storage: myStorage,
 *   datasetPath: 'ai/generated',
 *   flushThreshold: 500,
 * })
 *
 * // Record generated content
 * await mv.ingestContent({
 *   requestId: 'req_123',
 *   modelId: 'gpt-4',
 *   contentType: 'text',
 *   content: 'The generated response text...',
 *   tokenCount: 150,
 * })
 *
 * // Flush to Parquet
 * await mv.flush()
 * ```
 *
 * @packageDocumentation
 */

import type { StorageBackend } from '../types/storage'
import type { ParquetSchema } from '../parquet/types'

// =============================================================================
// Content Type Definitions
// =============================================================================

/**
 * Type of generated content
 */
export type GeneratedContentType =
  | 'text'              // Plain text response
  | 'code'              // Code/programming content
  | 'json'              // Structured JSON object
  | 'markdown'          // Markdown formatted text
  | 'html'              // HTML content
  | 'tool_call'         // Tool/function call
  | 'tool_result'       // Tool/function result
  | 'image_description' // Image description/alt text
  | 'embedding'         // Vector embedding
  | 'other'             // Other/unknown content type

/**
 * Content quality/safety classification
 */
export type ContentClassification =
  | 'safe'              // Safe content
  | 'sensitive'         // May contain sensitive information
  | 'pii'               // Contains personally identifiable information
  | 'flagged'           // Flagged for review
  | 'unclassified'      // Not yet classified

/**
 * Finish reason from the model
 */
export type FinishReason =
  | 'stop'              // Natural completion
  | 'length'            // Hit max token limit
  | 'tool_calls'        // Model wants to call tools
  | 'content_filter'    // Filtered by safety system
  | 'error'             // Error during generation
  | 'unknown'           // Unknown reason

// =============================================================================
// Generated Content Record Types
// =============================================================================

/**
 * A single generated content record
 */
export interface GeneratedContentRecord {
  /** Unique content ID (ULID) */
  id: string

  /** Request ID for correlation with AI requests */
  requestId: string

  /** Timestamp when content was generated */
  timestamp: number

  /** Model ID that generated the content */
  modelId: string

  /** Provider ID (e.g., 'openai', 'anthropic') */
  providerId: string | null

  /** Type of content generated */
  contentType: GeneratedContentType

  /** The generated content (text or serialized JSON) */
  content: string

  /** Content length in characters */
  contentLength: number

  /** Token count for the generated content */
  tokenCount: number | null

  /** Prompt token count (if available) */
  promptTokenCount: number | null

  /** Total token count (prompt + completion) */
  totalTokenCount: number | null

  /** Finish reason from the model */
  finishReason: FinishReason

  /** Latency in milliseconds */
  latencyMs: number | null

  /** Whether this was a streaming response */
  isStreaming: boolean

  /** Whether this was served from cache */
  isCached: boolean

  /** Content classification */
  classification: ContentClassification

  /** Tool name (if contentType is tool_call or tool_result) */
  toolName: string | null

  /** Tool call ID for correlation */
  toolCallId: string | null

  /** Language detected in the content (e.g., 'en', 'es', 'code:python') */
  language: string | null

  /** Content hash for deduplication */
  contentHash: string | null

  /** Session/conversation ID for grouping related content */
  sessionId: string | null

  /** User ID that triggered the generation */
  userId: string | null

  /** Application/source that generated the content */
  source: string | null

  /** Additional metadata */
  metadata: string | null
}

/**
 * Input for recording generated content
 */
export interface RecordContentInput {
  /** Request ID for correlation */
  requestId: string

  /** Model ID that generated the content */
  modelId: string

  /** Provider ID */
  providerId?: string

  /** Type of content */
  contentType: GeneratedContentType

  /** The generated content */
  content: string | Record<string, unknown>

  /** Token count for the generated content */
  tokenCount?: number

  /** Prompt token count */
  promptTokenCount?: number

  /** Total token count */
  totalTokenCount?: number

  /** Finish reason */
  finishReason?: FinishReason

  /** Latency in milliseconds */
  latencyMs?: number

  /** Whether this was a streaming response */
  isStreaming?: boolean

  /** Whether this was served from cache */
  isCached?: boolean

  /** Content classification */
  classification?: ContentClassification

  /** Tool name (for tool calls/results) */
  toolName?: string

  /** Tool call ID */
  toolCallId?: string

  /** Language detected */
  language?: string

  /** Session/conversation ID */
  sessionId?: string

  /** User ID */
  userId?: string

  /** Application/source */
  source?: string

  /** Custom ID (auto-generated if not provided) */
  id?: string

  /** Custom timestamp (defaults to now) */
  timestamp?: number

  /** Additional metadata */
  metadata?: Record<string, unknown>
}

/**
 * Parquet schema for generated content
 */
export const GENERATED_CONTENT_SCHEMA: ParquetSchema = {
  id: { type: 'BYTE_ARRAY', optional: false },
  requestId: { type: 'BYTE_ARRAY', optional: false },
  timestamp: { type: 'INT64', optional: false },
  modelId: { type: 'BYTE_ARRAY', optional: false },
  providerId: { type: 'BYTE_ARRAY', optional: true },
  contentType: { type: 'BYTE_ARRAY', optional: false },
  content: { type: 'BYTE_ARRAY', optional: false },
  contentLength: { type: 'INT32', optional: false },
  tokenCount: { type: 'INT32', optional: true },
  promptTokenCount: { type: 'INT32', optional: true },
  totalTokenCount: { type: 'INT32', optional: true },
  finishReason: { type: 'BYTE_ARRAY', optional: false },
  latencyMs: { type: 'INT32', optional: true },
  isStreaming: { type: 'BOOLEAN', optional: false },
  isCached: { type: 'BOOLEAN', optional: false },
  classification: { type: 'BYTE_ARRAY', optional: false },
  toolName: { type: 'BYTE_ARRAY', optional: true },
  toolCallId: { type: 'BYTE_ARRAY', optional: true },
  language: { type: 'BYTE_ARRAY', optional: true },
  contentHash: { type: 'BYTE_ARRAY', optional: true },
  sessionId: { type: 'BYTE_ARRAY', optional: true },
  userId: { type: 'BYTE_ARRAY', optional: true },
  source: { type: 'BYTE_ARRAY', optional: true },
  metadata: { type: 'BYTE_ARRAY', optional: true },
}

// =============================================================================
// Statistics Types
// =============================================================================

/**
 * Statistics for the GeneratedContent MV
 */
export interface GeneratedContentStats {
  /** Total content records ingested */
  recordsIngested: number
  /** Total content records written to Parquet */
  recordsWritten: number
  /** Total Parquet files created */
  filesCreated: number
  /** Total bytes written */
  bytesWritten: number
  /** Records by content type */
  byContentType: Record<GeneratedContentType, number>
  /** Records by model */
  byModel: Record<string, number>
  /** Records by finish reason */
  byFinishReason: Record<FinishReason, number>
  /** Records by classification */
  byClassification: Record<ContentClassification, number>
  /** Total tokens generated */
  totalTokens: number
  /** Total content characters */
  totalCharacters: number
  /** Number of flushes performed */
  flushCount: number
  /** Last flush timestamp */
  lastFlushAt: number | null
  /** Current buffer size */
  bufferSize: number
}

// =============================================================================
// Configuration Types
// =============================================================================

/**
 * Configuration for the GeneratedContent MV
 */
export interface GeneratedContentMVConfig {
  /** Storage backend for writing Parquet files */
  storage: StorageBackend
  /** Base path for content files (e.g., 'ai/generated') */
  datasetPath: string
  /** Number of records to buffer before flushing (default: 500) */
  flushThreshold?: number
  /** Maximum time to buffer records in ms (default: 30000) */
  flushIntervalMs?: number
  /** Compression codec for Parquet (default: 'lz4') */
  compression?: 'none' | 'snappy' | 'gzip' | 'lz4' | 'zstd'
  /** Target row group size (default: 5000) */
  rowGroupSize?: number
  /** ID generator function (default: uses ULID) */
  generateId?: () => string
  /** Hash function for content deduplication */
  hashContent?: (content: string) => string
}

/**
 * Default configuration values
 */
const DEFAULT_CONFIG = {
  flushThreshold: 500,
  flushIntervalMs: 30000,
  compression: 'lz4' as const,
  rowGroupSize: 5000,
}

// =============================================================================
// ULID Generator
// =============================================================================

/**
 * Generate a ULID-like ID for content records
 */
function generateULID(): string {
  const timestamp = Date.now()
  const timeStr = timestamp.toString(36).padStart(10, '0')
  const random = Array.from({ length: 16 }, () =>
    Math.floor(Math.random() * 36).toString(36)
  ).join('')
  return timeStr + random
}

/**
 * Simple hash function for content deduplication
 * Uses djb2 algorithm
 */
function simpleHash(content: string): string {
  let hash = 5381
  for (let i = 0; i < content.length; i++) {
    hash = ((hash << 5) + hash) ^ content.charCodeAt(i)
  }
  return (hash >>> 0).toString(36)
}

// =============================================================================
// GeneratedContentMV Class
// =============================================================================

/**
 * Materialized View for Generated Content
 *
 * Buffers generated content records in memory and periodically flushes
 * them to Parquet files for efficient storage and querying.
 */
export class GeneratedContentMV {
  private storage: StorageBackend
  private datasetPath: string
  private flushThreshold: number
  private flushIntervalMs: number
  private compression: 'none' | 'snappy' | 'gzip' | 'lz4' | 'zstd'
  private rowGroupSize: number
  private generateId: () => string
  private hashContent: (content: string) => string

  private buffer: GeneratedContentRecord[] = []
  private flushTimer: ReturnType<typeof setTimeout> | null = null
  private flushPromise: Promise<void> | null = null
  private running = false

  private stats: GeneratedContentStats = this.createEmptyStats()

  constructor(config: GeneratedContentMVConfig) {
    this.storage = config.storage
    this.datasetPath = config.datasetPath.replace(/\/$/, '') // Remove trailing slash
    this.flushThreshold = config.flushThreshold ?? DEFAULT_CONFIG.flushThreshold
    this.flushIntervalMs = config.flushIntervalMs ?? DEFAULT_CONFIG.flushIntervalMs
    this.compression = config.compression ?? DEFAULT_CONFIG.compression
    this.rowGroupSize = config.rowGroupSize ?? DEFAULT_CONFIG.rowGroupSize
    this.generateId = config.generateId ?? generateULID
    this.hashContent = config.hashContent ?? simpleHash
  }

  // ===========================================================================
  // Public API
  // ===========================================================================

  /**
   * Start the MV (enables periodic flushing)
   */
  start(): void {
    if (this.running) return

    this.running = true
    this.startFlushTimer()
  }

  /**
   * Stop the MV and flush remaining records
   */
  async stop(): Promise<void> {
    if (!this.running) return

    this.running = false
    this.stopFlushTimer()

    // Flush remaining records
    await this.flush()
  }

  /**
   * Check if the MV is running
   */
  isRunning(): boolean {
    return this.running
  }

  /**
   * Ingest generated content
   *
   * @param input - Content to record
   */
  async ingestContent(input: RecordContentInput): Promise<void> {
    const record = this.inputToRecord(input)
    this.buffer.push(record)
    this.stats.bufferSize = this.buffer.length

    // Update stats
    this.updateStats(record)

    // Check if we should flush
    await this.maybeFlush()
  }

  /**
   * Ingest multiple content records
   *
   * @param inputs - Array of content to record
   */
  async ingestContents(inputs: RecordContentInput[]): Promise<void> {
    for (const input of inputs) {
      const record = this.inputToRecord(input)
      this.buffer.push(record)
      this.updateStats(record)
    }
    this.stats.bufferSize = this.buffer.length

    // Check if we should flush
    await this.maybeFlush()
  }

  /**
   * Ingest raw content records directly
   *
   * @param records - Array of GeneratedContentRecord to ingest
   */
  async ingestRecords(records: GeneratedContentRecord[]): Promise<void> {
    this.buffer.push(...records)
    this.stats.bufferSize = this.buffer.length

    // Update stats
    for (const record of records) {
      this.updateStats(record)
    }

    // Check if we should flush
    await this.maybeFlush()
  }

  /**
   * Flush buffered records to Parquet
   */
  async flush(): Promise<void> {
    // Wait for any in-flight flush
    if (this.flushPromise) {
      await this.flushPromise
    }

    if (this.buffer.length === 0) {
      return
    }

    this.flushPromise = this.doFlush()
    try {
      await this.flushPromise
    } finally {
      this.flushPromise = null
    }
  }

  /**
   * Get current statistics
   */
  getStats(): GeneratedContentStats {
    return { ...this.stats }
  }

  /**
   * Reset statistics
   */
  resetStats(): void {
    this.stats = this.createEmptyStats()
    this.stats.bufferSize = this.buffer.length
  }

  /**
   * Get current buffer contents (for testing/debugging)
   */
  getBuffer(): GeneratedContentRecord[] {
    return [...this.buffer]
  }

  // ===========================================================================
  // Internal Methods
  // ===========================================================================

  /**
   * Create empty stats object
   */
  private createEmptyStats(): GeneratedContentStats {
    return {
      recordsIngested: 0,
      recordsWritten: 0,
      filesCreated: 0,
      bytesWritten: 0,
      byContentType: {
        text: 0,
        code: 0,
        json: 0,
        markdown: 0,
        html: 0,
        tool_call: 0,
        tool_result: 0,
        image_description: 0,
        embedding: 0,
        other: 0,
      },
      byModel: {},
      byFinishReason: {
        stop: 0,
        length: 0,
        tool_calls: 0,
        content_filter: 0,
        error: 0,
        unknown: 0,
      },
      byClassification: {
        safe: 0,
        sensitive: 0,
        pii: 0,
        flagged: 0,
        unclassified: 0,
      },
      totalTokens: 0,
      totalCharacters: 0,
      flushCount: 0,
      lastFlushAt: null,
      bufferSize: 0,
    }
  }

  /**
   * Update statistics for a record
   */
  private updateStats(record: GeneratedContentRecord): void {
    this.stats.recordsIngested++
    this.stats.byContentType[record.contentType] =
      (this.stats.byContentType[record.contentType] || 0) + 1
    this.stats.byModel[record.modelId] =
      (this.stats.byModel[record.modelId] || 0) + 1
    this.stats.byFinishReason[record.finishReason] =
      (this.stats.byFinishReason[record.finishReason] || 0) + 1
    this.stats.byClassification[record.classification] =
      (this.stats.byClassification[record.classification] || 0) + 1

    if (record.tokenCount) {
      this.stats.totalTokens += record.tokenCount
    }
    this.stats.totalCharacters += record.contentLength
  }

  /**
   * Convert input to a content record
   */
  private inputToRecord(input: RecordContentInput): GeneratedContentRecord {
    // Serialize content if it's an object
    const contentStr = typeof input.content === 'string'
      ? input.content
      : JSON.stringify(input.content)

    return {
      id: input.id ?? this.generateId(),
      requestId: input.requestId,
      timestamp: input.timestamp ?? Date.now(),
      modelId: input.modelId,
      providerId: input.providerId ?? null,
      contentType: input.contentType,
      content: contentStr,
      contentLength: contentStr.length,
      tokenCount: input.tokenCount ?? null,
      promptTokenCount: input.promptTokenCount ?? null,
      totalTokenCount: input.totalTokenCount ?? null,
      finishReason: input.finishReason ?? 'unknown',
      latencyMs: input.latencyMs ?? null,
      isStreaming: input.isStreaming ?? false,
      isCached: input.isCached ?? false,
      classification: input.classification ?? 'unclassified',
      toolName: input.toolName ?? null,
      toolCallId: input.toolCallId ?? null,
      language: input.language ?? null,
      contentHash: this.hashContent(contentStr),
      sessionId: input.sessionId ?? null,
      userId: input.userId ?? null,
      source: input.source ?? null,
      metadata: input.metadata ? JSON.stringify(input.metadata) : null,
    }
  }

  /**
   * Check if we should flush based on threshold
   */
  private async maybeFlush(): Promise<void> {
    if (this.buffer.length >= this.flushThreshold) {
      await this.flush()
    }
  }

  /**
   * Start the periodic flush timer
   */
  private startFlushTimer(): void {
    if (this.flushTimer) return

    this.flushTimer = setInterval(() => {
      if (this.buffer.length > 0 && !this.flushPromise) {
        this.flush().catch((err) => {
          console.error('[GeneratedContentMV] Periodic flush failed:', err)
        })
      }
    }, this.flushIntervalMs)
  }

  /**
   * Stop the periodic flush timer
   */
  private stopFlushTimer(): void {
    if (this.flushTimer) {
      clearInterval(this.flushTimer)
      this.flushTimer = null
    }
  }

  /**
   * Perform the actual flush to Parquet
   */
  private async doFlush(): Promise<void> {
    if (this.buffer.length === 0) return

    // Snapshot and clear buffer
    const records = this.buffer
    this.buffer = []
    this.stats.bufferSize = 0

    // Generate file path with timestamp partitioning
    const now = new Date()
    const year = now.getUTCFullYear()
    const month = String(now.getUTCMonth() + 1).padStart(2, '0')
    const day = String(now.getUTCDate()).padStart(2, '0')
    const hour = String(now.getUTCHours()).padStart(2, '0')
    const timestamp = Date.now()

    const filePath = `${this.datasetPath}/year=${year}/month=${month}/day=${day}/hour=${hour}/content-${timestamp}.parquet`

    try {
      // Convert records to columnar format
      const columns = this.recordsToColumns(records)

      // Write to Parquet using storage backend
      const buffer = await this.buildParquetBuffer(columns)
      const result = await this.storage.writeAtomic(filePath, buffer, {
        contentType: 'application/vnd.apache.parquet',
      })

      // Update stats
      this.stats.recordsWritten += records.length
      this.stats.filesCreated++
      this.stats.bytesWritten += result.size
      this.stats.flushCount++
      this.stats.lastFlushAt = Date.now()
    } catch (error) {
      // Put records back in buffer on failure
      this.buffer = records.concat(this.buffer)
      this.stats.bufferSize = this.buffer.length
      throw error
    }
  }

  /**
   * Convert records to columnar format
   */
  private recordsToColumns(records: GeneratedContentRecord[]): Record<string, unknown[]> {
    const columns: Record<string, unknown[]> = {}

    // Initialize columns
    for (const colName of Object.keys(GENERATED_CONTENT_SCHEMA)) {
      columns[colName] = []
    }

    // Fill columns
    for (const record of records) {
      columns['id']!.push(record.id)
      columns['requestId']!.push(record.requestId)
      columns['timestamp']!.push(record.timestamp)
      columns['modelId']!.push(record.modelId)
      columns['providerId']!.push(record.providerId)
      columns['contentType']!.push(record.contentType)
      columns['content']!.push(record.content)
      columns['contentLength']!.push(record.contentLength)
      columns['tokenCount']!.push(record.tokenCount)
      columns['promptTokenCount']!.push(record.promptTokenCount)
      columns['totalTokenCount']!.push(record.totalTokenCount)
      columns['finishReason']!.push(record.finishReason)
      columns['latencyMs']!.push(record.latencyMs)
      columns['isStreaming']!.push(record.isStreaming)
      columns['isCached']!.push(record.isCached)
      columns['classification']!.push(record.classification)
      columns['toolName']!.push(record.toolName)
      columns['toolCallId']!.push(record.toolCallId)
      columns['language']!.push(record.language)
      columns['contentHash']!.push(record.contentHash)
      columns['sessionId']!.push(record.sessionId)
      columns['userId']!.push(record.userId)
      columns['source']!.push(record.source)
      columns['metadata']!.push(record.metadata)
    }

    return columns
  }

  /**
   * Build Parquet buffer from columnar data
   */
  private async buildParquetBuffer(columns: Record<string, unknown[]>): Promise<Uint8Array> {
    try {
      // Try to use hyparquet-writer
      const { parquetWriteBuffer } = await import('hyparquet-writer')
      const { writeCompressors } = await import('../parquet/compression')

      const columnData = Object.entries(columns).map(([name, data]) => ({
        name,
        data,
        columnIndex: true,
        offsetIndex: true,
      }))

      const writeOptions: Record<string, unknown> = {
        columnData,
        statistics: true,
        rowGroupSize: this.rowGroupSize,
      }

      // Set compression
      if (this.compression !== 'none') {
        const codecMap: Record<string, string> = {
          snappy: 'SNAPPY',
          gzip: 'GZIP',
          lz4: 'LZ4',
          zstd: 'ZSTD',
        }
        writeOptions.codec = codecMap[this.compression]
        writeOptions.compressors = writeCompressors
      }

      const result = parquetWriteBuffer(writeOptions as Parameters<typeof parquetWriteBuffer>[0])
      return new Uint8Array(result)
    } catch {
      // Fallback to JSON-based format
      return this.buildFallbackBuffer(columns)
    }
  }

  /**
   * Build fallback buffer when hyparquet-writer is not available
   */
  private buildFallbackBuffer(columns: Record<string, unknown[]>): Uint8Array {
    const data = {
      schema: GENERATED_CONTENT_SCHEMA,
      columns,
      metadata: {
        compression: this.compression,
        rowGroupSize: this.rowGroupSize,
      },
    }

    const jsonStr = JSON.stringify(data)
    const encoder = new TextEncoder()
    const jsonBytes = encoder.encode(jsonStr)

    // Wrap with Parquet magic bytes
    const MAGIC = new Uint8Array([0x50, 0x41, 0x52, 0x31]) // 'PAR1'
    const buffer = new Uint8Array(MAGIC.length * 2 + jsonBytes.length)
    buffer.set(MAGIC, 0)
    buffer.set(jsonBytes, MAGIC.length)
    buffer.set(MAGIC, MAGIC.length + jsonBytes.length)

    return buffer
  }
}

// =============================================================================
// Factory Functions
// =============================================================================

/**
 * Create a new GeneratedContentMV instance
 */
export function createGeneratedContentMV(config: GeneratedContentMVConfig): GeneratedContentMV {
  return new GeneratedContentMV(config)
}

/**
 * Create a GeneratedContentMV handler for use with StreamingRefreshEngine
 *
 * This adapter allows the GeneratedContentMV to be registered as an MV handler
 * that processes CDC events from ParqueDB.
 *
 * @param mv - The GeneratedContentMV instance
 * @param sourceNamespace - The namespace to watch for content events
 */
export function createGeneratedContentMVHandler(
  mv: GeneratedContentMV,
  sourceNamespace = 'generated_content'
) {
  return {
    name: 'GeneratedContent',
    sourceNamespaces: [sourceNamespace],
    async process(events: import('../types/entity').Event[]): Promise<void> {
      // Convert CDC events to GeneratedContentRecords
      const records: GeneratedContentRecord[] = []

      for (const event of events) {
        if (event.op === 'CREATE' && event.after) {
          // Assume event.after contains a GeneratedContentRecord-like structure
          const data = event.after as Partial<GeneratedContentRecord>
          if (data.requestId && data.modelId && data.contentType && data.content) {
            records.push({
              id: data.id ?? generateULID(),
              requestId: data.requestId,
              timestamp: data.timestamp ?? Date.now(),
              modelId: data.modelId,
              providerId: data.providerId ?? null,
              contentType: data.contentType,
              content: data.content,
              contentLength: data.contentLength ?? data.content.length,
              tokenCount: data.tokenCount ?? null,
              promptTokenCount: data.promptTokenCount ?? null,
              totalTokenCount: data.totalTokenCount ?? null,
              finishReason: data.finishReason ?? 'unknown',
              latencyMs: data.latencyMs ?? null,
              isStreaming: data.isStreaming ?? false,
              isCached: data.isCached ?? false,
              classification: data.classification ?? 'unclassified',
              toolName: data.toolName ?? null,
              toolCallId: data.toolCallId ?? null,
              language: data.language ?? null,
              contentHash: data.contentHash ?? simpleHash(data.content),
              sessionId: data.sessionId ?? null,
              userId: data.userId ?? null,
              source: data.source ?? null,
              metadata: data.metadata ?? null,
            })
          }
        }
      }

      if (records.length > 0) {
        await mv.ingestRecords(records)
      }
    },
  }
}

// =============================================================================
// Utility Functions
// =============================================================================

/**
 * Detect content type from the content itself
 *
 * @param content - The content to analyze
 * @returns Detected content type
 */
export function detectContentType(content: string): GeneratedContentType {
  const trimmed = content.trim()

  // Check for JSON
  if (
    (trimmed.startsWith('{') && trimmed.endsWith('}')) ||
    (trimmed.startsWith('[') && trimmed.endsWith(']'))
  ) {
    try {
      JSON.parse(trimmed)
      return 'json'
    } catch {
      // Not valid JSON
    }
  }

  // Check for HTML
  if (trimmed.startsWith('<!DOCTYPE') || trimmed.startsWith('<html') || /<[a-z][\s\S]*>/i.test(trimmed)) {
    return 'html'
  }

  // Check for Markdown indicators
  if (
    /^#{1,6}\s/.test(trimmed) || // Headers
    /^\*{3,}$|^-{3,}$|^_{3,}$/m.test(trimmed) || // Horizontal rules
    /\[.+\]\(.+\)/.test(trimmed) || // Links
    /```[\s\S]+```/.test(trimmed) // Code blocks
  ) {
    return 'markdown'
  }

  // Check for code-like patterns
  if (
    /^(import|export|const|let|var|function|class|def|fn|pub|async|await)\s/m.test(trimmed) ||
    /[{}\[\]();]/.test(trimmed) && /\n/.test(trimmed)
  ) {
    return 'code'
  }

  return 'text'
}

/**
 * Detect programming language from code content
 *
 * @param content - The code content to analyze
 * @returns Detected language or null
 */
export function detectCodeLanguage(content: string): string | null {
  const patterns: Array<{ pattern: RegExp; language: string }> = [
    { pattern: /^import\s+[\w{}\s,]+\s+from\s+['"]/, language: 'javascript' },
    { pattern: /^from\s+\w+\s+import\s+/, language: 'python' },
    { pattern: /^package\s+\w+/, language: 'go' },
    { pattern: /^use\s+\w+::\w+/, language: 'rust' },
    { pattern: /^#include\s*</, language: 'cpp' },
    { pattern: /^public\s+class\s+\w+/, language: 'java' },
    { pattern: /^func\s+\w+\s*\(/, language: 'go' },
    { pattern: /^def\s+\w+\s*\(/, language: 'python' },
    { pattern: /^fn\s+\w+\s*\(/, language: 'rust' },
    { pattern: /^const\s+\w+:\s*\w+\s*=/, language: 'typescript' },
    { pattern: /^interface\s+\w+\s*{/, language: 'typescript' },
    { pattern: /^type\s+\w+\s*=/, language: 'typescript' },
  ]

  for (const { pattern, language } of patterns) {
    if (pattern.test(content)) {
      return `code:${language}`
    }
  }

  return null
}

/**
 * Calculate approximate token count for text
 * Uses a simple heuristic: ~4 characters per token
 *
 * @param text - Text to estimate tokens for
 * @returns Estimated token count
 */
export function estimateTokenCount(text: string): number {
  // GPT models average about 4 characters per token for English
  return Math.ceil(text.length / 4)
}
